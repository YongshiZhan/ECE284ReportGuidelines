{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "00401679",
   "metadata": {},
   "source": [
    "# ECE 284 Final Project - Software"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "924c9e6d",
   "metadata": {},
   "source": [
    "## Vanilla Training VGGNet with 4 bit activation and weight quantisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1ef33fe1",
   "metadata": {},
   "source": [
    "### Initialisation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "a5d2eeb4",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "VGG_quant(\n",
      "  (features): Sequential(\n",
      "    (0): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): QuantConv2d(\n",
      "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): QuantConv2d(\n",
      "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): QuantConv2d(\n",
      "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): QuantConv2d(\n",
      "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): QuantConv2d(\n",
      "      256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (44): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "\n",
    "batch_size = 128\n",
    "model_name = \"VGG16_quant\"\n",
    "model = VGG16_quant()\n",
    "\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "    \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [150, 225]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74c5f97d",
   "metadata": {},
   "source": [
    "### Chokepoint Block and SkipBlock Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "65b70166",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using SkipBlock optimisation\n",
      "VGG_quant(\n",
      "  (features): Sequential(\n",
      "    (0): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): QuantConv2d(\n",
      "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): QuantConv2d(\n",
      "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): QuantConv2d(\n",
      "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): QuantConv2d(\n",
      "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): QuantConv2d(\n",
      "      256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (25): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): QuantConv2d(\n",
      "      8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (28): Identity()\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): QuantConv2d(\n",
      "      8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (44): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# [SEE custom_vgg.py for details on SkipBlock optimisation]\n",
    "from models.custom_vgg import SkipBlock\n",
    "\n",
    "use_skip_block = False\n",
    "if use_skip_block:\n",
    "    print(\"Using SkipBlock optimisation\")\n",
    "    skip_block = SkipBlock()\n",
    "    model.features[20] = skip_block\n",
    "    for i in range(21, 33):\n",
    "        model.features[i] = nn.Identity()\n",
    "else:\n",
    "    print(\"Not using SkipBlock optimisation\")\n",
    "    model.features[24] = QuantConv2d(256, 8, kernel_size=3, padding=1, bias=False)\n",
    "    model.features[25] = nn.BatchNorm2d(8)\n",
    "    model.features[26] = nn.ReLU(inplace=True)\n",
    "    \n",
    "    model.features[27] = QuantConv2d(8, 8, kernel_size=3, padding=1, bias=False)\n",
    "    model.features[28] = nn.Identity()\n",
    "    model.features[29] = nn.ReLU(inplace=True)\n",
    "    \n",
    "    model.features[30] = QuantConv2d(8, 512, kernel_size=3, padding=1, bias=False)\n",
    "    model.features[31] = nn.BatchNorm2d(512)\n",
    "    model.features[32] = nn.ReLU(inplace=True)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f7f29e57",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "junior-reminder",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 0.939 (0.939)\tData 0.420 (0.420)\tLoss 2.4035 (2.4035)\tPrec 11.719% (11.719%)\n",
      "Epoch: [0][100/391]\tTime 0.049 (0.056)\tData 0.001 (0.005)\tLoss 1.7465 (2.0822)\tPrec 39.844% (28.759%)\n",
      "Epoch: [0][200/391]\tTime 0.047 (0.052)\tData 0.001 (0.003)\tLoss 1.5257 (1.8682)\tPrec 50.781% (37.512%)\n",
      "Epoch: [0][300/391]\tTime 0.048 (0.050)\tData 0.001 (0.003)\tLoss 1.4412 (1.7406)\tPrec 54.688% (43.010%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.289 (0.289)\tLoss 1.4663 (1.4663)\tPrec 56.250% (56.250%)\n",
      " * Prec 53.660% \n",
      "best acc: 53.660000\n",
      "Epoch: [1][0/391]\tTime 0.213 (0.213)\tData 0.181 (0.181)\tLoss 1.4423 (1.4423)\tPrec 53.906% (53.906%)\n",
      "Epoch: [1][100/391]\tTime 0.047 (0.049)\tData 0.001 (0.004)\tLoss 1.3009 (1.3072)\tPrec 68.750% (63.157%)\n",
      "Epoch: [1][200/391]\tTime 0.047 (0.048)\tData 0.001 (0.003)\tLoss 1.3568 (1.2779)\tPrec 64.844% (64.754%)\n",
      "Epoch: [1][300/391]\tTime 0.046 (0.048)\tData 0.001 (0.002)\tLoss 1.0507 (1.2527)\tPrec 75.000% (66.100%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.184 (0.184)\tLoss 1.2687 (1.2687)\tPrec 66.406% (66.406%)\n",
      " * Prec 64.730% \n",
      "best acc: 64.730000\n",
      "Epoch: [2][0/391]\tTime 0.334 (0.334)\tData 0.305 (0.305)\tLoss 1.2197 (1.2197)\tPrec 70.312% (70.312%)\n",
      "Epoch: [2][100/391]\tTime 0.043 (0.050)\tData 0.001 (0.005)\tLoss 1.0297 (1.1198)\tPrec 77.344% (72.587%)\n",
      "Epoch: [2][200/391]\tTime 0.046 (0.049)\tData 0.001 (0.003)\tLoss 1.1417 (1.1116)\tPrec 70.312% (72.936%)\n",
      "Epoch: [2][300/391]\tTime 0.049 (0.048)\tData 0.001 (0.003)\tLoss 0.9801 (1.0991)\tPrec 80.469% (73.567%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.195 (0.195)\tLoss 1.0513 (1.0513)\tPrec 71.094% (71.094%)\n",
      " * Prec 74.680% \n",
      "best acc: 74.680000\n",
      "Epoch: [3][0/391]\tTime 0.377 (0.377)\tData 0.345 (0.345)\tLoss 1.0457 (1.0457)\tPrec 78.125% (78.125%)\n",
      "Epoch: [3][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.005)\tLoss 1.0430 (1.0269)\tPrec 76.562% (76.841%)\n",
      "Epoch: [3][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 1.0912 (1.0232)\tPrec 76.562% (77.219%)\n",
      "Epoch: [3][300/391]\tTime 0.050 (0.048)\tData 0.001 (0.002)\tLoss 1.1389 (1.0235)\tPrec 70.312% (77.146%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.306 (0.306)\tLoss 1.1308 (1.1308)\tPrec 75.000% (75.000%)\n",
      " * Prec 72.620% \n",
      "best acc: 74.680000\n",
      "Epoch: [4][0/391]\tTime 0.342 (0.342)\tData 0.313 (0.313)\tLoss 1.0026 (1.0026)\tPrec 78.906% (78.906%)\n",
      "Epoch: [4][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.004)\tLoss 0.9576 (0.9618)\tPrec 79.688% (79.873%)\n",
      "Epoch: [4][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.9847 (0.9760)\tPrec 79.688% (79.233%)\n",
      "Epoch: [4][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.9020 (0.9693)\tPrec 80.469% (79.503%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.349 (0.349)\tLoss 0.9826 (0.9826)\tPrec 81.250% (81.250%)\n",
      " * Prec 77.030% \n",
      "best acc: 77.030000\n",
      "Epoch: [5][0/391]\tTime 0.380 (0.380)\tData 0.346 (0.346)\tLoss 0.9629 (0.9629)\tPrec 79.688% (79.688%)\n",
      "Epoch: [5][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.005)\tLoss 1.0388 (0.9261)\tPrec 80.469% (81.072%)\n",
      "Epoch: [5][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.9449 (0.9303)\tPrec 79.688% (80.962%)\n",
      "Epoch: [5][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 1.0165 (0.9261)\tPrec 78.125% (81.086%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.176 (0.176)\tLoss 0.9228 (0.9228)\tPrec 79.688% (79.688%)\n",
      " * Prec 79.610% \n",
      "best acc: 79.610000\n",
      "Epoch: [6][0/391]\tTime 0.389 (0.389)\tData 0.330 (0.330)\tLoss 0.9570 (0.9570)\tPrec 80.469% (80.469%)\n",
      "Epoch: [6][100/391]\tTime 0.046 (0.050)\tData 0.010 (0.005)\tLoss 0.9280 (0.8945)\tPrec 78.125% (82.720%)\n",
      "Epoch: [6][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 1.0190 (0.9012)\tPrec 82.812% (82.494%)\n",
      "Epoch: [6][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.003)\tLoss 0.8851 (0.8995)\tPrec 85.156% (82.527%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.186 (0.186)\tLoss 0.9262 (0.9262)\tPrec 80.469% (80.469%)\n",
      " * Prec 78.790% \n",
      "best acc: 79.610000\n",
      "Epoch: [7][0/391]\tTime 0.380 (0.380)\tData 0.348 (0.348)\tLoss 1.0497 (1.0497)\tPrec 75.000% (75.000%)\n",
      "Epoch: [7][100/391]\tTime 0.046 (0.051)\tData 0.001 (0.005)\tLoss 0.8141 (0.8657)\tPrec 84.375% (83.950%)\n",
      "Epoch: [7][200/391]\tTime 0.053 (0.049)\tData 0.001 (0.003)\tLoss 0.8371 (0.8685)\tPrec 85.156% (84.049%)\n",
      "Epoch: [7][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.9103 (0.8728)\tPrec 83.594% (83.731%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.217 (0.217)\tLoss 0.8823 (0.8823)\tPrec 84.375% (84.375%)\n",
      " * Prec 82.020% \n",
      "best acc: 82.020000\n",
      "Epoch: [8][0/391]\tTime 0.325 (0.325)\tData 0.293 (0.293)\tLoss 0.8805 (0.8805)\tPrec 82.812% (82.812%)\n",
      "Epoch: [8][100/391]\tTime 0.051 (0.050)\tData 0.001 (0.004)\tLoss 0.9460 (0.8401)\tPrec 81.250% (85.009%)\n",
      "Epoch: [8][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.7924 (0.8460)\tPrec 87.500% (84.845%)\n",
      "Epoch: [8][300/391]\tTime 0.042 (0.048)\tData 0.001 (0.002)\tLoss 0.9758 (0.8475)\tPrec 79.688% (84.915%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.296 (0.296)\tLoss 0.8538 (0.8538)\tPrec 85.938% (85.938%)\n",
      " * Prec 82.350% \n",
      "best acc: 82.350000\n",
      "Epoch: [9][0/391]\tTime 0.368 (0.368)\tData 0.333 (0.333)\tLoss 0.8768 (0.8768)\tPrec 82.031% (82.031%)\n",
      "Epoch: [9][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.005)\tLoss 0.8462 (0.8240)\tPrec 84.375% (86.340%)\n",
      "Epoch: [9][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.8640 (0.8262)\tPrec 83.594% (86.023%)\n",
      "Epoch: [9][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.9485 (0.8278)\tPrec 78.906% (85.847%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.8406 (0.8406)\tPrec 85.938% (85.938%)\n",
      " * Prec 83.290% \n",
      "best acc: 83.290000\n",
      "Epoch: [10][0/391]\tTime 0.357 (0.357)\tData 0.326 (0.326)\tLoss 0.8995 (0.8995)\tPrec 81.250% (81.250%)\n",
      "Epoch: [10][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.7489 (0.8007)\tPrec 86.719% (86.757%)\n",
      "Epoch: [10][200/391]\tTime 0.050 (0.049)\tData 0.001 (0.003)\tLoss 0.8620 (0.8082)\tPrec 80.469% (86.629%)\n",
      "Epoch: [10][300/391]\tTime 0.044 (0.048)\tData 0.001 (0.002)\tLoss 0.7506 (0.8069)\tPrec 87.500% (86.633%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.185 (0.185)\tLoss 0.8594 (0.8594)\tPrec 85.156% (85.156%)\n",
      " * Prec 82.640% \n",
      "best acc: 83.290000\n",
      "Epoch: [11][0/391]\tTime 0.367 (0.367)\tData 0.334 (0.334)\tLoss 0.7645 (0.7645)\tPrec 87.500% (87.500%)\n",
      "Epoch: [11][100/391]\tTime 0.046 (0.051)\tData 0.001 (0.005)\tLoss 0.8249 (0.7848)\tPrec 86.719% (87.755%)\n",
      "Epoch: [11][200/391]\tTime 0.045 (0.049)\tData 0.001 (0.003)\tLoss 0.7422 (0.7894)\tPrec 89.062% (87.667%)\n",
      "Epoch: [11][300/391]\tTime 0.045 (0.048)\tData 0.001 (0.002)\tLoss 0.8313 (0.7912)\tPrec 88.281% (87.508%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.187 (0.187)\tLoss 0.7820 (0.7820)\tPrec 86.719% (86.719%)\n",
      " * Prec 81.690% \n",
      "best acc: 83.290000\n",
      "Epoch: [12][0/391]\tTime 0.371 (0.371)\tData 0.339 (0.339)\tLoss 0.7439 (0.7439)\tPrec 89.844% (89.844%)\n",
      "Epoch: [12][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.005)\tLoss 0.7493 (0.7751)\tPrec 89.062% (87.987%)\n",
      "Epoch: [12][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.9000 (0.7762)\tPrec 83.594% (87.920%)\n",
      "Epoch: [12][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.8374 (0.7804)\tPrec 86.719% (87.798%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.205 (0.205)\tLoss 0.8506 (0.8506)\tPrec 83.594% (83.594%)\n",
      " * Prec 82.540% \n",
      "best acc: 83.290000\n",
      "Epoch: [13][0/391]\tTime 0.366 (0.366)\tData 0.334 (0.334)\tLoss 0.8287 (0.8287)\tPrec 85.938% (85.938%)\n",
      "Epoch: [13][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.005)\tLoss 0.7967 (0.7661)\tPrec 87.500% (88.560%)\n",
      "Epoch: [13][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.8003 (0.7641)\tPrec 89.062% (88.771%)\n",
      "Epoch: [13][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.7921 (0.7620)\tPrec 87.500% (88.777%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.256 (0.256)\tLoss 0.8884 (0.8884)\tPrec 82.812% (82.812%)\n",
      " * Prec 81.550% \n",
      "best acc: 83.290000\n",
      "Epoch: [14][0/391]\tTime 0.348 (0.348)\tData 0.318 (0.318)\tLoss 0.7937 (0.7937)\tPrec 86.719% (86.719%)\n",
      "Epoch: [14][100/391]\tTime 0.044 (0.050)\tData 0.001 (0.004)\tLoss 0.7123 (0.7521)\tPrec 92.188% (89.109%)\n",
      "Epoch: [14][200/391]\tTime 0.045 (0.049)\tData 0.001 (0.003)\tLoss 0.8681 (0.7545)\tPrec 85.156% (89.109%)\n",
      "Epoch: [14][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.7737 (0.7560)\tPrec 88.281% (89.065%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.192 (0.192)\tLoss 0.7827 (0.7827)\tPrec 85.938% (85.938%)\n",
      " * Prec 83.780% \n",
      "best acc: 83.780000\n",
      "Epoch: [15][0/391]\tTime 0.212 (0.212)\tData 0.182 (0.182)\tLoss 0.7677 (0.7677)\tPrec 89.844% (89.844%)\n",
      "Epoch: [15][100/391]\tTime 0.049 (0.049)\tData 0.001 (0.003)\tLoss 0.7446 (0.7420)\tPrec 89.062% (89.519%)\n",
      "Epoch: [15][200/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.7899 (0.7457)\tPrec 88.281% (89.354%)\n",
      "Epoch: [15][300/391]\tTime 0.042 (0.048)\tData 0.001 (0.002)\tLoss 0.6926 (0.7447)\tPrec 91.406% (89.452%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.8117 (0.8117)\tPrec 86.719% (86.719%)\n",
      " * Prec 84.990% \n",
      "best acc: 84.990000\n",
      "Epoch: [16][0/391]\tTime 0.347 (0.347)\tData 0.286 (0.286)\tLoss 0.7631 (0.7631)\tPrec 89.062% (89.062%)\n",
      "Epoch: [16][100/391]\tTime 0.044 (0.050)\tData 0.001 (0.004)\tLoss 0.7394 (0.7281)\tPrec 90.625% (90.076%)\n",
      "Epoch: [16][200/391]\tTime 0.043 (0.049)\tData 0.001 (0.003)\tLoss 0.7170 (0.7299)\tPrec 92.188% (90.038%)\n",
      "Epoch: [16][300/391]\tTime 0.053 (0.048)\tData 0.001 (0.002)\tLoss 0.7416 (0.7331)\tPrec 90.625% (89.924%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.7474 (0.7474)\tPrec 88.281% (88.281%)\n",
      " * Prec 85.510% \n",
      "best acc: 85.510000\n",
      "Epoch: [17][0/391]\tTime 0.339 (0.339)\tData 0.309 (0.309)\tLoss 0.7717 (0.7717)\tPrec 86.719% (86.719%)\n",
      "Epoch: [17][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.7879 (0.7177)\tPrec 85.938% (90.625%)\n",
      "Epoch: [17][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.7579 (0.7181)\tPrec 92.188% (90.644%)\n",
      "Epoch: [17][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.8550 (0.7258)\tPrec 85.938% (90.251%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.7660 (0.7660)\tPrec 88.281% (88.281%)\n",
      " * Prec 85.660% \n",
      "best acc: 85.660000\n",
      "Epoch: [18][0/391]\tTime 0.339 (0.339)\tData 0.308 (0.308)\tLoss 0.6767 (0.6767)\tPrec 94.531% (94.531%)\n",
      "Epoch: [18][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.7117 (0.7079)\tPrec 91.406% (91.136%)\n",
      "Epoch: [18][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.8043 (0.7104)\tPrec 85.938% (90.940%)\n",
      "Epoch: [18][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.7411 (0.7138)\tPrec 90.625% (90.859%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.190 (0.190)\tLoss 0.7481 (0.7481)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.180% \n",
      "best acc: 86.180000\n",
      "Epoch: [19][0/391]\tTime 0.379 (0.379)\tData 0.316 (0.316)\tLoss 0.6194 (0.6194)\tPrec 95.312% (95.312%)\n",
      "Epoch: [19][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.004)\tLoss 0.7365 (0.6928)\tPrec 90.625% (91.553%)\n",
      "Epoch: [19][200/391]\tTime 0.046 (0.049)\tData 0.001 (0.003)\tLoss 0.6813 (0.6969)\tPrec 92.969% (91.395%)\n",
      "Epoch: [19][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.8208 (0.7005)\tPrec 85.156% (91.266%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.7712 (0.7712)\tPrec 85.938% (85.938%)\n",
      " * Prec 85.810% \n",
      "best acc: 86.180000\n",
      "Epoch: [20][0/391]\tTime 0.319 (0.319)\tData 0.288 (0.288)\tLoss 0.5909 (0.5909)\tPrec 97.656% (97.656%)\n",
      "Epoch: [20][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.004)\tLoss 0.6802 (0.6952)\tPrec 92.969% (91.600%)\n",
      "Epoch: [20][200/391]\tTime 0.053 (0.049)\tData 0.001 (0.003)\tLoss 0.7593 (0.6959)\tPrec 89.062% (91.527%)\n",
      "Epoch: [20][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.7032 (0.6960)\tPrec 90.625% (91.513%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.293 (0.293)\tLoss 0.7551 (0.7551)\tPrec 88.281% (88.281%)\n",
      " * Prec 85.910% \n",
      "best acc: 86.180000\n",
      "Epoch: [21][0/391]\tTime 0.355 (0.355)\tData 0.323 (0.323)\tLoss 0.6467 (0.6467)\tPrec 94.531% (94.531%)\n",
      "Epoch: [21][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.004)\tLoss 0.6884 (0.6832)\tPrec 90.625% (92.157%)\n",
      "Epoch: [21][200/391]\tTime 0.047 (0.049)\tData 0.004 (0.003)\tLoss 0.6737 (0.6898)\tPrec 92.969% (91.725%)\n",
      "Epoch: [21][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.8416 (0.6901)\tPrec 83.594% (91.801%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.301 (0.301)\tLoss 0.7232 (0.7232)\tPrec 89.844% (89.844%)\n",
      " * Prec 85.790% \n",
      "best acc: 86.180000\n",
      "Epoch: [22][0/391]\tTime 0.360 (0.360)\tData 0.329 (0.329)\tLoss 0.6739 (0.6739)\tPrec 92.969% (92.969%)\n",
      "Epoch: [22][100/391]\tTime 0.046 (0.050)\tData 0.001 (0.005)\tLoss 0.7070 (0.6779)\tPrec 91.406% (92.172%)\n",
      "Epoch: [22][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.6841 (0.6756)\tPrec 91.406% (92.300%)\n",
      "Epoch: [22][300/391]\tTime 0.049 (0.048)\tData 0.001 (0.002)\tLoss 0.6099 (0.6796)\tPrec 96.094% (92.221%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.7549 (0.7549)\tPrec 90.625% (90.625%)\n",
      " * Prec 86.230% \n",
      "best acc: 86.230000\n",
      "Epoch: [23][0/391]\tTime 0.368 (0.368)\tData 0.338 (0.338)\tLoss 0.7703 (0.7703)\tPrec 89.062% (89.062%)\n",
      "Epoch: [23][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.005)\tLoss 0.6928 (0.6656)\tPrec 91.406% (93.000%)\n",
      "Epoch: [23][200/391]\tTime 0.050 (0.049)\tData 0.001 (0.003)\tLoss 0.6401 (0.6687)\tPrec 95.312% (92.864%)\n",
      "Epoch: [23][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.6729 (0.6734)\tPrec 92.188% (92.538%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.7221 (0.7221)\tPrec 91.406% (91.406%)\n",
      " * Prec 86.840% \n",
      "best acc: 86.840000\n",
      "Epoch: [24][0/391]\tTime 0.356 (0.356)\tData 0.326 (0.326)\tLoss 0.6854 (0.6854)\tPrec 92.188% (92.188%)\n",
      "Epoch: [24][100/391]\tTime 0.049 (0.050)\tData 0.001 (0.005)\tLoss 0.6656 (0.6661)\tPrec 92.969% (92.930%)\n",
      "Epoch: [24][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.6274 (0.6655)\tPrec 93.750% (92.965%)\n",
      "Epoch: [24][300/391]\tTime 0.049 (0.048)\tData 0.001 (0.002)\tLoss 0.6021 (0.6669)\tPrec 96.875% (92.836%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.190 (0.190)\tLoss 0.6954 (0.6954)\tPrec 91.406% (91.406%)\n",
      " * Prec 86.730% \n",
      "best acc: 86.840000\n",
      "Epoch: [25][0/391]\tTime 0.395 (0.395)\tData 0.342 (0.342)\tLoss 0.6882 (0.6882)\tPrec 92.188% (92.188%)\n",
      "Epoch: [25][100/391]\tTime 0.051 (0.051)\tData 0.001 (0.005)\tLoss 0.6094 (0.6485)\tPrec 96.094% (93.619%)\n",
      "Epoch: [25][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.6007 (0.6565)\tPrec 96.875% (93.221%)\n",
      "Epoch: [25][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.6197 (0.6560)\tPrec 95.312% (93.298%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.7161 (0.7161)\tPrec 91.406% (91.406%)\n",
      " * Prec 86.710% \n",
      "best acc: 86.840000\n",
      "Epoch: [26][0/391]\tTime 0.337 (0.337)\tData 0.308 (0.308)\tLoss 0.6103 (0.6103)\tPrec 96.094% (96.094%)\n",
      "Epoch: [26][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5930 (0.6430)\tPrec 96.875% (93.912%)\n",
      "Epoch: [26][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.6685 (0.6499)\tPrec 92.969% (93.505%)\n",
      "Epoch: [26][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.6346 (0.6504)\tPrec 93.750% (93.457%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.292 (0.292)\tLoss 0.6833 (0.6833)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.320% \n",
      "best acc: 87.320000\n",
      "Epoch: [27][0/391]\tTime 0.294 (0.294)\tData 0.265 (0.265)\tLoss 0.7102 (0.7102)\tPrec 90.625% (90.625%)\n",
      "Epoch: [27][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.004)\tLoss 0.5803 (0.6436)\tPrec 98.438% (93.735%)\n",
      "Epoch: [27][200/391]\tTime 0.045 (0.048)\tData 0.001 (0.003)\tLoss 0.6077 (0.6424)\tPrec 97.656% (93.839%)\n",
      "Epoch: [27][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.6679 (0.6458)\tPrec 92.969% (93.727%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.183 (0.183)\tLoss 0.7628 (0.7628)\tPrec 90.625% (90.625%)\n",
      " * Prec 84.780% \n",
      "best acc: 87.320000\n",
      "Epoch: [28][0/391]\tTime 0.362 (0.362)\tData 0.327 (0.327)\tLoss 0.6629 (0.6629)\tPrec 92.188% (92.188%)\n",
      "Epoch: [28][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.6313 (0.6345)\tPrec 95.312% (94.106%)\n",
      "Epoch: [28][200/391]\tTime 0.042 (0.049)\tData 0.001 (0.003)\tLoss 0.6500 (0.6360)\tPrec 93.750% (94.146%)\n",
      "Epoch: [28][300/391]\tTime 0.051 (0.048)\tData 0.001 (0.002)\tLoss 0.6801 (0.6399)\tPrec 90.625% (94.010%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.188 (0.188)\tLoss 0.7315 (0.7315)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.720% \n",
      "best acc: 87.320000\n",
      "Epoch: [29][0/391]\tTime 0.361 (0.361)\tData 0.332 (0.332)\tLoss 0.6035 (0.6035)\tPrec 94.531% (94.531%)\n",
      "Epoch: [29][100/391]\tTime 0.048 (0.051)\tData 0.001 (0.005)\tLoss 0.6216 (0.6328)\tPrec 96.094% (94.114%)\n",
      "Epoch: [29][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.6148 (0.6343)\tPrec 96.875% (94.080%)\n",
      "Epoch: [29][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.6850 (0.6370)\tPrec 92.188% (93.965%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.181 (0.181)\tLoss 0.6509 (0.6509)\tPrec 93.750% (93.750%)\n",
      " * Prec 87.530% \n",
      "best acc: 87.530000\n",
      "Epoch: [30][0/391]\tTime 0.323 (0.323)\tData 0.291 (0.291)\tLoss 0.6271 (0.6271)\tPrec 94.531% (94.531%)\n",
      "Epoch: [30][100/391]\tTime 0.053 (0.050)\tData 0.001 (0.004)\tLoss 0.6675 (0.6259)\tPrec 92.969% (94.632%)\n",
      "Epoch: [30][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.6083 (0.6298)\tPrec 94.531% (94.473%)\n",
      "Epoch: [30][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.6481 (0.6315)\tPrec 92.188% (94.381%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.203 (0.203)\tLoss 0.6939 (0.6939)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.700% \n",
      "best acc: 87.700000\n",
      "Epoch: [31][0/391]\tTime 0.366 (0.366)\tData 0.330 (0.330)\tLoss 0.6239 (0.6239)\tPrec 93.750% (93.750%)\n",
      "Epoch: [31][100/391]\tTime 0.045 (0.051)\tData 0.001 (0.005)\tLoss 0.6266 (0.6183)\tPrec 95.312% (94.763%)\n",
      "Epoch: [31][200/391]\tTime 0.044 (0.049)\tData 0.001 (0.003)\tLoss 0.6108 (0.6232)\tPrec 95.312% (94.644%)\n",
      "Epoch: [31][300/391]\tTime 0.049 (0.048)\tData 0.001 (0.002)\tLoss 0.6351 (0.6247)\tPrec 95.312% (94.640%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.186 (0.186)\tLoss 0.7707 (0.7707)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.370% \n",
      "best acc: 87.700000\n",
      "Epoch: [32][0/391]\tTime 0.356 (0.356)\tData 0.327 (0.327)\tLoss 0.6137 (0.6137)\tPrec 95.312% (95.312%)\n",
      "Epoch: [32][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.005)\tLoss 0.5678 (0.6157)\tPrec 97.656% (95.096%)\n",
      "Epoch: [32][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.6650 (0.6194)\tPrec 92.969% (94.877%)\n",
      "Epoch: [32][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.6566 (0.6221)\tPrec 93.750% (94.744%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.7765 (0.7765)\tPrec 87.500% (87.500%)\n",
      " * Prec 87.300% \n",
      "best acc: 87.700000\n",
      "Epoch: [33][0/391]\tTime 0.364 (0.364)\tData 0.307 (0.307)\tLoss 0.6723 (0.6723)\tPrec 92.969% (92.969%)\n",
      "Epoch: [33][100/391]\tTime 0.041 (0.051)\tData 0.001 (0.004)\tLoss 0.6346 (0.6151)\tPrec 95.312% (95.073%)\n",
      "Epoch: [33][200/391]\tTime 0.044 (0.049)\tData 0.001 (0.003)\tLoss 0.6692 (0.6178)\tPrec 91.406% (94.862%)\n",
      "Epoch: [33][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.6136 (0.6171)\tPrec 95.312% (94.949%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.7044 (0.7044)\tPrec 90.625% (90.625%)\n",
      " * Prec 87.200% \n",
      "best acc: 87.700000\n",
      "Epoch: [34][0/391]\tTime 0.422 (0.422)\tData 0.392 (0.392)\tLoss 0.6713 (0.6713)\tPrec 92.969% (92.969%)\n",
      "Epoch: [34][100/391]\tTime 0.044 (0.051)\tData 0.001 (0.005)\tLoss 0.5831 (0.6034)\tPrec 96.094% (95.552%)\n",
      "Epoch: [34][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5835 (0.6060)\tPrec 96.875% (95.402%)\n",
      "Epoch: [34][300/391]\tTime 0.040 (0.049)\tData 0.001 (0.003)\tLoss 0.6350 (0.6096)\tPrec 96.094% (95.323%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.182 (0.182)\tLoss 0.7312 (0.7312)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.610% \n",
      "best acc: 87.700000\n",
      "Epoch: [35][0/391]\tTime 0.227 (0.227)\tData 0.195 (0.195)\tLoss 0.5993 (0.5993)\tPrec 97.656% (97.656%)\n",
      "Epoch: [35][100/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.6399 (0.6044)\tPrec 94.531% (95.421%)\n",
      "Epoch: [35][200/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.6106 (0.6048)\tPrec 94.531% (95.472%)\n",
      "Epoch: [35][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.6311 (0.6077)\tPrec 96.875% (95.333%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.181 (0.181)\tLoss 0.6611 (0.6611)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.560% \n",
      "best acc: 87.700000\n",
      "Epoch: [36][0/391]\tTime 0.359 (0.359)\tData 0.330 (0.330)\tLoss 0.6221 (0.6221)\tPrec 94.531% (94.531%)\n",
      "Epoch: [36][100/391]\tTime 0.050 (0.050)\tData 0.001 (0.005)\tLoss 0.6132 (0.5941)\tPrec 93.750% (95.947%)\n",
      "Epoch: [36][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5970 (0.5995)\tPrec 96.875% (95.802%)\n",
      "Epoch: [36][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5916 (0.6035)\tPrec 96.094% (95.606%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.186 (0.186)\tLoss 0.6710 (0.6710)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.850% \n",
      "best acc: 87.850000\n",
      "Epoch: [37][0/391]\tTime 0.386 (0.386)\tData 0.355 (0.355)\tLoss 0.6254 (0.6254)\tPrec 91.406% (91.406%)\n",
      "Epoch: [37][100/391]\tTime 0.040 (0.051)\tData 0.001 (0.005)\tLoss 0.5861 (0.5932)\tPrec 96.094% (95.931%)\n",
      "Epoch: [37][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5553 (0.5975)\tPrec 97.656% (95.783%)\n",
      "Epoch: [37][300/391]\tTime 0.049 (0.048)\tData 0.001 (0.003)\tLoss 0.6180 (0.6005)\tPrec 96.094% (95.632%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.186 (0.186)\tLoss 0.6424 (0.6424)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.370% \n",
      "best acc: 87.850000\n",
      "Epoch: [38][0/391]\tTime 0.355 (0.355)\tData 0.324 (0.324)\tLoss 0.5555 (0.5555)\tPrec 97.656% (97.656%)\n",
      "Epoch: [38][100/391]\tTime 0.044 (0.050)\tData 0.001 (0.005)\tLoss 0.6344 (0.5975)\tPrec 95.312% (96.086%)\n",
      "Epoch: [38][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.6058 (0.5980)\tPrec 96.094% (95.927%)\n",
      "Epoch: [38][300/391]\tTime 0.046 (0.048)\tData 0.001 (0.002)\tLoss 0.5917 (0.5988)\tPrec 96.875% (95.845%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.187 (0.187)\tLoss 0.6691 (0.6691)\tPrec 93.750% (93.750%)\n",
      " * Prec 87.800% \n",
      "best acc: 87.850000\n",
      "Epoch: [39][0/391]\tTime 0.387 (0.387)\tData 0.358 (0.358)\tLoss 0.5555 (0.5555)\tPrec 97.656% (97.656%)\n",
      "Epoch: [39][100/391]\tTime 0.048 (0.051)\tData 0.001 (0.005)\tLoss 0.5528 (0.5881)\tPrec 98.438% (96.233%)\n",
      "Epoch: [39][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5727 (0.5919)\tPrec 96.875% (96.035%)\n",
      "Epoch: [39][300/391]\tTime 0.049 (0.048)\tData 0.001 (0.003)\tLoss 0.6180 (0.5944)\tPrec 95.312% (95.951%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.7204 (0.7204)\tPrec 89.844% (89.844%)\n",
      " * Prec 88.020% \n",
      "best acc: 88.020000\n",
      "Epoch: [40][0/391]\tTime 0.333 (0.333)\tData 0.301 (0.301)\tLoss 0.5498 (0.5498)\tPrec 97.656% (97.656%)\n",
      "Epoch: [40][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.004)\tLoss 0.5747 (0.5886)\tPrec 97.656% (96.194%)\n",
      "Epoch: [40][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.6080 (0.5877)\tPrec 95.312% (96.276%)\n",
      "Epoch: [40][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.6121 (0.5881)\tPrec 95.312% (96.260%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.196 (0.196)\tLoss 0.7418 (0.7418)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.520% \n",
      "best acc: 88.020000\n",
      "Epoch: [41][0/391]\tTime 0.352 (0.352)\tData 0.319 (0.319)\tLoss 0.5711 (0.5711)\tPrec 97.656% (97.656%)\n",
      "Epoch: [41][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.004)\tLoss 0.5761 (0.5844)\tPrec 96.094% (96.473%)\n",
      "Epoch: [41][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5947 (0.5867)\tPrec 96.094% (96.362%)\n",
      "Epoch: [41][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5724 (0.5878)\tPrec 98.438% (96.358%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.194 (0.194)\tLoss 0.7600 (0.7600)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.820% \n",
      "best acc: 88.020000\n",
      "Epoch: [42][0/391]\tTime 0.355 (0.355)\tData 0.324 (0.324)\tLoss 0.5833 (0.5833)\tPrec 96.094% (96.094%)\n",
      "Epoch: [42][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.005)\tLoss 0.6565 (0.5847)\tPrec 93.750% (96.488%)\n",
      "Epoch: [42][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5877 (0.5858)\tPrec 96.875% (96.389%)\n",
      "Epoch: [42][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.5767 (0.5865)\tPrec 96.875% (96.395%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.171 (0.171)\tLoss 0.7179 (0.7179)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.540% \n",
      "best acc: 88.020000\n",
      "Epoch: [43][0/391]\tTime 0.407 (0.407)\tData 0.337 (0.337)\tLoss 0.5594 (0.5594)\tPrec 97.656% (97.656%)\n",
      "Epoch: [43][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.005)\tLoss 0.5551 (0.5813)\tPrec 97.656% (96.689%)\n",
      "Epoch: [43][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.6017 (0.5804)\tPrec 96.094% (96.653%)\n",
      "Epoch: [43][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.6031 (0.5815)\tPrec 94.531% (96.587%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.199 (0.199)\tLoss 0.7326 (0.7326)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.670% \n",
      "best acc: 88.020000\n",
      "Epoch: [44][0/391]\tTime 0.372 (0.372)\tData 0.342 (0.342)\tLoss 0.5797 (0.5797)\tPrec 96.094% (96.094%)\n",
      "Epoch: [44][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.005)\tLoss 0.6026 (0.5711)\tPrec 94.531% (96.968%)\n",
      "Epoch: [44][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5923 (0.5766)\tPrec 94.531% (96.766%)\n",
      "Epoch: [44][300/391]\tTime 0.049 (0.048)\tData 0.001 (0.002)\tLoss 0.5972 (0.5771)\tPrec 93.750% (96.735%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.7175 (0.7175)\tPrec 88.281% (88.281%)\n",
      " * Prec 88.350% \n",
      "best acc: 88.350000\n",
      "Epoch: [45][0/391]\tTime 0.406 (0.406)\tData 0.374 (0.374)\tLoss 0.6037 (0.6037)\tPrec 94.531% (94.531%)\n",
      "Epoch: [45][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.006)\tLoss 0.5380 (0.5734)\tPrec 98.438% (96.991%)\n",
      "Epoch: [45][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.004)\tLoss 0.5370 (0.5698)\tPrec 98.438% (97.143%)\n",
      "Epoch: [45][300/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.6171 (0.5731)\tPrec 92.969% (96.963%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.201 (0.201)\tLoss 0.6486 (0.6486)\tPrec 94.531% (94.531%)\n",
      " * Prec 87.940% \n",
      "best acc: 88.350000\n",
      "Epoch: [46][0/391]\tTime 0.351 (0.351)\tData 0.322 (0.322)\tLoss 0.5585 (0.5585)\tPrec 97.656% (97.656%)\n",
      "Epoch: [46][100/391]\tTime 0.050 (0.050)\tData 0.001 (0.004)\tLoss 0.5332 (0.5674)\tPrec 98.438% (97.068%)\n",
      "Epoch: [46][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5689 (0.5694)\tPrec 96.094% (96.988%)\n",
      "Epoch: [46][300/391]\tTime 0.050 (0.048)\tData 0.001 (0.002)\tLoss 0.5922 (0.5713)\tPrec 96.094% (96.937%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.7016 (0.7016)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.510% \n",
      "best acc: 88.350000\n",
      "Epoch: [47][0/391]\tTime 0.335 (0.335)\tData 0.305 (0.305)\tLoss 0.5890 (0.5890)\tPrec 96.875% (96.875%)\n",
      "Epoch: [47][100/391]\tTime 0.052 (0.050)\tData 0.001 (0.004)\tLoss 0.5519 (0.5656)\tPrec 98.438% (97.355%)\n",
      "Epoch: [47][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5605 (0.5661)\tPrec 96.094% (97.283%)\n",
      "Epoch: [47][300/391]\tTime 0.041 (0.048)\tData 0.001 (0.002)\tLoss 0.5698 (0.5679)\tPrec 96.094% (97.194%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.7777 (0.7777)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.550% \n",
      "best acc: 88.350000\n",
      "Epoch: [48][0/391]\tTime 0.349 (0.349)\tData 0.319 (0.319)\tLoss 0.5574 (0.5574)\tPrec 97.656% (97.656%)\n",
      "Epoch: [48][100/391]\tTime 0.042 (0.050)\tData 0.001 (0.004)\tLoss 0.5952 (0.5636)\tPrec 96.094% (97.300%)\n",
      "Epoch: [48][200/391]\tTime 0.051 (0.049)\tData 0.001 (0.003)\tLoss 0.5412 (0.5672)\tPrec 97.656% (97.139%)\n",
      "Epoch: [48][300/391]\tTime 0.046 (0.048)\tData 0.001 (0.002)\tLoss 0.6091 (0.5669)\tPrec 95.312% (97.184%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.7411 (0.7411)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.710% \n",
      "best acc: 88.350000\n",
      "Epoch: [49][0/391]\tTime 0.378 (0.378)\tData 0.325 (0.325)\tLoss 0.5752 (0.5752)\tPrec 96.875% (96.875%)\n",
      "Epoch: [49][100/391]\tTime 0.053 (0.051)\tData 0.001 (0.004)\tLoss 0.5651 (0.5620)\tPrec 98.438% (97.416%)\n",
      "Epoch: [49][200/391]\tTime 0.055 (0.049)\tData 0.001 (0.003)\tLoss 0.5553 (0.5620)\tPrec 98.438% (97.392%)\n",
      "Epoch: [49][300/391]\tTime 0.053 (0.048)\tData 0.001 (0.002)\tLoss 0.5506 (0.5624)\tPrec 96.875% (97.368%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.189 (0.189)\tLoss 0.6233 (0.6233)\tPrec 96.094% (96.094%)\n",
      " * Prec 88.150% \n",
      "best acc: 88.350000\n",
      "Epoch: [50][0/391]\tTime 0.360 (0.360)\tData 0.330 (0.330)\tLoss 0.5446 (0.5446)\tPrec 98.438% (98.438%)\n",
      "Epoch: [50][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.005)\tLoss 0.6177 (0.5588)\tPrec 95.312% (97.571%)\n",
      "Epoch: [50][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5326 (0.5587)\tPrec 98.438% (97.563%)\n",
      "Epoch: [50][300/391]\tTime 0.044 (0.048)\tData 0.001 (0.002)\tLoss 0.5298 (0.5598)\tPrec 99.219% (97.482%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.189 (0.189)\tLoss 0.6404 (0.6404)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.870% \n",
      "best acc: 88.870000\n",
      "Epoch: [51][0/391]\tTime 0.354 (0.354)\tData 0.323 (0.323)\tLoss 0.5526 (0.5526)\tPrec 98.438% (98.438%)\n",
      "Epoch: [51][100/391]\tTime 0.051 (0.050)\tData 0.001 (0.004)\tLoss 0.5738 (0.5593)\tPrec 96.875% (97.486%)\n",
      "Epoch: [51][200/391]\tTime 0.043 (0.049)\tData 0.001 (0.003)\tLoss 0.5836 (0.5600)\tPrec 96.875% (97.415%)\n",
      "Epoch: [51][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5166 (0.5616)\tPrec 99.219% (97.329%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.184 (0.184)\tLoss 0.6665 (0.6665)\tPrec 94.531% (94.531%)\n",
      " * Prec 88.450% \n",
      "best acc: 88.870000\n",
      "Epoch: [52][0/391]\tTime 0.359 (0.359)\tData 0.327 (0.327)\tLoss 0.5720 (0.5720)\tPrec 97.656% (97.656%)\n",
      "Epoch: [52][100/391]\tTime 0.053 (0.050)\tData 0.001 (0.005)\tLoss 0.5419 (0.5564)\tPrec 97.656% (97.718%)\n",
      "Epoch: [52][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5397 (0.5562)\tPrec 98.438% (97.753%)\n",
      "Epoch: [52][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5313 (0.5571)\tPrec 99.219% (97.680%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.7035 (0.7035)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.020% \n",
      "best acc: 88.870000\n",
      "Epoch: [53][0/391]\tTime 0.342 (0.342)\tData 0.307 (0.307)\tLoss 0.5174 (0.5174)\tPrec 100.000% (100.000%)\n",
      "Epoch: [53][100/391]\tTime 0.050 (0.050)\tData 0.001 (0.004)\tLoss 0.5751 (0.5517)\tPrec 96.875% (97.649%)\n",
      "Epoch: [53][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5362 (0.5530)\tPrec 98.438% (97.668%)\n",
      "Epoch: [53][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5426 (0.5540)\tPrec 98.438% (97.656%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.295 (0.295)\tLoss 0.6467 (0.6467)\tPrec 94.531% (94.531%)\n",
      " * Prec 88.230% \n",
      "best acc: 88.870000\n",
      "Epoch: [54][0/391]\tTime 0.388 (0.388)\tData 0.359 (0.359)\tLoss 0.5528 (0.5528)\tPrec 97.656% (97.656%)\n",
      "Epoch: [54][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.005)\tLoss 0.5623 (0.5518)\tPrec 98.438% (97.803%)\n",
      "Epoch: [54][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5885 (0.5523)\tPrec 96.094% (97.726%)\n",
      "Epoch: [54][300/391]\tTime 0.053 (0.048)\tData 0.001 (0.002)\tLoss 0.5918 (0.5535)\tPrec 95.312% (97.737%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.6985 (0.6985)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.280% \n",
      "best acc: 88.870000\n",
      "Epoch: [55][0/391]\tTime 0.368 (0.368)\tData 0.335 (0.335)\tLoss 0.5352 (0.5352)\tPrec 99.219% (99.219%)\n",
      "Epoch: [55][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.005)\tLoss 0.5199 (0.5465)\tPrec 99.219% (98.120%)\n",
      "Epoch: [55][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5168 (0.5475)\tPrec 100.000% (98.033%)\n",
      "Epoch: [55][300/391]\tTime 0.049 (0.048)\tData 0.001 (0.002)\tLoss 0.5479 (0.5501)\tPrec 96.875% (97.918%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.6538 (0.6538)\tPrec 93.750% (93.750%)\n",
      " * Prec 88.430% \n",
      "best acc: 88.870000\n",
      "Epoch: [56][0/391]\tTime 0.368 (0.368)\tData 0.336 (0.336)\tLoss 0.5155 (0.5155)\tPrec 99.219% (99.219%)\n",
      "Epoch: [56][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.005)\tLoss 0.5527 (0.5464)\tPrec 97.656% (98.089%)\n",
      "Epoch: [56][200/391]\tTime 0.046 (0.049)\tData 0.001 (0.003)\tLoss 0.5262 (0.5486)\tPrec 99.219% (97.952%)\n",
      "Epoch: [56][300/391]\tTime 0.048 (0.048)\tData 0.002 (0.002)\tLoss 0.5810 (0.5497)\tPrec 95.312% (97.921%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.182 (0.182)\tLoss 0.6607 (0.6607)\tPrec 92.969% (92.969%)\n",
      " * Prec 88.890% \n",
      "best acc: 88.890000\n",
      "Epoch: [57][0/391]\tTime 0.353 (0.353)\tData 0.322 (0.322)\tLoss 0.5511 (0.5511)\tPrec 97.656% (97.656%)\n",
      "Epoch: [57][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.004)\tLoss 0.5222 (0.5445)\tPrec 99.219% (98.144%)\n",
      "Epoch: [57][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5398 (0.5435)\tPrec 98.438% (98.204%)\n",
      "Epoch: [57][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5403 (0.5467)\tPrec 98.438% (98.077%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.279 (0.279)\tLoss 0.7062 (0.7062)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.340% \n",
      "best acc: 88.890000\n",
      "Epoch: [58][0/391]\tTime 0.351 (0.351)\tData 0.321 (0.321)\tLoss 0.6111 (0.6111)\tPrec 94.531% (94.531%)\n",
      "Epoch: [58][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.004)\tLoss 0.5208 (0.5416)\tPrec 99.219% (98.291%)\n",
      "Epoch: [58][200/391]\tTime 0.051 (0.049)\tData 0.001 (0.003)\tLoss 0.5134 (0.5441)\tPrec 100.000% (98.158%)\n",
      "Epoch: [58][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5430 (0.5462)\tPrec 99.219% (98.064%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.283 (0.283)\tLoss 0.6633 (0.6633)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.660% \n",
      "best acc: 88.890000\n",
      "Epoch: [59][0/391]\tTime 0.328 (0.328)\tData 0.299 (0.299)\tLoss 0.5528 (0.5528)\tPrec 98.438% (98.438%)\n",
      "Epoch: [59][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5354 (0.5404)\tPrec 98.438% (98.252%)\n",
      "Epoch: [59][200/391]\tTime 0.043 (0.049)\tData 0.001 (0.003)\tLoss 0.5831 (0.5411)\tPrec 96.094% (98.278%)\n",
      "Epoch: [59][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5201 (0.5428)\tPrec 99.219% (98.188%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.178 (0.178)\tLoss 0.7022 (0.7022)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.610% \n",
      "best acc: 88.890000\n",
      "Epoch: [60][0/391]\tTime 0.342 (0.342)\tData 0.311 (0.311)\tLoss 0.5248 (0.5248)\tPrec 99.219% (99.219%)\n",
      "Epoch: [60][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.004)\tLoss 0.5210 (0.5398)\tPrec 99.219% (98.283%)\n",
      "Epoch: [60][200/391]\tTime 0.052 (0.049)\tData 0.004 (0.003)\tLoss 0.5295 (0.5420)\tPrec 99.219% (98.228%)\n",
      "Epoch: [60][300/391]\tTime 0.041 (0.048)\tData 0.001 (0.002)\tLoss 0.5245 (0.5413)\tPrec 99.219% (98.261%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 0.6594 (0.6594)\tPrec 91.406% (91.406%)\n",
      " * Prec 88.590% \n",
      "best acc: 88.890000\n",
      "Epoch: [61][0/391]\tTime 0.391 (0.391)\tData 0.358 (0.358)\tLoss 0.5522 (0.5522)\tPrec 98.438% (98.438%)\n",
      "Epoch: [61][100/391]\tTime 0.038 (0.051)\tData 0.004 (0.005)\tLoss 0.5534 (0.5406)\tPrec 97.656% (98.329%)\n",
      "Epoch: [61][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5156 (0.5406)\tPrec 99.219% (98.333%)\n",
      "Epoch: [61][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5367 (0.5402)\tPrec 98.438% (98.354%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.188 (0.188)\tLoss 0.6760 (0.6760)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.250% \n",
      "best acc: 89.250000\n",
      "Epoch: [62][0/391]\tTime 0.389 (0.389)\tData 0.358 (0.358)\tLoss 0.5307 (0.5307)\tPrec 98.438% (98.438%)\n",
      "Epoch: [62][100/391]\tTime 0.048 (0.051)\tData 0.001 (0.005)\tLoss 0.5593 (0.5375)\tPrec 98.438% (98.422%)\n",
      "Epoch: [62][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5864 (0.5390)\tPrec 95.312% (98.356%)\n",
      "Epoch: [62][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.003)\tLoss 0.5372 (0.5403)\tPrec 96.875% (98.326%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.6503 (0.6503)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.300% \n",
      "best acc: 89.250000\n",
      "Epoch: [63][0/391]\tTime 0.356 (0.356)\tData 0.324 (0.324)\tLoss 0.5070 (0.5070)\tPrec 100.000% (100.000%)\n",
      "Epoch: [63][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.004)\tLoss 0.5530 (0.5378)\tPrec 96.875% (98.314%)\n",
      "Epoch: [63][200/391]\tTime 0.054 (0.049)\tData 0.001 (0.003)\tLoss 0.5422 (0.5378)\tPrec 98.438% (98.340%)\n",
      "Epoch: [63][300/391]\tTime 0.046 (0.048)\tData 0.001 (0.002)\tLoss 0.6118 (0.5386)\tPrec 96.094% (98.326%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.178 (0.178)\tLoss 0.6887 (0.6887)\tPrec 92.188% (92.188%)\n",
      " * Prec 88.590% \n",
      "best acc: 89.250000\n",
      "Epoch: [64][0/391]\tTime 0.339 (0.339)\tData 0.308 (0.308)\tLoss 0.5051 (0.5051)\tPrec 100.000% (100.000%)\n",
      "Epoch: [64][100/391]\tTime 0.041 (0.050)\tData 0.001 (0.004)\tLoss 0.5504 (0.5358)\tPrec 97.656% (98.654%)\n",
      "Epoch: [64][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5167 (0.5366)\tPrec 98.438% (98.562%)\n",
      "Epoch: [64][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.5622 (0.5381)\tPrec 97.656% (98.445%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.201 (0.201)\tLoss 0.6773 (0.6773)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.530% \n",
      "best acc: 89.530000\n",
      "Epoch: [65][0/391]\tTime 0.387 (0.387)\tData 0.354 (0.354)\tLoss 0.5205 (0.5205)\tPrec 99.219% (99.219%)\n",
      "Epoch: [65][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.005)\tLoss 0.5495 (0.5324)\tPrec 96.875% (98.677%)\n",
      "Epoch: [65][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5193 (0.5339)\tPrec 99.219% (98.612%)\n",
      "Epoch: [65][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.003)\tLoss 0.5253 (0.5346)\tPrec 99.219% (98.601%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.258 (0.258)\tLoss 0.6809 (0.6809)\tPrec 89.062% (89.062%)\n",
      " * Prec 88.970% \n",
      "best acc: 89.530000\n",
      "Epoch: [66][0/391]\tTime 0.363 (0.363)\tData 0.332 (0.332)\tLoss 0.5641 (0.5641)\tPrec 96.875% (96.875%)\n",
      "Epoch: [66][100/391]\tTime 0.043 (0.050)\tData 0.001 (0.005)\tLoss 0.5049 (0.5329)\tPrec 100.000% (98.700%)\n",
      "Epoch: [66][200/391]\tTime 0.043 (0.049)\tData 0.001 (0.003)\tLoss 0.5559 (0.5335)\tPrec 97.656% (98.651%)\n",
      "Epoch: [66][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5178 (0.5334)\tPrec 99.219% (98.640%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.6183 (0.6183)\tPrec 94.531% (94.531%)\n",
      " * Prec 88.750% \n",
      "best acc: 89.530000\n",
      "Epoch: [67][0/391]\tTime 0.356 (0.356)\tData 0.324 (0.324)\tLoss 0.5412 (0.5412)\tPrec 98.438% (98.438%)\n",
      "Epoch: [67][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.005)\tLoss 0.5701 (0.5317)\tPrec 97.656% (98.685%)\n",
      "Epoch: [67][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5123 (0.5346)\tPrec 100.000% (98.593%)\n",
      "Epoch: [67][300/391]\tTime 0.050 (0.048)\tData 0.001 (0.002)\tLoss 0.5059 (0.5342)\tPrec 100.000% (98.648%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.216 (0.216)\tLoss 0.6255 (0.6255)\tPrec 95.312% (95.312%)\n",
      " * Prec 89.420% \n",
      "best acc: 89.530000\n",
      "Epoch: [68][0/391]\tTime 0.350 (0.350)\tData 0.321 (0.321)\tLoss 0.5063 (0.5063)\tPrec 100.000% (100.000%)\n",
      "Epoch: [68][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5537 (0.5343)\tPrec 97.656% (98.561%)\n",
      "Epoch: [68][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5272 (0.5339)\tPrec 98.438% (98.574%)\n",
      "Epoch: [68][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5118 (0.5313)\tPrec 100.000% (98.702%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.6815 (0.6815)\tPrec 95.312% (95.312%)\n",
      " * Prec 89.530% \n",
      "best acc: 89.530000\n",
      "Epoch: [69][0/391]\tTime 0.358 (0.358)\tData 0.325 (0.325)\tLoss 0.5462 (0.5462)\tPrec 98.438% (98.438%)\n",
      "Epoch: [69][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.004)\tLoss 0.5188 (0.5297)\tPrec 99.219% (98.871%)\n",
      "Epoch: [69][200/391]\tTime 0.041 (0.049)\tData 0.001 (0.003)\tLoss 0.5357 (0.5283)\tPrec 98.438% (98.888%)\n",
      "Epoch: [69][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.5287 (0.5288)\tPrec 98.438% (98.840%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.194 (0.194)\tLoss 0.6164 (0.6164)\tPrec 95.312% (95.312%)\n",
      " * Prec 89.000% \n",
      "best acc: 89.530000\n",
      "Epoch: [70][0/391]\tTime 0.297 (0.297)\tData 0.269 (0.269)\tLoss 0.5233 (0.5233)\tPrec 99.219% (99.219%)\n",
      "Epoch: [70][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.004)\tLoss 0.5766 (0.5301)\tPrec 94.531% (98.778%)\n",
      "Epoch: [70][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5651 (0.5299)\tPrec 97.656% (98.838%)\n",
      "Epoch: [70][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5145 (0.5296)\tPrec 99.219% (98.809%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.180 (0.180)\tLoss 0.5761 (0.5761)\tPrec 96.875% (96.875%)\n",
      " * Prec 89.450% \n",
      "best acc: 89.530000\n",
      "Epoch: [71][0/391]\tTime 0.392 (0.392)\tData 0.327 (0.327)\tLoss 0.5100 (0.5100)\tPrec 100.000% (100.000%)\n",
      "Epoch: [71][100/391]\tTime 0.045 (0.051)\tData 0.001 (0.005)\tLoss 0.5129 (0.5328)\tPrec 99.219% (98.623%)\n",
      "Epoch: [71][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5476 (0.5304)\tPrec 98.438% (98.702%)\n",
      "Epoch: [71][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5494 (0.5312)\tPrec 96.094% (98.687%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.6319 (0.6319)\tPrec 94.531% (94.531%)\n",
      " * Prec 89.360% \n",
      "best acc: 89.530000\n",
      "Epoch: [72][0/391]\tTime 0.350 (0.350)\tData 0.322 (0.322)\tLoss 0.5120 (0.5120)\tPrec 99.219% (99.219%)\n",
      "Epoch: [72][100/391]\tTime 0.046 (0.050)\tData 0.001 (0.004)\tLoss 0.5356 (0.5236)\tPrec 99.219% (99.072%)\n",
      "Epoch: [72][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5097 (0.5260)\tPrec 100.000% (98.966%)\n",
      "Epoch: [72][300/391]\tTime 0.049 (0.048)\tData 0.001 (0.002)\tLoss 0.5342 (0.5262)\tPrec 97.656% (98.957%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 0.6994 (0.6994)\tPrec 90.625% (90.625%)\n",
      " * Prec 89.260% \n",
      "best acc: 89.530000\n",
      "Epoch: [73][0/391]\tTime 0.354 (0.354)\tData 0.321 (0.321)\tLoss 0.5093 (0.5093)\tPrec 100.000% (100.000%)\n",
      "Epoch: [73][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5103 (0.5254)\tPrec 100.000% (98.987%)\n",
      "Epoch: [73][200/391]\tTime 0.043 (0.049)\tData 0.001 (0.003)\tLoss 0.5356 (0.5252)\tPrec 99.219% (98.982%)\n",
      "Epoch: [73][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5242 (0.5264)\tPrec 99.219% (98.900%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.201 (0.201)\tLoss 0.6655 (0.6655)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.260% \n",
      "best acc: 89.530000\n",
      "Epoch: [74][0/391]\tTime 0.354 (0.354)\tData 0.323 (0.323)\tLoss 0.5458 (0.5458)\tPrec 97.656% (97.656%)\n",
      "Epoch: [74][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5467 (0.5246)\tPrec 98.438% (99.041%)\n",
      "Epoch: [74][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5292 (0.5248)\tPrec 98.438% (98.993%)\n",
      "Epoch: [74][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5241 (0.5250)\tPrec 99.219% (98.988%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.6627 (0.6627)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.620% \n",
      "best acc: 89.620000\n",
      "Epoch: [75][0/391]\tTime 0.389 (0.389)\tData 0.360 (0.360)\tLoss 0.5152 (0.5152)\tPrec 100.000% (100.000%)\n",
      "Epoch: [75][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.005)\tLoss 0.5335 (0.5255)\tPrec 98.438% (98.979%)\n",
      "Epoch: [75][200/391]\tTime 0.045 (0.049)\tData 0.001 (0.003)\tLoss 0.5575 (0.5267)\tPrec 97.656% (98.900%)\n",
      "Epoch: [75][300/391]\tTime 0.046 (0.048)\tData 0.001 (0.003)\tLoss 0.5554 (0.5267)\tPrec 96.875% (98.910%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.203 (0.203)\tLoss 0.6874 (0.6874)\tPrec 93.750% (93.750%)\n",
      " * Prec 89.530% \n",
      "best acc: 89.620000\n",
      "Epoch: [76][0/391]\tTime 0.325 (0.325)\tData 0.288 (0.288)\tLoss 0.5075 (0.5075)\tPrec 100.000% (100.000%)\n",
      "Epoch: [76][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5162 (0.5228)\tPrec 98.438% (99.095%)\n",
      "Epoch: [76][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5191 (0.5218)\tPrec 99.219% (99.172%)\n",
      "Epoch: [76][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5104 (0.5227)\tPrec 100.000% (99.146%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.190 (0.190)\tLoss 0.6409 (0.6409)\tPrec 93.750% (93.750%)\n",
      " * Prec 89.100% \n",
      "best acc: 89.620000\n",
      "Epoch: [77][0/391]\tTime 0.319 (0.319)\tData 0.285 (0.285)\tLoss 0.5175 (0.5175)\tPrec 100.000% (100.000%)\n",
      "Epoch: [77][100/391]\tTime 0.044 (0.050)\tData 0.001 (0.004)\tLoss 0.5107 (0.5209)\tPrec 100.000% (99.203%)\n",
      "Epoch: [77][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5172 (0.5218)\tPrec 99.219% (99.164%)\n",
      "Epoch: [77][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5670 (0.5222)\tPrec 96.875% (99.125%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.211 (0.211)\tLoss 0.7181 (0.7181)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.530% \n",
      "best acc: 89.620000\n",
      "Epoch: [78][0/391]\tTime 0.316 (0.316)\tData 0.286 (0.286)\tLoss 0.5117 (0.5117)\tPrec 100.000% (100.000%)\n",
      "Epoch: [78][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5166 (0.5215)\tPrec 99.219% (99.188%)\n",
      "Epoch: [78][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5114 (0.5209)\tPrec 99.219% (99.211%)\n",
      "Epoch: [78][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.5081 (0.5223)\tPrec 100.000% (99.131%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.184 (0.184)\tLoss 0.7032 (0.7032)\tPrec 93.750% (93.750%)\n",
      " * Prec 89.910% \n",
      "best acc: 89.910000\n",
      "Epoch: [79][0/391]\tTime 0.282 (0.282)\tData 0.218 (0.218)\tLoss 0.5100 (0.5100)\tPrec 99.219% (99.219%)\n",
      "Epoch: [79][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.003)\tLoss 0.5081 (0.5222)\tPrec 100.000% (99.149%)\n",
      "Epoch: [79][200/391]\tTime 0.052 (0.049)\tData 0.001 (0.002)\tLoss 0.5121 (0.5210)\tPrec 100.000% (99.192%)\n",
      "Epoch: [79][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5155 (0.5206)\tPrec 99.219% (99.188%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.192 (0.192)\tLoss 0.6408 (0.6408)\tPrec 93.750% (93.750%)\n",
      " * Prec 89.260% \n",
      "best acc: 89.910000\n",
      "Epoch: [80][0/391]\tTime 0.382 (0.382)\tData 0.324 (0.324)\tLoss 0.5169 (0.5169)\tPrec 99.219% (99.219%)\n",
      "Epoch: [80][100/391]\tTime 0.043 (0.051)\tData 0.001 (0.005)\tLoss 0.5156 (0.5208)\tPrec 99.219% (99.188%)\n",
      "Epoch: [80][200/391]\tTime 0.046 (0.049)\tData 0.001 (0.003)\tLoss 0.5239 (0.5199)\tPrec 99.219% (99.242%)\n",
      "Epoch: [80][300/391]\tTime 0.050 (0.048)\tData 0.001 (0.002)\tLoss 0.5089 (0.5208)\tPrec 100.000% (99.169%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.220 (0.220)\tLoss 0.6595 (0.6595)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.310% \n",
      "best acc: 89.910000\n",
      "Epoch: [81][0/391]\tTime 0.399 (0.399)\tData 0.368 (0.368)\tLoss 0.5299 (0.5299)\tPrec 99.219% (99.219%)\n",
      "Epoch: [81][100/391]\tTime 0.046 (0.051)\tData 0.001 (0.005)\tLoss 0.5304 (0.5191)\tPrec 99.219% (99.242%)\n",
      "Epoch: [81][200/391]\tTime 0.042 (0.049)\tData 0.001 (0.003)\tLoss 0.5184 (0.5187)\tPrec 99.219% (99.250%)\n",
      "Epoch: [81][300/391]\tTime 0.042 (0.049)\tData 0.001 (0.003)\tLoss 0.5118 (0.5191)\tPrec 100.000% (99.232%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.225 (0.225)\tLoss 0.5886 (0.5886)\tPrec 95.312% (95.312%)\n",
      " * Prec 89.230% \n",
      "best acc: 89.910000\n",
      "Epoch: [82][0/391]\tTime 0.336 (0.336)\tData 0.307 (0.307)\tLoss 0.5330 (0.5330)\tPrec 99.219% (99.219%)\n",
      "Epoch: [82][100/391]\tTime 0.044 (0.050)\tData 0.001 (0.004)\tLoss 0.5028 (0.5187)\tPrec 100.000% (99.312%)\n",
      "Epoch: [82][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5294 (0.5184)\tPrec 99.219% (99.339%)\n",
      "Epoch: [82][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5088 (0.5182)\tPrec 100.000% (99.356%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.185 (0.185)\tLoss 0.6629 (0.6629)\tPrec 93.750% (93.750%)\n",
      " * Prec 89.640% \n",
      "best acc: 89.910000\n",
      "Epoch: [83][0/391]\tTime 0.391 (0.391)\tData 0.362 (0.362)\tLoss 0.5213 (0.5213)\tPrec 99.219% (99.219%)\n",
      "Epoch: [83][100/391]\tTime 0.048 (0.051)\tData 0.001 (0.005)\tLoss 0.5282 (0.5203)\tPrec 98.438% (99.172%)\n",
      "Epoch: [83][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5302 (0.5185)\tPrec 98.438% (99.277%)\n",
      "Epoch: [83][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.003)\tLoss 0.5058 (0.5179)\tPrec 100.000% (99.302%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.193 (0.193)\tLoss 0.6606 (0.6606)\tPrec 95.312% (95.312%)\n",
      " * Prec 89.240% \n",
      "best acc: 89.910000\n",
      "Epoch: [84][0/391]\tTime 0.432 (0.432)\tData 0.398 (0.398)\tLoss 0.5037 (0.5037)\tPrec 100.000% (100.000%)\n",
      "Epoch: [84][100/391]\tTime 0.044 (0.051)\tData 0.001 (0.005)\tLoss 0.5108 (0.5161)\tPrec 100.000% (99.366%)\n",
      "Epoch: [84][200/391]\tTime 0.051 (0.049)\tData 0.001 (0.003)\tLoss 0.5148 (0.5169)\tPrec 100.000% (99.320%)\n",
      "Epoch: [84][300/391]\tTime 0.051 (0.049)\tData 0.001 (0.003)\tLoss 0.5217 (0.5166)\tPrec 99.219% (99.369%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.199 (0.199)\tLoss 0.6676 (0.6676)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.510% \n",
      "best acc: 89.910000\n",
      "Epoch: [85][0/391]\tTime 0.361 (0.361)\tData 0.327 (0.327)\tLoss 0.5020 (0.5020)\tPrec 100.000% (100.000%)\n",
      "Epoch: [85][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.004)\tLoss 0.5070 (0.5151)\tPrec 100.000% (99.358%)\n",
      "Epoch: [85][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5264 (0.5156)\tPrec 98.438% (99.347%)\n",
      "Epoch: [85][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5117 (0.5163)\tPrec 99.219% (99.323%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.6961 (0.6961)\tPrec 92.188% (92.188%)\n",
      " * Prec 89.780% \n",
      "best acc: 89.910000\n",
      "Epoch: [86][0/391]\tTime 0.332 (0.332)\tData 0.303 (0.303)\tLoss 0.5326 (0.5326)\tPrec 99.219% (99.219%)\n",
      "Epoch: [86][100/391]\tTime 0.043 (0.050)\tData 0.001 (0.004)\tLoss 0.5293 (0.5196)\tPrec 99.219% (99.226%)\n",
      "Epoch: [86][200/391]\tTime 0.050 (0.049)\tData 0.001 (0.003)\tLoss 0.5120 (0.5171)\tPrec 100.000% (99.366%)\n",
      "Epoch: [86][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.5358 (0.5171)\tPrec 99.219% (99.359%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.179 (0.179)\tLoss 0.6099 (0.6099)\tPrec 95.312% (95.312%)\n",
      " * Prec 89.940% \n",
      "best acc: 89.940000\n",
      "Epoch: [87][0/391]\tTime 0.364 (0.364)\tData 0.330 (0.330)\tLoss 0.5031 (0.5031)\tPrec 100.000% (100.000%)\n",
      "Epoch: [87][100/391]\tTime 0.044 (0.050)\tData 0.001 (0.005)\tLoss 0.5193 (0.5144)\tPrec 98.438% (99.459%)\n",
      "Epoch: [87][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5059 (0.5144)\tPrec 100.000% (99.456%)\n",
      "Epoch: [87][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.5085 (0.5147)\tPrec 99.219% (99.439%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.186 (0.186)\tLoss 0.6685 (0.6685)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.960% \n",
      "best acc: 89.960000\n",
      "Epoch: [88][0/391]\tTime 0.331 (0.331)\tData 0.300 (0.300)\tLoss 0.5088 (0.5088)\tPrec 100.000% (100.000%)\n",
      "Epoch: [88][100/391]\tTime 0.046 (0.050)\tData 0.001 (0.004)\tLoss 0.5229 (0.5126)\tPrec 99.219% (99.590%)\n",
      "Epoch: [88][200/391]\tTime 0.042 (0.049)\tData 0.001 (0.003)\tLoss 0.5045 (0.5128)\tPrec 100.000% (99.545%)\n",
      "Epoch: [88][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.5214 (0.5133)\tPrec 99.219% (99.522%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.206 (0.206)\tLoss 0.6233 (0.6233)\tPrec 95.312% (95.312%)\n",
      " * Prec 89.660% \n",
      "best acc: 89.960000\n",
      "Epoch: [89][0/391]\tTime 0.352 (0.352)\tData 0.321 (0.321)\tLoss 0.5138 (0.5138)\tPrec 99.219% (99.219%)\n",
      "Epoch: [89][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5239 (0.5146)\tPrec 99.219% (99.544%)\n",
      "Epoch: [89][200/391]\tTime 0.054 (0.049)\tData 0.001 (0.003)\tLoss 0.5279 (0.5146)\tPrec 99.219% (99.510%)\n",
      "Epoch: [89][300/391]\tTime 0.046 (0.048)\tData 0.001 (0.002)\tLoss 0.5029 (0.5144)\tPrec 100.000% (99.499%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.176 (0.176)\tLoss 0.6573 (0.6573)\tPrec 92.969% (92.969%)\n",
      " * Prec 89.770% \n",
      "best acc: 89.960000\n",
      "Epoch: [90][0/391]\tTime 0.322 (0.322)\tData 0.292 (0.292)\tLoss 0.5166 (0.5166)\tPrec 99.219% (99.219%)\n",
      "Epoch: [90][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.004)\tLoss 0.5112 (0.5150)\tPrec 99.219% (99.404%)\n",
      "Epoch: [90][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5080 (0.5142)\tPrec 100.000% (99.464%)\n",
      "Epoch: [90][300/391]\tTime 0.046 (0.048)\tData 0.001 (0.002)\tLoss 0.5221 (0.5139)\tPrec 99.219% (99.489%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.6161 (0.6161)\tPrec 95.312% (95.312%)\n",
      " * Prec 89.780% \n",
      "best acc: 89.960000\n",
      "Epoch: [91][0/391]\tTime 0.354 (0.354)\tData 0.322 (0.322)\tLoss 0.5034 (0.5034)\tPrec 100.000% (100.000%)\n",
      "Epoch: [91][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.005)\tLoss 0.5047 (0.5133)\tPrec 100.000% (99.489%)\n",
      "Epoch: [91][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5075 (0.5132)\tPrec 100.000% (99.526%)\n",
      "Epoch: [91][300/391]\tTime 0.041 (0.048)\tData 0.001 (0.002)\tLoss 0.5208 (0.5133)\tPrec 99.219% (99.512%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.287 (0.287)\tLoss 0.5998 (0.5998)\tPrec 96.094% (96.094%)\n",
      " * Prec 89.740% \n",
      "best acc: 89.960000\n",
      "Epoch: [92][0/391]\tTime 0.362 (0.362)\tData 0.330 (0.330)\tLoss 0.5056 (0.5056)\tPrec 100.000% (100.000%)\n",
      "Epoch: [92][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.004)\tLoss 0.5192 (0.5118)\tPrec 99.219% (99.559%)\n",
      "Epoch: [92][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5101 (0.5124)\tPrec 100.000% (99.541%)\n",
      "Epoch: [92][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5155 (0.5124)\tPrec 99.219% (99.548%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.125 (0.125)\tLoss 0.6286 (0.6286)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.100% \n",
      "best acc: 90.100000\n",
      "Epoch: [93][0/391]\tTime 0.340 (0.340)\tData 0.309 (0.309)\tLoss 0.5116 (0.5116)\tPrec 99.219% (99.219%)\n",
      "Epoch: [93][100/391]\tTime 0.044 (0.050)\tData 0.001 (0.004)\tLoss 0.5060 (0.5125)\tPrec 100.000% (99.528%)\n",
      "Epoch: [93][200/391]\tTime 0.051 (0.049)\tData 0.001 (0.003)\tLoss 0.5274 (0.5130)\tPrec 98.438% (99.518%)\n",
      "Epoch: [93][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.5303 (0.5131)\tPrec 99.219% (99.515%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.202 (0.202)\tLoss 0.6056 (0.6056)\tPrec 96.094% (96.094%)\n",
      " * Prec 90.060% \n",
      "best acc: 90.100000\n",
      "Epoch: [94][0/391]\tTime 0.340 (0.340)\tData 0.308 (0.308)\tLoss 0.5019 (0.5019)\tPrec 100.000% (100.000%)\n",
      "Epoch: [94][100/391]\tTime 0.046 (0.050)\tData 0.001 (0.004)\tLoss 0.5231 (0.5103)\tPrec 99.219% (99.590%)\n",
      "Epoch: [94][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5091 (0.5101)\tPrec 99.219% (99.639%)\n",
      "Epoch: [94][300/391]\tTime 0.042 (0.048)\tData 0.001 (0.002)\tLoss 0.5035 (0.5108)\tPrec 100.000% (99.595%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.6103 (0.6103)\tPrec 96.094% (96.094%)\n",
      " * Prec 89.810% \n",
      "best acc: 90.100000\n",
      "Epoch: [95][0/391]\tTime 0.343 (0.343)\tData 0.312 (0.312)\tLoss 0.5071 (0.5071)\tPrec 100.000% (100.000%)\n",
      "Epoch: [95][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5084 (0.5117)\tPrec 100.000% (99.575%)\n",
      "Epoch: [95][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5049 (0.5115)\tPrec 100.000% (99.588%)\n",
      "Epoch: [95][300/391]\tTime 0.045 (0.048)\tData 0.001 (0.002)\tLoss 0.5280 (0.5115)\tPrec 99.219% (99.598%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.222 (0.222)\tLoss 0.6170 (0.6170)\tPrec 94.531% (94.531%)\n",
      " * Prec 89.610% \n",
      "best acc: 90.100000\n",
      "Epoch: [96][0/391]\tTime 0.475 (0.475)\tData 0.445 (0.445)\tLoss 0.5021 (0.5021)\tPrec 100.000% (100.000%)\n",
      "Epoch: [96][100/391]\tTime 0.046 (0.052)\tData 0.001 (0.006)\tLoss 0.5115 (0.5123)\tPrec 100.000% (99.567%)\n",
      "Epoch: [96][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.004)\tLoss 0.5126 (0.5129)\tPrec 99.219% (99.530%)\n",
      "Epoch: [96][300/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5193 (0.5124)\tPrec 99.219% (99.554%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.190 (0.190)\tLoss 0.6085 (0.6085)\tPrec 95.312% (95.312%)\n",
      " * Prec 89.850% \n",
      "best acc: 90.100000\n",
      "Epoch: [97][0/391]\tTime 0.351 (0.351)\tData 0.321 (0.321)\tLoss 0.5058 (0.5058)\tPrec 100.000% (100.000%)\n",
      "Epoch: [97][100/391]\tTime 0.048 (0.051)\tData 0.001 (0.004)\tLoss 0.5078 (0.5099)\tPrec 100.000% (99.683%)\n",
      "Epoch: [97][200/391]\tTime 0.050 (0.049)\tData 0.001 (0.003)\tLoss 0.5195 (0.5099)\tPrec 98.438% (99.674%)\n",
      "Epoch: [97][300/391]\tTime 0.044 (0.048)\tData 0.001 (0.002)\tLoss 0.5320 (0.5100)\tPrec 99.219% (99.655%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.187 (0.187)\tLoss 0.6096 (0.6096)\tPrec 96.094% (96.094%)\n",
      " * Prec 89.920% \n",
      "best acc: 90.100000\n",
      "Epoch: [98][0/391]\tTime 0.367 (0.367)\tData 0.332 (0.332)\tLoss 0.5048 (0.5048)\tPrec 100.000% (100.000%)\n",
      "Epoch: [98][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.005)\tLoss 0.5031 (0.5089)\tPrec 100.000% (99.745%)\n",
      "Epoch: [98][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5042 (0.5089)\tPrec 100.000% (99.747%)\n",
      "Epoch: [98][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5150 (0.5092)\tPrec 99.219% (99.720%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.196 (0.196)\tLoss 0.6215 (0.6215)\tPrec 96.094% (96.094%)\n",
      " * Prec 90.240% \n",
      "best acc: 90.240000\n",
      "Epoch: [99][0/391]\tTime 0.342 (0.342)\tData 0.310 (0.310)\tLoss 0.5031 (0.5031)\tPrec 100.000% (100.000%)\n",
      "Epoch: [99][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5023 (0.5116)\tPrec 100.000% (99.606%)\n",
      "Epoch: [99][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5023 (0.5111)\tPrec 100.000% (99.607%)\n",
      "Epoch: [99][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.5034 (0.5111)\tPrec 100.000% (99.603%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.215 (0.215)\tLoss 0.5630 (0.5630)\tPrec 97.656% (97.656%)\n",
      " * Prec 90.210% \n",
      "best acc: 90.240000\n",
      "Epoch: [100][0/391]\tTime 0.371 (0.371)\tData 0.340 (0.340)\tLoss 0.5036 (0.5036)\tPrec 100.000% (100.000%)\n",
      "Epoch: [100][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.005)\tLoss 0.5046 (0.5090)\tPrec 100.000% (99.706%)\n",
      "Epoch: [100][200/391]\tTime 0.045 (0.049)\tData 0.001 (0.003)\tLoss 0.5016 (0.5097)\tPrec 100.000% (99.646%)\n",
      "Epoch: [100][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5029 (0.5098)\tPrec 100.000% (99.660%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.198 (0.198)\tLoss 0.5657 (0.5657)\tPrec 97.656% (97.656%)\n",
      " * Prec 89.820% \n",
      "best acc: 90.240000\n",
      "Epoch: [101][0/391]\tTime 0.378 (0.378)\tData 0.347 (0.347)\tLoss 0.5134 (0.5134)\tPrec 99.219% (99.219%)\n",
      "Epoch: [101][100/391]\tTime 0.046 (0.050)\tData 0.001 (0.005)\tLoss 0.5080 (0.5100)\tPrec 100.000% (99.683%)\n",
      "Epoch: [101][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5091 (0.5099)\tPrec 100.000% (99.666%)\n",
      "Epoch: [101][300/391]\tTime 0.050 (0.048)\tData 0.001 (0.002)\tLoss 0.5151 (0.5101)\tPrec 99.219% (99.650%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.192 (0.192)\tLoss 0.6045 (0.6045)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.040% \n",
      "best acc: 90.240000\n",
      "Epoch: [102][0/391]\tTime 0.349 (0.349)\tData 0.318 (0.318)\tLoss 0.5038 (0.5038)\tPrec 100.000% (100.000%)\n",
      "Epoch: [102][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5018 (0.5099)\tPrec 100.000% (99.667%)\n",
      "Epoch: [102][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5163 (0.5102)\tPrec 99.219% (99.658%)\n",
      "Epoch: [102][300/391]\tTime 0.045 (0.048)\tData 0.001 (0.002)\tLoss 0.5053 (0.5099)\tPrec 100.000% (99.660%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.194 (0.194)\tLoss 0.6076 (0.6076)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.330% \n",
      "best acc: 90.330000\n",
      "Epoch: [103][0/391]\tTime 0.464 (0.464)\tData 0.433 (0.433)\tLoss 0.5019 (0.5019)\tPrec 100.000% (100.000%)\n",
      "Epoch: [103][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.006)\tLoss 0.5035 (0.5092)\tPrec 100.000% (99.714%)\n",
      "Epoch: [103][200/391]\tTime 0.045 (0.049)\tData 0.001 (0.003)\tLoss 0.5017 (0.5086)\tPrec 100.000% (99.743%)\n",
      "Epoch: [103][300/391]\tTime 0.045 (0.049)\tData 0.001 (0.003)\tLoss 0.5201 (0.5086)\tPrec 99.219% (99.735%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.201 (0.201)\tLoss 0.5916 (0.5916)\tPrec 96.875% (96.875%)\n",
      " * Prec 89.840% \n",
      "best acc: 90.330000\n",
      "Epoch: [104][0/391]\tTime 0.290 (0.290)\tData 0.262 (0.262)\tLoss 0.5027 (0.5027)\tPrec 100.000% (100.000%)\n",
      "Epoch: [104][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5202 (0.5095)\tPrec 99.219% (99.714%)\n",
      "Epoch: [104][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5025 (0.5092)\tPrec 100.000% (99.685%)\n",
      "Epoch: [104][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.5052 (0.5090)\tPrec 100.000% (99.702%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.186 (0.186)\tLoss 0.5814 (0.5814)\tPrec 96.875% (96.875%)\n",
      " * Prec 89.840% \n",
      "best acc: 90.330000\n",
      "Epoch: [105][0/391]\tTime 0.465 (0.465)\tData 0.434 (0.434)\tLoss 0.5018 (0.5018)\tPrec 100.000% (100.000%)\n",
      "Epoch: [105][100/391]\tTime 0.044 (0.051)\tData 0.001 (0.006)\tLoss 0.5022 (0.5082)\tPrec 100.000% (99.760%)\n",
      "Epoch: [105][200/391]\tTime 0.046 (0.049)\tData 0.001 (0.003)\tLoss 0.5019 (0.5084)\tPrec 100.000% (99.724%)\n",
      "Epoch: [105][300/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5105 (0.5087)\tPrec 99.219% (99.707%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.179 (0.179)\tLoss 0.6086 (0.6086)\tPrec 95.312% (95.312%)\n",
      " * Prec 89.980% \n",
      "best acc: 90.330000\n",
      "Epoch: [106][0/391]\tTime 0.417 (0.417)\tData 0.388 (0.388)\tLoss 0.5041 (0.5041)\tPrec 100.000% (100.000%)\n",
      "Epoch: [106][100/391]\tTime 0.048 (0.051)\tData 0.001 (0.005)\tLoss 0.5212 (0.5087)\tPrec 99.219% (99.675%)\n",
      "Epoch: [106][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5158 (0.5083)\tPrec 98.438% (99.689%)\n",
      "Epoch: [106][300/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5063 (0.5085)\tPrec 100.000% (99.707%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.214 (0.214)\tLoss 0.6169 (0.6169)\tPrec 95.312% (95.312%)\n",
      " * Prec 89.810% \n",
      "best acc: 90.330000\n",
      "Epoch: [107][0/391]\tTime 0.337 (0.337)\tData 0.305 (0.305)\tLoss 0.5099 (0.5099)\tPrec 100.000% (100.000%)\n",
      "Epoch: [107][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5061 (0.5078)\tPrec 100.000% (99.729%)\n",
      "Epoch: [107][200/391]\tTime 0.046 (0.049)\tData 0.001 (0.003)\tLoss 0.5093 (0.5081)\tPrec 99.219% (99.716%)\n",
      "Epoch: [107][300/391]\tTime 0.045 (0.048)\tData 0.001 (0.002)\tLoss 0.5032 (0.5077)\tPrec 100.000% (99.738%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.187 (0.187)\tLoss 0.6010 (0.6010)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.320% \n",
      "best acc: 90.330000\n",
      "Epoch: [108][0/391]\tTime 0.398 (0.398)\tData 0.364 (0.364)\tLoss 0.5024 (0.5024)\tPrec 100.000% (100.000%)\n",
      "Epoch: [108][100/391]\tTime 0.048 (0.051)\tData 0.001 (0.005)\tLoss 0.5022 (0.5074)\tPrec 100.000% (99.783%)\n",
      "Epoch: [108][200/391]\tTime 0.044 (0.049)\tData 0.001 (0.003)\tLoss 0.5088 (0.5080)\tPrec 100.000% (99.759%)\n",
      "Epoch: [108][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5027 (0.5079)\tPrec 100.000% (99.735%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.131 (0.131)\tLoss 0.5942 (0.5942)\tPrec 96.875% (96.875%)\n",
      " * Prec 89.900% \n",
      "best acc: 90.330000\n",
      "Epoch: [109][0/391]\tTime 0.328 (0.328)\tData 0.297 (0.297)\tLoss 0.5022 (0.5022)\tPrec 100.000% (100.000%)\n",
      "Epoch: [109][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5016 (0.5075)\tPrec 100.000% (99.768%)\n",
      "Epoch: [109][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5050 (0.5070)\tPrec 100.000% (99.813%)\n",
      "Epoch: [109][300/391]\tTime 0.049 (0.048)\tData 0.001 (0.002)\tLoss 0.5013 (0.5070)\tPrec 100.000% (99.790%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.204 (0.204)\tLoss 0.5767 (0.5767)\tPrec 97.656% (97.656%)\n",
      " * Prec 90.250% \n",
      "best acc: 90.330000\n",
      "Epoch: [110][0/391]\tTime 0.339 (0.339)\tData 0.310 (0.310)\tLoss 0.5107 (0.5107)\tPrec 99.219% (99.219%)\n",
      "Epoch: [110][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5016 (0.5067)\tPrec 100.000% (99.799%)\n",
      "Epoch: [110][200/391]\tTime 0.049 (0.049)\tData 0.001 (0.003)\tLoss 0.5217 (0.5071)\tPrec 99.219% (99.782%)\n",
      "Epoch: [110][300/391]\tTime 0.045 (0.048)\tData 0.001 (0.002)\tLoss 0.5016 (0.5070)\tPrec 100.000% (99.782%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.6048 (0.6048)\tPrec 96.094% (96.094%)\n",
      " * Prec 90.090% \n",
      "best acc: 90.330000\n",
      "Epoch: [111][0/391]\tTime 0.383 (0.383)\tData 0.346 (0.346)\tLoss 0.5022 (0.5022)\tPrec 100.000% (100.000%)\n",
      "Epoch: [111][100/391]\tTime 0.054 (0.051)\tData 0.001 (0.005)\tLoss 0.5127 (0.5069)\tPrec 99.219% (99.752%)\n",
      "Epoch: [111][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5446 (0.5072)\tPrec 98.438% (99.743%)\n",
      "Epoch: [111][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5075 (0.5071)\tPrec 100.000% (99.756%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.208 (0.208)\tLoss 0.5972 (0.5972)\tPrec 96.875% (96.875%)\n",
      " * Prec 90.230% \n",
      "best acc: 90.330000\n",
      "Epoch: [112][0/391]\tTime 0.326 (0.326)\tData 0.296 (0.296)\tLoss 0.5025 (0.5025)\tPrec 100.000% (100.000%)\n",
      "Epoch: [112][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5018 (0.5062)\tPrec 100.000% (99.807%)\n",
      "Epoch: [112][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5024 (0.5068)\tPrec 100.000% (99.802%)\n",
      "Epoch: [112][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.5059 (0.5071)\tPrec 100.000% (99.779%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.188 (0.188)\tLoss 0.6343 (0.6343)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.080% \n",
      "best acc: 90.330000\n",
      "Epoch: [113][0/391]\tTime 0.376 (0.376)\tData 0.343 (0.343)\tLoss 0.5025 (0.5025)\tPrec 100.000% (100.000%)\n",
      "Epoch: [113][100/391]\tTime 0.048 (0.051)\tData 0.001 (0.005)\tLoss 0.5040 (0.5062)\tPrec 100.000% (99.822%)\n",
      "Epoch: [113][200/391]\tTime 0.046 (0.049)\tData 0.001 (0.003)\tLoss 0.5079 (0.5064)\tPrec 99.219% (99.786%)\n",
      "Epoch: [113][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5081 (0.5067)\tPrec 99.219% (99.782%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.119 (0.119)\tLoss 0.5945 (0.5945)\tPrec 96.094% (96.094%)\n",
      " * Prec 90.470% \n",
      "best acc: 90.470000\n",
      "Epoch: [114][0/391]\tTime 0.323 (0.323)\tData 0.292 (0.292)\tLoss 0.5031 (0.5031)\tPrec 100.000% (100.000%)\n",
      "Epoch: [114][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.004)\tLoss 0.5055 (0.5062)\tPrec 100.000% (99.783%)\n",
      "Epoch: [114][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5036 (0.5064)\tPrec 100.000% (99.782%)\n",
      "Epoch: [114][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5124 (0.5064)\tPrec 99.219% (99.800%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.195 (0.195)\tLoss 0.6238 (0.6238)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.330% \n",
      "best acc: 90.470000\n",
      "Epoch: [115][0/391]\tTime 0.355 (0.355)\tData 0.324 (0.324)\tLoss 0.5046 (0.5046)\tPrec 100.000% (100.000%)\n",
      "Epoch: [115][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5023 (0.5058)\tPrec 100.000% (99.830%)\n",
      "Epoch: [115][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5093 (0.5060)\tPrec 100.000% (99.833%)\n",
      "Epoch: [115][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5027 (0.5064)\tPrec 100.000% (99.800%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.180 (0.180)\tLoss 0.6152 (0.6152)\tPrec 93.750% (93.750%)\n",
      " * Prec 90.350% \n",
      "best acc: 90.470000\n",
      "Epoch: [116][0/391]\tTime 0.378 (0.378)\tData 0.349 (0.349)\tLoss 0.5031 (0.5031)\tPrec 100.000% (100.000%)\n",
      "Epoch: [116][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.005)\tLoss 0.5033 (0.5056)\tPrec 100.000% (99.853%)\n",
      "Epoch: [116][200/391]\tTime 0.050 (0.049)\tData 0.001 (0.003)\tLoss 0.5052 (0.5059)\tPrec 100.000% (99.825%)\n",
      "Epoch: [116][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5142 (0.5064)\tPrec 99.219% (99.805%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.183 (0.183)\tLoss 0.6014 (0.6014)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.270% \n",
      "best acc: 90.470000\n",
      "Epoch: [117][0/391]\tTime 0.339 (0.339)\tData 0.310 (0.310)\tLoss 0.5062 (0.5062)\tPrec 100.000% (100.000%)\n",
      "Epoch: [117][100/391]\tTime 0.041 (0.050)\tData 0.001 (0.004)\tLoss 0.5034 (0.5053)\tPrec 100.000% (99.830%)\n",
      "Epoch: [117][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5035 (0.5051)\tPrec 100.000% (99.845%)\n",
      "Epoch: [117][300/391]\tTime 0.052 (0.048)\tData 0.001 (0.002)\tLoss 0.5021 (0.5056)\tPrec 100.000% (99.829%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.6025 (0.6025)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.220% \n",
      "best acc: 90.470000\n",
      "Epoch: [118][0/391]\tTime 0.394 (0.394)\tData 0.320 (0.320)\tLoss 0.5061 (0.5061)\tPrec 100.000% (100.000%)\n",
      "Epoch: [118][100/391]\tTime 0.051 (0.051)\tData 0.001 (0.004)\tLoss 0.5141 (0.5066)\tPrec 99.219% (99.783%)\n",
      "Epoch: [118][200/391]\tTime 0.050 (0.049)\tData 0.001 (0.003)\tLoss 0.5134 (0.5063)\tPrec 99.219% (99.790%)\n",
      "Epoch: [118][300/391]\tTime 0.053 (0.049)\tData 0.001 (0.002)\tLoss 0.5018 (0.5061)\tPrec 100.000% (99.813%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.191 (0.191)\tLoss 0.6112 (0.6112)\tPrec 96.094% (96.094%)\n",
      " * Prec 90.470% \n",
      "best acc: 90.470000\n",
      "Epoch: [119][0/391]\tTime 0.442 (0.442)\tData 0.376 (0.376)\tLoss 0.5020 (0.5020)\tPrec 100.000% (100.000%)\n",
      "Epoch: [119][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.005)\tLoss 0.5030 (0.5054)\tPrec 100.000% (99.845%)\n",
      "Epoch: [119][200/391]\tTime 0.042 (0.049)\tData 0.001 (0.003)\tLoss 0.5152 (0.5055)\tPrec 99.219% (99.841%)\n",
      "Epoch: [119][300/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5022 (0.5057)\tPrec 100.000% (99.836%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.219 (0.219)\tLoss 0.6101 (0.6101)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.410% \n",
      "best acc: 90.470000\n",
      "Epoch: [120][0/391]\tTime 0.342 (0.342)\tData 0.312 (0.312)\tLoss 0.5105 (0.5105)\tPrec 100.000% (100.000%)\n",
      "Epoch: [120][100/391]\tTime 0.050 (0.050)\tData 0.001 (0.004)\tLoss 0.5042 (0.5057)\tPrec 100.000% (99.845%)\n",
      "Epoch: [120][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5018 (0.5052)\tPrec 100.000% (99.856%)\n",
      "Epoch: [120][300/391]\tTime 0.049 (0.048)\tData 0.001 (0.002)\tLoss 0.5033 (0.5055)\tPrec 100.000% (99.847%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.263 (0.263)\tLoss 0.5834 (0.5834)\tPrec 96.094% (96.094%)\n",
      " * Prec 90.280% \n",
      "best acc: 90.470000\n",
      "Epoch: [121][0/391]\tTime 0.383 (0.383)\tData 0.354 (0.354)\tLoss 0.5013 (0.5013)\tPrec 100.000% (100.000%)\n",
      "Epoch: [121][100/391]\tTime 0.043 (0.051)\tData 0.005 (0.005)\tLoss 0.5020 (0.5061)\tPrec 100.000% (99.791%)\n",
      "Epoch: [121][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5018 (0.5058)\tPrec 100.000% (99.821%)\n",
      "Epoch: [121][300/391]\tTime 0.047 (0.049)\tData 0.001 (0.002)\tLoss 0.5037 (0.5059)\tPrec 100.000% (99.811%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.189 (0.189)\tLoss 0.6146 (0.6146)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.350% \n",
      "best acc: 90.470000\n",
      "Epoch: [122][0/391]\tTime 0.382 (0.382)\tData 0.352 (0.352)\tLoss 0.5054 (0.5054)\tPrec 100.000% (100.000%)\n",
      "Epoch: [122][100/391]\tTime 0.046 (0.051)\tData 0.001 (0.005)\tLoss 0.5026 (0.5045)\tPrec 100.000% (99.892%)\n",
      "Epoch: [122][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5017 (0.5054)\tPrec 100.000% (99.829%)\n",
      "Epoch: [122][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5014 (0.5057)\tPrec 100.000% (99.805%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.5975 (0.5975)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.400% \n",
      "best acc: 90.470000\n",
      "Epoch: [123][0/391]\tTime 0.448 (0.448)\tData 0.418 (0.418)\tLoss 0.5047 (0.5047)\tPrec 100.000% (100.000%)\n",
      "Epoch: [123][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.005)\tLoss 0.5053 (0.5043)\tPrec 100.000% (99.915%)\n",
      "Epoch: [123][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5071 (0.5049)\tPrec 99.219% (99.891%)\n",
      "Epoch: [123][300/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5019 (0.5050)\tPrec 100.000% (99.873%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.286 (0.286)\tLoss 0.5664 (0.5664)\tPrec 96.875% (96.875%)\n",
      " * Prec 90.320% \n",
      "best acc: 90.470000\n",
      "Epoch: [124][0/391]\tTime 0.359 (0.359)\tData 0.330 (0.330)\tLoss 0.5030 (0.5030)\tPrec 100.000% (100.000%)\n",
      "Epoch: [124][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.005)\tLoss 0.5058 (0.5051)\tPrec 100.000% (99.830%)\n",
      "Epoch: [124][200/391]\tTime 0.052 (0.049)\tData 0.001 (0.003)\tLoss 0.5013 (0.5058)\tPrec 100.000% (99.813%)\n",
      "Epoch: [124][300/391]\tTime 0.045 (0.048)\tData 0.001 (0.002)\tLoss 0.5029 (0.5056)\tPrec 100.000% (99.829%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.189 (0.189)\tLoss 0.5932 (0.5932)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.270% \n",
      "best acc: 90.470000\n",
      "Epoch: [125][0/391]\tTime 0.350 (0.350)\tData 0.321 (0.321)\tLoss 0.5011 (0.5011)\tPrec 100.000% (100.000%)\n",
      "Epoch: [125][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.005)\tLoss 0.5048 (0.5055)\tPrec 100.000% (99.807%)\n",
      "Epoch: [125][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5037 (0.5054)\tPrec 100.000% (99.833%)\n",
      "Epoch: [125][300/391]\tTime 0.042 (0.048)\tData 0.001 (0.002)\tLoss 0.5032 (0.5050)\tPrec 100.000% (99.855%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.184 (0.184)\tLoss 0.5973 (0.5973)\tPrec 96.094% (96.094%)\n",
      " * Prec 90.390% \n",
      "best acc: 90.470000\n",
      "Epoch: [126][0/391]\tTime 0.357 (0.357)\tData 0.327 (0.327)\tLoss 0.5077 (0.5077)\tPrec 99.219% (99.219%)\n",
      "Epoch: [126][100/391]\tTime 0.051 (0.050)\tData 0.001 (0.005)\tLoss 0.5031 (0.5051)\tPrec 100.000% (99.876%)\n",
      "Epoch: [126][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5035 (0.5050)\tPrec 100.000% (99.864%)\n",
      "Epoch: [126][300/391]\tTime 0.046 (0.048)\tData 0.001 (0.002)\tLoss 0.5013 (0.5050)\tPrec 100.000% (99.868%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.184 (0.184)\tLoss 0.6063 (0.6063)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.230% \n",
      "best acc: 90.470000\n",
      "Epoch: [127][0/391]\tTime 0.402 (0.402)\tData 0.338 (0.338)\tLoss 0.5024 (0.5024)\tPrec 100.000% (100.000%)\n",
      "Epoch: [127][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.005)\tLoss 0.5095 (0.5048)\tPrec 99.219% (99.884%)\n",
      "Epoch: [127][200/391]\tTime 0.053 (0.049)\tData 0.001 (0.003)\tLoss 0.5067 (0.5049)\tPrec 99.219% (99.876%)\n",
      "Epoch: [127][300/391]\tTime 0.046 (0.049)\tData 0.001 (0.002)\tLoss 0.5019 (0.5048)\tPrec 100.000% (99.875%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.196 (0.196)\tLoss 0.5914 (0.5914)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.500% \n",
      "best acc: 90.500000\n",
      "Epoch: [128][0/391]\tTime 0.290 (0.290)\tData 0.242 (0.242)\tLoss 0.5019 (0.5019)\tPrec 100.000% (100.000%)\n",
      "Epoch: [128][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5018 (0.5045)\tPrec 100.000% (99.899%)\n",
      "Epoch: [128][200/391]\tTime 0.045 (0.048)\tData 0.001 (0.002)\tLoss 0.5019 (0.5045)\tPrec 100.000% (99.907%)\n",
      "Epoch: [128][300/391]\tTime 0.050 (0.048)\tData 0.001 (0.002)\tLoss 0.5015 (0.5045)\tPrec 100.000% (99.896%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.195 (0.195)\tLoss 0.5999 (0.5999)\tPrec 96.094% (96.094%)\n",
      " * Prec 90.410% \n",
      "best acc: 90.500000\n",
      "Epoch: [129][0/391]\tTime 0.381 (0.381)\tData 0.331 (0.331)\tLoss 0.5018 (0.5018)\tPrec 100.000% (100.000%)\n",
      "Epoch: [129][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.005)\tLoss 0.5017 (0.5049)\tPrec 100.000% (99.884%)\n",
      "Epoch: [129][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5045 (0.5048)\tPrec 100.000% (99.880%)\n",
      "Epoch: [129][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.5053 (0.5047)\tPrec 100.000% (99.873%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.185 (0.185)\tLoss 0.5689 (0.5689)\tPrec 96.875% (96.875%)\n",
      " * Prec 90.190% \n",
      "best acc: 90.500000\n",
      "Epoch: [130][0/391]\tTime 0.361 (0.361)\tData 0.327 (0.327)\tLoss 0.5014 (0.5014)\tPrec 100.000% (100.000%)\n",
      "Epoch: [130][100/391]\tTime 0.044 (0.050)\tData 0.001 (0.004)\tLoss 0.5033 (0.5048)\tPrec 100.000% (99.861%)\n",
      "Epoch: [130][200/391]\tTime 0.049 (0.049)\tData 0.001 (0.003)\tLoss 0.5016 (0.5050)\tPrec 100.000% (99.841%)\n",
      "Epoch: [130][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5015 (0.5050)\tPrec 100.000% (99.852%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.187 (0.187)\tLoss 0.5847 (0.5847)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.480% \n",
      "best acc: 90.500000\n",
      "Epoch: [131][0/391]\tTime 0.340 (0.340)\tData 0.306 (0.306)\tLoss 0.5031 (0.5031)\tPrec 100.000% (100.000%)\n",
      "Epoch: [131][100/391]\tTime 0.046 (0.050)\tData 0.001 (0.004)\tLoss 0.5075 (0.5047)\tPrec 100.000% (99.884%)\n",
      "Epoch: [131][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5043 (0.5049)\tPrec 100.000% (99.864%)\n",
      "Epoch: [131][300/391]\tTime 0.049 (0.048)\tData 0.001 (0.002)\tLoss 0.5019 (0.5049)\tPrec 100.000% (99.868%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.5915 (0.5915)\tPrec 96.094% (96.094%)\n",
      " * Prec 90.320% \n",
      "best acc: 90.500000\n",
      "Epoch: [132][0/391]\tTime 0.247 (0.247)\tData 0.217 (0.217)\tLoss 0.5079 (0.5079)\tPrec 99.219% (99.219%)\n",
      "Epoch: [132][100/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5056 (0.5043)\tPrec 100.000% (99.884%)\n",
      "Epoch: [132][200/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5033 (0.5045)\tPrec 100.000% (99.876%)\n",
      "Epoch: [132][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5078 (0.5047)\tPrec 100.000% (99.868%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.187 (0.187)\tLoss 0.5768 (0.5768)\tPrec 96.875% (96.875%)\n",
      " * Prec 90.580% \n",
      "best acc: 90.580000\n",
      "Epoch: [133][0/391]\tTime 0.367 (0.367)\tData 0.334 (0.334)\tLoss 0.5018 (0.5018)\tPrec 100.000% (100.000%)\n",
      "Epoch: [133][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.005)\tLoss 0.5093 (0.5044)\tPrec 99.219% (99.907%)\n",
      "Epoch: [133][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5205 (0.5049)\tPrec 99.219% (99.872%)\n",
      "Epoch: [133][300/391]\tTime 0.048 (0.048)\tData 0.001 (0.002)\tLoss 0.5022 (0.5048)\tPrec 100.000% (99.868%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.207 (0.207)\tLoss 0.5767 (0.5767)\tPrec 96.094% (96.094%)\n",
      " * Prec 90.360% \n",
      "best acc: 90.580000\n",
      "Epoch: [134][0/391]\tTime 0.369 (0.369)\tData 0.338 (0.338)\tLoss 0.5017 (0.5017)\tPrec 100.000% (100.000%)\n",
      "Epoch: [134][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.005)\tLoss 0.5013 (0.5049)\tPrec 100.000% (99.876%)\n",
      "Epoch: [134][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5053 (0.5052)\tPrec 100.000% (99.852%)\n",
      "Epoch: [134][300/391]\tTime 0.045 (0.048)\tData 0.001 (0.002)\tLoss 0.5016 (0.5049)\tPrec 100.000% (99.862%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.196 (0.196)\tLoss 0.5619 (0.5619)\tPrec 97.656% (97.656%)\n",
      " * Prec 90.500% \n",
      "best acc: 90.580000\n",
      "Epoch: [135][0/391]\tTime 0.329 (0.329)\tData 0.298 (0.298)\tLoss 0.5031 (0.5031)\tPrec 100.000% (100.000%)\n",
      "Epoch: [135][100/391]\tTime 0.051 (0.050)\tData 0.001 (0.004)\tLoss 0.5058 (0.5045)\tPrec 100.000% (99.876%)\n",
      "Epoch: [135][200/391]\tTime 0.050 (0.049)\tData 0.001 (0.003)\tLoss 0.5033 (0.5047)\tPrec 100.000% (99.860%)\n",
      "Epoch: [135][300/391]\tTime 0.053 (0.048)\tData 0.001 (0.002)\tLoss 0.5177 (0.5047)\tPrec 99.219% (99.870%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.187 (0.187)\tLoss 0.5881 (0.5881)\tPrec 96.875% (96.875%)\n",
      " * Prec 90.510% \n",
      "best acc: 90.580000\n",
      "Epoch: [136][0/391]\tTime 0.379 (0.379)\tData 0.351 (0.351)\tLoss 0.5025 (0.5025)\tPrec 100.000% (100.000%)\n",
      "Epoch: [136][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.005)\tLoss 0.5018 (0.5051)\tPrec 100.000% (99.838%)\n",
      "Epoch: [136][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5022 (0.5047)\tPrec 100.000% (99.864%)\n",
      "Epoch: [136][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5036 (0.5047)\tPrec 100.000% (99.875%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.200 (0.200)\tLoss 0.5468 (0.5468)\tPrec 98.438% (98.438%)\n",
      " * Prec 90.440% \n",
      "best acc: 90.580000\n",
      "Epoch: [137][0/391]\tTime 0.351 (0.351)\tData 0.320 (0.320)\tLoss 0.5057 (0.5057)\tPrec 100.000% (100.000%)\n",
      "Epoch: [137][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.005)\tLoss 0.5058 (0.5048)\tPrec 100.000% (99.869%)\n",
      "Epoch: [137][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5015 (0.5043)\tPrec 100.000% (99.895%)\n",
      "Epoch: [137][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5011 (0.5047)\tPrec 100.000% (99.870%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.268 (0.268)\tLoss 0.6091 (0.6091)\tPrec 96.094% (96.094%)\n",
      " * Prec 90.520% \n",
      "best acc: 90.580000\n",
      "Epoch: [138][0/391]\tTime 0.377 (0.377)\tData 0.347 (0.347)\tLoss 0.5084 (0.5084)\tPrec 99.219% (99.219%)\n",
      "Epoch: [138][100/391]\tTime 0.046 (0.050)\tData 0.001 (0.005)\tLoss 0.5047 (0.5043)\tPrec 100.000% (99.907%)\n",
      "Epoch: [138][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5020 (0.5044)\tPrec 100.000% (99.895%)\n",
      "Epoch: [138][300/391]\tTime 0.052 (0.048)\tData 0.001 (0.002)\tLoss 0.5281 (0.5047)\tPrec 99.219% (99.883%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.212 (0.212)\tLoss 0.6136 (0.6136)\tPrec 96.094% (96.094%)\n",
      " * Prec 90.660% \n",
      "best acc: 90.660000\n",
      "Epoch: [139][0/391]\tTime 0.412 (0.412)\tData 0.379 (0.379)\tLoss 0.5274 (0.5274)\tPrec 98.438% (98.438%)\n",
      "Epoch: [139][100/391]\tTime 0.049 (0.051)\tData 0.001 (0.005)\tLoss 0.5021 (0.5054)\tPrec 100.000% (99.822%)\n",
      "Epoch: [139][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5032 (0.5048)\tPrec 100.000% (99.856%)\n",
      "Epoch: [139][300/391]\tTime 0.049 (0.049)\tData 0.001 (0.003)\tLoss 0.5040 (0.5052)\tPrec 100.000% (99.842%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.185 (0.185)\tLoss 0.6074 (0.6074)\tPrec 94.531% (94.531%)\n",
      " * Prec 90.320% \n",
      "best acc: 90.660000\n",
      "Epoch: [140][0/391]\tTime 0.352 (0.352)\tData 0.322 (0.322)\tLoss 0.5029 (0.5029)\tPrec 100.000% (100.000%)\n",
      "Epoch: [140][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.005)\tLoss 0.5057 (0.5046)\tPrec 100.000% (99.861%)\n",
      "Epoch: [140][200/391]\tTime 0.046 (0.049)\tData 0.001 (0.003)\tLoss 0.5020 (0.5044)\tPrec 100.000% (99.880%)\n",
      "Epoch: [140][300/391]\tTime 0.045 (0.048)\tData 0.004 (0.002)\tLoss 0.5033 (0.5048)\tPrec 100.000% (99.870%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.209 (0.209)\tLoss 0.6195 (0.6195)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.580% \n",
      "best acc: 90.660000\n",
      "Epoch: [141][0/391]\tTime 0.352 (0.352)\tData 0.320 (0.320)\tLoss 0.5037 (0.5037)\tPrec 100.000% (100.000%)\n",
      "Epoch: [141][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.004)\tLoss 0.5026 (0.5049)\tPrec 100.000% (99.884%)\n",
      "Epoch: [141][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5043 (0.5052)\tPrec 100.000% (99.868%)\n",
      "Epoch: [141][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5021 (0.5052)\tPrec 100.000% (99.860%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.176 (0.176)\tLoss 0.5652 (0.5652)\tPrec 97.656% (97.656%)\n",
      " * Prec 90.580% \n",
      "best acc: 90.660000\n",
      "Epoch: [142][0/391]\tTime 0.429 (0.429)\tData 0.398 (0.398)\tLoss 0.5121 (0.5121)\tPrec 99.219% (99.219%)\n",
      "Epoch: [142][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.005)\tLoss 0.5018 (0.5049)\tPrec 100.000% (99.845%)\n",
      "Epoch: [142][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5019 (0.5050)\tPrec 100.000% (99.852%)\n",
      "Epoch: [142][300/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5012 (0.5047)\tPrec 100.000% (99.870%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.186 (0.186)\tLoss 0.5973 (0.5973)\tPrec 96.094% (96.094%)\n",
      " * Prec 90.490% \n",
      "best acc: 90.660000\n",
      "Epoch: [143][0/391]\tTime 0.364 (0.364)\tData 0.333 (0.333)\tLoss 0.5037 (0.5037)\tPrec 100.000% (100.000%)\n",
      "Epoch: [143][100/391]\tTime 0.047 (0.051)\tData 0.002 (0.005)\tLoss 0.5019 (0.5041)\tPrec 100.000% (99.892%)\n",
      "Epoch: [143][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5032 (0.5043)\tPrec 100.000% (99.883%)\n",
      "Epoch: [143][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5015 (0.5044)\tPrec 100.000% (99.883%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.213 (0.213)\tLoss 0.5698 (0.5698)\tPrec 96.875% (96.875%)\n",
      " * Prec 90.500% \n",
      "best acc: 90.660000\n",
      "Epoch: [144][0/391]\tTime 0.403 (0.403)\tData 0.370 (0.370)\tLoss 0.5045 (0.5045)\tPrec 100.000% (100.000%)\n",
      "Epoch: [144][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.005)\tLoss 0.5038 (0.5040)\tPrec 100.000% (99.892%)\n",
      "Epoch: [144][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5023 (0.5041)\tPrec 100.000% (99.880%)\n",
      "Epoch: [144][300/391]\tTime 0.048 (0.049)\tData 0.001 (0.002)\tLoss 0.5029 (0.5040)\tPrec 100.000% (99.891%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.189 (0.189)\tLoss 0.5658 (0.5658)\tPrec 96.094% (96.094%)\n",
      " * Prec 90.550% \n",
      "best acc: 90.660000\n",
      "Epoch: [145][0/391]\tTime 0.372 (0.372)\tData 0.343 (0.343)\tLoss 0.5039 (0.5039)\tPrec 100.000% (100.000%)\n",
      "Epoch: [145][100/391]\tTime 0.048 (0.051)\tData 0.001 (0.005)\tLoss 0.5049 (0.5039)\tPrec 100.000% (99.915%)\n",
      "Epoch: [145][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5069 (0.5045)\tPrec 100.000% (99.876%)\n",
      "Epoch: [145][300/391]\tTime 0.046 (0.048)\tData 0.001 (0.002)\tLoss 0.5128 (0.5043)\tPrec 99.219% (99.883%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.186 (0.186)\tLoss 0.5639 (0.5639)\tPrec 97.656% (97.656%)\n",
      " * Prec 90.420% \n",
      "best acc: 90.660000\n",
      "Epoch: [146][0/391]\tTime 0.334 (0.334)\tData 0.304 (0.304)\tLoss 0.5200 (0.5200)\tPrec 99.219% (99.219%)\n",
      "Epoch: [146][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5021 (0.5045)\tPrec 100.000% (99.884%)\n",
      "Epoch: [146][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5029 (0.5043)\tPrec 100.000% (99.895%)\n",
      "Epoch: [146][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5097 (0.5043)\tPrec 100.000% (99.901%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.5648 (0.5648)\tPrec 98.438% (98.438%)\n",
      " * Prec 90.360% \n",
      "best acc: 90.660000\n",
      "Epoch: [147][0/391]\tTime 0.390 (0.390)\tData 0.359 (0.359)\tLoss 0.5049 (0.5049)\tPrec 100.000% (100.000%)\n",
      "Epoch: [147][100/391]\tTime 0.047 (0.051)\tData 0.001 (0.005)\tLoss 0.5076 (0.5041)\tPrec 99.219% (99.884%)\n",
      "Epoch: [147][200/391]\tTime 0.047 (0.049)\tData 0.001 (0.003)\tLoss 0.5017 (0.5041)\tPrec 100.000% (99.903%)\n",
      "Epoch: [147][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.003)\tLoss 0.5015 (0.5044)\tPrec 100.000% (99.886%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.197 (0.197)\tLoss 0.6034 (0.6034)\tPrec 96.875% (96.875%)\n",
      " * Prec 90.450% \n",
      "best acc: 90.660000\n",
      "Epoch: [148][0/391]\tTime 0.347 (0.347)\tData 0.314 (0.314)\tLoss 0.5032 (0.5032)\tPrec 100.000% (100.000%)\n",
      "Epoch: [148][100/391]\tTime 0.047 (0.050)\tData 0.001 (0.004)\tLoss 0.5016 (0.5042)\tPrec 100.000% (99.892%)\n",
      "Epoch: [148][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5026 (0.5042)\tPrec 100.000% (99.903%)\n",
      "Epoch: [148][300/391]\tTime 0.050 (0.048)\tData 0.001 (0.002)\tLoss 0.5015 (0.5042)\tPrec 100.000% (99.886%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.183 (0.183)\tLoss 0.5800 (0.5800)\tPrec 96.094% (96.094%)\n",
      " * Prec 90.460% \n",
      "best acc: 90.660000\n",
      "Epoch: [149][0/391]\tTime 0.360 (0.360)\tData 0.327 (0.327)\tLoss 0.5019 (0.5019)\tPrec 100.000% (100.000%)\n",
      "Epoch: [149][100/391]\tTime 0.048 (0.050)\tData 0.001 (0.005)\tLoss 0.5024 (0.5045)\tPrec 100.000% (99.915%)\n",
      "Epoch: [149][200/391]\tTime 0.048 (0.049)\tData 0.001 (0.003)\tLoss 0.5072 (0.5043)\tPrec 100.000% (99.899%)\n",
      "Epoch: [149][300/391]\tTime 0.047 (0.048)\tData 0.001 (0.002)\tLoss 0.5024 (0.5042)\tPrec 100.000% (99.894%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.195 (0.195)\tLoss 0.5858 (0.5858)\tPrec 95.312% (95.312%)\n",
      " * Prec 90.450% \n",
      "best acc: 90.660000\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "weight_decay = 1e-5\n",
    "epochs = 150\n",
    "best_prec = 0\n",
    "\n",
    "model.cuda()\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1).cuda()\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=0.9, weight_decay=weight_decay, nesterov=True)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'+str(model_name)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    # adjust_learning_rate(optimizer, epoch)\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    scheduler.step()\n",
    "\n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "34f8e3ea",
   "metadata": {},
   "source": [
    "### Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "entertaining-queensland",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "VGG_quant(\n",
      "  (features): Sequential(\n",
      "    (0): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): QuantConv2d(\n",
      "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): QuantConv2d(\n",
      "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): QuantConv2d(\n",
      "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): QuantConv2d(\n",
      "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): QuantConv2d(\n",
      "      256, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (25): BatchNorm2d(8, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): QuantConv2d(\n",
      "      8, 8, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (28): Identity()\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): QuantConv2d(\n",
      "      8, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (44): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_893700/128479599.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 9072/10000 (91%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/VGG16_quant/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "print(model)\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3e4b275",
   "metadata": {},
   "source": [
    "### Weight and Activation recovery verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c12bddff",
   "metadata": {},
   "source": [
    "#### Getting the right target layer and attaching hooks for fwd pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "101aaff3",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured Transient Input for 8x8 layer: [[[[0.7528543  1.7992511  1.7467965  1.3647989 ]\n",
      "   [0.         0.26089427 0.         0.        ]\n",
      "   [0.         0.05128749 0.6869564  0.42997885]\n",
      "   [0.         0.         0.         0.        ]]\n",
      "\n",
      "  [[0.12536542 1.0985982  0.97800106 0.8837508 ]\n",
      "   [0.12086887 1.5830147  0.19548273 0.        ]\n",
      "   [0.93421614 1.587489   0.32703155 0.        ]\n",
      "   [0.         0.30065754 0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.         0.04210338]\n",
      "   [0.         0.         0.         0.2601679 ]\n",
      "   [0.         0.30907613 1.5854645  1.0959355 ]\n",
      "   [0.         0.18303858 0.48659316 1.2263494 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.         0.5830591 ]\n",
      "   [0.         0.         0.56545293 1.357479  ]\n",
      "   [0.         0.         0.         0.47578564]\n",
      "   [0.         0.         0.         0.        ]]\n",
      "\n",
      "  [[0.541478   0.19551845 0.         0.7155491 ]\n",
      "   [0.4184445  0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.45869854 0.         0.         0.11493356]]\n",
      "\n",
      "  [[0.36285886 1.3648515  1.1481204  0.49288452]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.03617152 0.32693967 0.5940028 ]\n",
      "   [0.         0.         0.01565718 0.        ]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]]\n",
      "\n",
      "  [[0.38401628 0.12330111 0.         0.        ]\n",
      "   [0.7368569  0.45192885 0.         0.        ]\n",
      "   [0.56377393 0.2985332  0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.8330142  1.5854013  1.0274963 ]\n",
      "   [0.03767974 1.3031905  2.9192286  2.3465035 ]\n",
      "   [0.         0.         0.92690575 1.8312359 ]\n",
      "   [0.         0.         0.         1.2882979 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.1870321 ]]\n",
      "\n",
      "  [[0.9044368  0.03007763 0.363258   0.87050474]\n",
      "   [0.25070333 0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [1.0402485  0.         0.         0.06627068]]\n",
      "\n",
      "  [[0.0878469  0.35802397 0.2212204  0.        ]\n",
      "   [0.         0.23778246 0.         0.        ]\n",
      "   [0.54128146 0.8345675  0.94304806 0.        ]\n",
      "   [0.         0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.43503314 0.         0.08350185]\n",
      "   [0.         0.         0.09187768 0.14933118]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.         0.        ]\n",
      "   [0.4101944  0.7719477  0.         0.        ]\n",
      "   [0.8727489  0.7718811  0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]]\n",
      "\n",
      "  [[0.11898619 0.70475036 0.9975092  0.96331304]\n",
      "   [1.1749792  1.0573281  2.124067   2.4619997 ]\n",
      "   [0.4908656  0.         0.         0.9718575 ]\n",
      "   [0.         0.         0.         0.37331295]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.5206106 ]\n",
      "   [0.         0.         0.6844818  1.5584648 ]\n",
      "   [0.         0.         0.34706634 1.0199999 ]]\n",
      "\n",
      "  [[0.26986682 0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [1.0742328  0.1722415  0.02581897 0.22742009]]\n",
      "\n",
      "  [[0.1912022  0.7496761  0.7330107  0.5879524 ]\n",
      "   [0.1960446  0.5145084  0.         0.        ]\n",
      "   [0.63793194 0.66966784 0.20780048 0.        ]\n",
      "   [0.         0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.03443312 0.7884195  0.58894336 0.        ]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.         0.01920244 0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.         0.938559   0.         0.37947437]\n",
      "   [0.         0.         0.         0.        ]]\n",
      "\n",
      "  [[0.0590895  0.22799434 0.         0.65551215]\n",
      "   [0.         0.         0.         1.3588489 ]\n",
      "   [0.         0.         0.         1.784281  ]\n",
      "   [0.         0.         0.         0.21946196]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.         0.33920184]\n",
      "   [0.         0.         0.         0.8405489 ]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]]\n",
      "\n",
      "  [[0.9596517  0.48851588 0.58396286 0.5606218 ]\n",
      "   [0.09788828 0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.7218491  0.09574782 0.         0.73252237]]\n",
      "\n",
      "  [[0.6313153  0.7797351  0.2678015  0.04603857]\n",
      "   [0.         0.02767751 0.         0.        ]\n",
      "   [0.59956235 1.0413587  1.0014671  0.20278032]\n",
      "   [0.         0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[0.         0.         0.26600072 0.20346555]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.01930008 0.        ]\n",
      "   [0.         0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.         2.0364845  2.2372792 ]\n",
      "   [0.         0.         0.747603   1.7993227 ]\n",
      "   [0.14670573 0.5164939  0.34565303 0.80523235]\n",
      "   [0.01618504 0.41391173 0.40756777 0.7689356 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.         0.2748921 ]\n",
      "   [0.         0.27494213 0.         1.2930018 ]\n",
      "   [0.         0.         0.         0.2435778 ]]\n",
      "\n",
      "  [[0.31231388 0.         0.         0.        ]\n",
      "   [0.14457688 0.         0.         0.        ]\n",
      "   [0.7451842  0.         0.         0.        ]\n",
      "   [0.99996215 0.08093536 0.         0.5753624 ]]\n",
      "\n",
      "  [[0.7162666  1.2882297  1.3749807  0.02445042]\n",
      "   [0.         0.52452785 0.4695539  0.        ]\n",
      "   [0.         0.         0.26619747 0.        ]\n",
      "   [0.         0.         0.         0.        ]]]\n",
      "\n",
      "\n",
      " [[[1.2989155  2.5127459  2.0545428  1.2481818 ]\n",
      "   [0.76633203 1.8837847  1.0757982  0.37591273]\n",
      "   [0.99960935 1.9445457  1.2922035  0.44685408]\n",
      "   [0.         0.         0.         0.        ]]\n",
      "\n",
      "  [[0.6164024  0.5353968  0.         0.        ]\n",
      "   [1.2916254  1.4758251  0.         0.        ]\n",
      "   [1.624741   1.4494817  0.         0.        ]\n",
      "   [0.41898292 0.         0.         0.        ]]\n",
      "\n",
      "  [[0.         0.68117017 1.260556   1.1151305 ]\n",
      "   [0.         0.12098938 0.98905164 1.6046773 ]\n",
      "   [0.03777865 0.         1.1343564  1.2434909 ]\n",
      "   [0.         0.07413168 0.34978312 0.8479832 ]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.         0.03876591 0.         0.        ]\n",
      "   [0.06610738 0.8951343  0.         0.5479445 ]\n",
      "   [0.         0.4328743  0.         0.        ]\n",
      "   [0.         0.         0.         0.        ]]\n",
      "\n",
      "  [[1.6939504  0.92985857 1.1082153  1.163402  ]\n",
      "   [0.8746297  0.         0.         0.        ]\n",
      "   [0.649677   0.         0.         0.        ]\n",
      "   [1.176112   0.         0.         0.49485177]]\n",
      "\n",
      "  [[0.05944609 0.36953807 0.18780734 0.        ]\n",
      "   [0.         0.         0.         0.        ]\n",
      "   [0.         0.         0.0144757  0.        ]\n",
      "   [0.         0.         0.         0.        ]]]]\n"
     ]
    }
   ],
   "source": [
    "if use_skip_block:\n",
    "    target_layer = model.features[20].conv27\n",
    "    next_layer = model.features[20].bn28\n",
    "else:\n",
    "    target_layer = model.features[27]\n",
    "    next_layer = model.features[28]\n",
    "\n",
    "# some sanity checking to ensure we're extracting the right layer\n",
    "assert isinstance(target_layer, QuantConv2d)\n",
    "\n",
    "input_records = {}\n",
    "def get_input_hook(name):\n",
    "    def hook(model, input, output):\n",
    "        input_records[name] = input[0].detach().clone()\n",
    "    return hook\n",
    "\n",
    "target_layer.register_forward_hook(get_input_hook('conv8x8_input'))\n",
    "next_layer.register_forward_hook(get_input_hook('next_layer_input'))\n",
    "\n",
    "# Running a sample forward pass to extract inputs\n",
    "data, _ = next(iter(testloader))\n",
    "data = data.cuda()\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(data)\n",
    "conv8x8_input = input_records['conv8x8_input'].cpu().numpy()\n",
    "print(f\"Captured Transient Input for 8x8 layer: {conv8x8_input}\")\n",
    "\n",
    "target_layer = target_layer.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "10013bed",
   "metadata": {},
   "source": [
    "#### Extracting weights for 8x8 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "7c658032",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Weights (check if they're all integers for sanity): tensor([[-1.0000, -1.0000, -2.0000],\n",
      "        [-3.0000, -1.0000, -1.0000],\n",
      "        [ 1.0000, -3.0000, -1.0000]], grad_fn=<SliceBackward0>)\n",
      "Sample Weights after rounding: tensor([[-1., -1., -2.],\n",
      "        [-3., -1., -1.],\n",
      "        [ 1., -3., -1.]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "w_bit = 4\n",
    "weight_float_q = target_layer.weight_q\n",
    "w_alpha = target_layer.weight_quant.wgt_alpha\n",
    "w_delta = w_alpha / (2**(w_bit - 1)-1)\n",
    "\n",
    "weight_int = (weight_float_q / w_delta)\n",
    "print(f\"Sample Weights (check if they're all integers for sanity): {weight_int[0][0][:][:]}\")\n",
    "\n",
    "weight_int = weight_int.round()\n",
    "print(f\"Sample Weights after rounding: {weight_int[0][0][:][:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "21b3cd37-db8d-4373-956b-c7ab032874e8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "weight shape: torch.Size([8, 8, 3, 3])\n",
      "Saved weight_itile0_otile0_kij0.txt for kernel tap (kh=0, kw=0)\n",
      "Saved weight_itile0_otile0_kij1.txt for kernel tap (kh=0, kw=1)\n",
      "Saved weight_itile0_otile0_kij2.txt for kernel tap (kh=0, kw=2)\n",
      "Saved weight_itile0_otile0_kij3.txt for kernel tap (kh=1, kw=0)\n",
      "Saved weight_itile0_otile0_kij4.txt for kernel tap (kh=1, kw=1)\n",
      "Saved weight_itile0_otile0_kij5.txt for kernel tap (kh=1, kw=2)\n",
      "Saved weight_itile0_otile0_kij6.txt for kernel tap (kh=2, kw=0)\n",
      "Saved weight_itile0_otile0_kij7.txt for kernel tap (kh=2, kw=1)\n",
      "Saved weight_itile0_otile0_kij8.txt for kernel tap (kh=2, kw=2)\n"
     ]
    }
   ],
   "source": [
    "WGT_BITS = 4\n",
    "\n",
    "weight_cpu = weight_int.detach().cpu().clone()  # [8, 8, 3, 3]\n",
    "OC, IC, kH, kW = weight_cpu.shape\n",
    "print(\"weight shape:\", weight_cpu.shape)\n",
    "\n",
    "assert OC == 8 and IC == 8 and kH == 3 and kW == 3\n",
    "\n",
    "# col in your Verilog should be 8 (same as IC)\n",
    "col = IC\n",
    "\n",
    "# Enumerate kernel positions in some order; you can change naming if needed\n",
    "kernel_positions = [(i, j) for i in range(3) for j in range(3)]\n",
    "\n",
    "for idx, (kh, kw) in enumerate(kernel_positions):\n",
    "    # Get the 8x8 weight matrix for this kernel tap\n",
    "    # W_k[oc, ic] = weight for (out_channel, in_channel) at this (kh,kw)\n",
    "    W_k = weight_cpu[:, :, kh, kw]   # [8, 8]\n",
    "\n",
    "    filename = f\"weight_itile0_otile0_kij{idx}.txt\"   # k0..k8; rename if needed\n",
    "    with open(filename, \"w\") as f:\n",
    "        # No header lines here, because your Verilog uses \"%32b\" directly.\n",
    "        # If you add comments, you must skip them in Verilog.\n",
    "\n",
    "        # ic = input channel index, corresponds to t in Verilog loop\n",
    "        for oc in range(OC):          # t = 0..7\n",
    "            # Build one 32-bit word: row7..row0, each 4 bits\n",
    "            line_bits = []\n",
    "            for ic in range(IC):       # rows\n",
    "                val = int(W_k[7 - oc, ic].item())  # row7 first, down to row0\n",
    "\n",
    "                # Mask into 4 bits (unsigned view)\n",
    "                val &= (1 << WGT_BITS) - 1\n",
    "                bits = f\"{val:0{WGT_BITS}b}\"       # \"0000\"..\"1111\"\n",
    "                line_bits.append(bits)\n",
    "\n",
    "            # Concatenate into 32-bit string\n",
    "            f.write(\"\".join(line_bits) + \"\\n\")\n",
    "\n",
    "    print(f\"Saved {filename} for kernel tap (kh={kh}, kw={kw})\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ba433fdb",
   "metadata": {},
   "source": [
    "#### Extracting Inputs for 8x8 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d59d9f1a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Inputs after quantization: tensor([[1., 3., 3., 3.],\n",
      "        [0., 1., 0., 0.],\n",
      "        [0., 0., 1., 1.],\n",
      "        [0., 0., 0., 0.]])\n"
     ]
    }
   ],
   "source": [
    "x_bit = 4\n",
    "x = conv8x8_input\n",
    "x_alpha = target_layer.act_alpha.detach()\n",
    "x_delta = x_alpha / (2**x_bit - 1)\n",
    "\n",
    "x_div = x / x_alpha\n",
    "x_clamped = torch.clamp(x_div, 0, 1)\n",
    "x_int = (x_clamped * (2**x_bit - 1)).round()\n",
    "\n",
    "print(f\"Sample Inputs after quantization: {x_int[0][0][:][:]}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ac0440a7-3d2c-4ef9-b7d2-6a65387468ea",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single sample shape: torch.Size([8, 4, 4])\n",
      "Saved activation.txt\n"
     ]
    }
   ],
   "source": [
    "ACT_BITS = 4 # 4-bit activations\n",
    "\n",
    "# Choose which sample in the batch you want to export\n",
    "sample_id = 0   # 0..127\n",
    "x_int_cpu = x_int.detach().cpu().clone()      # [128, 8, 4, 4]\n",
    "\n",
    "# Take one sample: shape [8, 4, 4]\n",
    "x_int_sample = x_int_cpu[sample_id]           # [C=8, H=4, W=4]\n",
    "\n",
    "C, H, W = x_int_sample.shape\n",
    "print(\"single sample shape:\", x_int_sample.shape)\n",
    "assert C == 8, f\"Expected 8 channels, got {C}\"\n",
    "assert H * W == 16, f\"Expected 4x4 spatial, got {H}x{W}\"\n",
    "\n",
    "# Flatten spatial into time: [rows=8, timesteps=16]\n",
    "# Here: each channel  one systolic row, 16 time steps\n",
    "X = x_int_sample.reshape(C, H * W)            # [8, 16]\n",
    "\n",
    "with open('activation.txt', 'w') as f:\n",
    "    f.write('#time0row7[msb-lsb],time0row6[msb-lsb],....,time0row0[msb-lsb]#\\n')\n",
    "    f.write('#time1row7[msb-lsb],time1row6[msb-lsb],....,time1row0[msb-lsb]#\\n')\n",
    "    f.write('#................#\\n')\n",
    "\n",
    "    # i: time step, j: row index\n",
    "    for i in range(X.size(1)):       # time steps (0..15)\n",
    "        for j in range(X.size(0)):   # row index (0..7)\n",
    "            X_bin = '{0:04b}'.format(round(X[7-j,i].item()))\n",
    "            #val = int(round(X[7 - j, i].item()))   # write row7..row0 order\n",
    "\n",
    "            # If you're treating activations as unsigned 4-bit:\n",
    "            #val = val & ((1 << ACT_BITS) - 1)\n",
    "\n",
    "            #X_bin = f'{val:0{ACT_BITS}b}'         # \"0000\"..\"1111\"\n",
    "            for k in range(ACT_BITS):\n",
    "                f.write(X_bin[k])\n",
    "        f.write('\\n')\n",
    "\n",
    "print(\"Saved activation.txt\")\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0dec9bf1",
   "metadata": {},
   "source": [
    "#### Verifying Psum Integrity with reference psum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "44c2fb4e",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_346/2530370086.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  psum_int = conv_int(torch.tensor(x_int))\n",
      "/tmp/ipykernel_346/2530370086.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_model_q = act_fn(torch.tensor(x), torch.tensor(x_alpha))\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 9.626764949643984e-07\n",
      "Success... Psum integrity verified!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_346/2530370086.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output_ref = F.conv2d(torch.tensor(x_model_q), torch.tensor(target_layer.weight_q), bias=None, stride=1, padding=1)\n"
     ]
    }
   ],
   "source": [
    "conv_int = nn.Conv2d(8, 8, kernel_size=3, padding=1, bias=False)\n",
    "conv_int.weight = nn.Parameter(weight_int.float())\n",
    "psum_int = conv_int(torch.tensor(x_int))\n",
    "output_recovered = psum_int * x_delta * w_delta\n",
    "\n",
    "act_fn = act_quantization(b=4)\n",
    "x_model_q = act_fn(torch.tensor(x), torch.tensor(x_alpha))\n",
    "output_ref = F.conv2d(torch.tensor(x_model_q), torch.tensor(target_layer.weight_q), bias=None, stride=1, padding=1)\n",
    "\n",
    "difference = torch.abs(output_recovered - output_ref)\n",
    "print(f\"Mean Absolute Error: {difference.mean().item()}\")\n",
    "if difference.mean().item() < 1e-3:\n",
    "    print(\"Success... Psum integrity verified!\")\n",
    "else:\n",
    "    print(\"Error too high... Psum integrity failed.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5a1efc0a",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"x_int shape:\", x_int.shape)\n",
    "print(\"weight_int shape:\", weight_int.shape)\n",
    "print(\"psum_int shape:\", psum_int.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "bd3ca3a0-4f5c-484c-86ff-22bd6dffe4cf",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved psum.txt\n"
     ]
    }
   ],
   "source": [
    "PSUM_BITS = 16\n",
    "\n",
    "sample_id = 0\n",
    "p_sample = psum_int[sample_id]      # [8, 4, 4]\n",
    "C, H, W = p_sample.shape\n",
    "assert C == 8 and H == 4 and W == 4\n",
    "\n",
    "# Flatten spatial dimension\n",
    "P = p_sample.reshape(C, H*W)        # [8, 16]\n",
    "\n",
    "with open(\"psum.txt\", \"w\") as f:\n",
    "    f.write(\"#time0row7[msb-lsb],time0row6[msb-lsb],...,time0row0[msb-lsb]#\\n\")\n",
    "    f.write(\"#............................#\\n\")\n",
    "\n",
    "    for t in range(P.size(1)):      # 16 time steps\n",
    "        for r in range(P.size(0)):  # 8 rows\n",
    "            val = int(P[7 - r, t].item())\n",
    "            val &= (1 << PSUM_BITS) - 1\n",
    "\n",
    "            bits = f\"{val:0{PSUM_BITS}b}\"\n",
    "            f.write(bits)\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(\"Saved psum.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "aef78e1d-ca16-47e9-a901-6f33a23b3f01",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved psum_relu.txt\n"
     ]
    }
   ],
   "source": [
    "PSUM_BITS = 16   # or match your RTL width\n",
    "\n",
    "sample_id = 0\n",
    "p_sample = psum_int[sample_id]      # shape [8,4,4]\n",
    "\n",
    "C, H, W = p_sample.shape\n",
    "assert C == 8 and H == 4 and W == 4\n",
    "\n",
    "# Flatten spatial  time\n",
    "P = p_sample.reshape(C, H*W)    # [8, 16]\n",
    "\n",
    "with open(\"psum_relu.txt\", \"w\") as f:\n",
    "    f.write(\"#ReLUed psum output\\n\")\n",
    "    f.write(\"#time0row7[msb-lsb],time0row6[msb-lsb],...,row0#\\n\")\n",
    "    f.write(\"#....................................#\\n\")\n",
    "\n",
    "    for t in range(P.size(1)):      # 16 timesteps\n",
    "        for r in range(P.size(0)):  # 8 rows\n",
    "            val = int(P[7-r,t].item())\n",
    "\n",
    "            # Apply ReLU\n",
    "            val = max(0, val)\n",
    "\n",
    "            # Fit into chosen bit width\n",
    "            val &= (1 << PSUM_BITS) - 1\n",
    "\n",
    "            bits = f\"{val:0{PSUM_BITS}b}\"\n",
    "            f.write(bits)\n",
    "\n",
    "        f.write(\"\\n\")\n",
    "\n",
    "print(\"Saved psum_relu.txt\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "edbdb3eb-31be-449a-9a9b-701829b16611",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Saved psum_0.txt\n",
      "Saved psum_1.txt\n",
      "Saved psum_2.txt\n",
      "Saved psum_3.txt\n",
      "Saved psum_4.txt\n",
      "Saved psum_5.txt\n",
      "Saved psum_6.txt\n",
      "Saved psum_7.txt\n",
      "Saved psum_8.txt\n"
     ]
    }
   ],
   "source": [
    "PSUM_BITS = 16\n",
    "sample_id = 0\n",
    "\n",
    "x_sample = x_int[sample_id].detach().cpu().clone()      # [8,4,4]\n",
    "w_cpu    = weight_int.detach().cpu().clone()            # [8,8,3,3]\n",
    "\n",
    "OC, IC, kH, kW = w_cpu.shape\n",
    "C, H, W = x_sample.shape\n",
    "assert H==4 and W==4 and C==8\n",
    "\n",
    "kernel_positions = [(i,j) for i in range(3) for j in range(3)]\n",
    "\n",
    "# pad input (padding=1)\n",
    "x_pad = torch.zeros((C, H+2, W+2), dtype=torch.int32)\n",
    "x_pad[:,1:H+1,1:W+1] = x_sample\n",
    "\n",
    "for idx, (kh, kw) in enumerate(kernel_positions):\n",
    "    # Extract weight matrix for this tap\n",
    "    W_k = w_cpu[:,:,kh,kw]   # [8,8]\n",
    "\n",
    "    # Output psum for this kernel (8,4,4)\n",
    "    psum_k = torch.zeros((OC,H,W), dtype=torch.int32)\n",
    "\n",
    "    # Compute per-tap convolution manually\n",
    "    for oc in range(OC):\n",
    "        for ic in range(IC):\n",
    "            w_val = int(W_k[oc, ic].item())\n",
    "            for h in range(H):\n",
    "                for w in range(W):\n",
    "                    # shifted input index = (h + kh, w + kw)\n",
    "                    xi = x_pad[ic, h + kh, w + kw].item()\n",
    "                    psum_k[oc, h, w] += xi * w_val\n",
    "\n",
    "    # Now dump as file with 16-bit mask\n",
    "    filename = f\"psum_{idx}.txt\"\n",
    "    with open(filename, \"w\") as f:\n",
    "        for t in range(H*W):         # 16 timesteps\n",
    "            h = t // W\n",
    "            w = t %  W\n",
    "\n",
    "            line_bits = []\n",
    "            for oc in range(OC):    # row7..row0\n",
    "                val = int(psum_k[7 - oc, h, w].item())\n",
    "                val &= (1 << PSUM_BITS) - 1\n",
    "                bits = f\"{val:0{PSUM_BITS}b}\"\n",
    "                line_bits.append(bits)\n",
    "\n",
    "            f.write(\"\".join(line_bits) + \"\\n\")\n",
    "\n",
    "    print(\"Saved\", filename)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "19e2aa4b",
   "metadata": {},
   "source": [
    "#### Verifying Psum Integrity with next layer input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1a13a456",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error with next layer input: 1.4162951629259624e-06\n",
      "Success... Psum integrity verified!\n"
     ]
    }
   ],
   "source": [
    "difference2 = torch.abs(input_records['next_layer_input'].cpu() - output_recovered)\n",
    "print(f\"Mean Absolute Error with next layer input: {difference2.mean().item()}\")\n",
    "if difference2.mean().item() < 1e-3:\n",
    "    print(\"Success... Psum integrity verified!\")\n",
    "else:\n",
    "    print(\"Error too high... Psum integrity failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "649a35a8",
   "metadata": {},
   "source": [
    "# ECE 284 Final Project - Software"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c5b90321",
   "metadata": {},
   "source": [
    "## Vanilla Training VGGNet with 2 bit activation and 4 bit weight quantisation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6d78e1e",
   "metadata": {},
   "source": [
    "### Initialisation Code"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bbec0cce",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Building model...\n",
      "VGG_quant(\n",
      "  (features): Sequential(\n",
      "    (0): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): QuantConv2d(\n",
      "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): QuantConv2d(\n",
      "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): QuantConv2d(\n",
      "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): QuantConv2d(\n",
      "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): QuantConv2d(\n",
      "      256, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (25): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (28): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (44): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n",
      "Files already downloaded and verified\n",
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import os\n",
    "import time\n",
    "import shutil\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torch.nn.functional as F\n",
    "import torch.backends.cudnn as cudnn\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "\n",
    "from models import *\n",
    "\n",
    "global best_prec\n",
    "use_gpu = torch.cuda.is_available()\n",
    "print('=> Building model...')\n",
    "\n",
    "batch_size = 128\n",
    "model_name = \"VGG16_quant\"\n",
    "model = VGG16_quant(wbit=4, abit=2)\n",
    "\n",
    "print(model)\n",
    "\n",
    "normalize = transforms.Normalize(mean=[0.491, 0.482, 0.447], std=[0.247, 0.243, 0.262])\n",
    "\n",
    "train_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=True,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.RandomCrop(32, padding=4),\n",
    "        transforms.RandomHorizontalFlip(),\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "trainloader = torch.utils.data.DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=2)\n",
    "\n",
    "test_dataset = torchvision.datasets.CIFAR10(\n",
    "    root='./data',\n",
    "    train=False,\n",
    "    download=True,\n",
    "    transform=transforms.Compose([\n",
    "        transforms.ToTensor(),\n",
    "        normalize,\n",
    "    ]))\n",
    "\n",
    "testloader = torch.utils.data.DataLoader(test_dataset, batch_size=batch_size, shuffle=False, num_workers=2)\n",
    "\n",
    "print_freq = 100 # every 100 batches, accuracy printed. Here, each batch includes \"batch_size\" data points\n",
    "# CIFAR10 has 50,000 training data, and 10,000 validation data.\n",
    "\n",
    "def train(trainloader, model, criterion, optimizer, epoch):\n",
    "    batch_time = AverageMeter()\n",
    "    data_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    model.train()\n",
    "\n",
    "    end = time.time()\n",
    "    for i, (input, target) in enumerate(trainloader):\n",
    "        # measure data loading time\n",
    "        data_time.update(time.time() - end)\n",
    "\n",
    "        input, target = input.cuda(), target.cuda()\n",
    "\n",
    "        # compute output\n",
    "        output = model(input)\n",
    "        loss = criterion(output, target)\n",
    "\n",
    "        # measure accuracy and record loss\n",
    "        prec = accuracy(output, target)[0]\n",
    "        losses.update(loss.item(), input.size(0))\n",
    "        top1.update(prec.item(), input.size(0))\n",
    "\n",
    "        # compute gradient and do SGD step\n",
    "        optimizer.zero_grad()\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "        # measure elapsed time\n",
    "        batch_time.update(time.time() - end)\n",
    "        end = time.time()\n",
    "\n",
    "\n",
    "        if i % print_freq == 0:\n",
    "            print('Epoch: [{0}][{1}/{2}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Data {data_time.val:.3f} ({data_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   epoch, i, len(trainloader), batch_time=batch_time,\n",
    "                   data_time=data_time, loss=losses, top1=top1))\n",
    "\n",
    "def validate(val_loader, model, criterion ):\n",
    "    batch_time = AverageMeter()\n",
    "    losses = AverageMeter()\n",
    "    top1 = AverageMeter()\n",
    "\n",
    "    # switch to evaluate mode\n",
    "    model.eval()\n",
    "\n",
    "    end = time.time()\n",
    "    with torch.no_grad():\n",
    "        for i, (input, target) in enumerate(val_loader):\n",
    "         \n",
    "            input, target = input.cuda(), target.cuda()\n",
    "\n",
    "            # compute output\n",
    "            output = model(input)\n",
    "            loss = criterion(output, target)\n",
    "\n",
    "            # measure accuracy and record loss\n",
    "            prec = accuracy(output, target)[0]\n",
    "            losses.update(loss.item(), input.size(0))\n",
    "            top1.update(prec.item(), input.size(0))\n",
    "\n",
    "            # measure elapsed time\n",
    "            batch_time.update(time.time() - end)\n",
    "            end = time.time()\n",
    "\n",
    "            if i % print_freq == 0:  # This line shows how frequently print out the status. e.g., i%5 => every 5 batch, prints out\n",
    "                print('Test: [{0}/{1}]\\t'\n",
    "                  'Time {batch_time.val:.3f} ({batch_time.avg:.3f})\\t'\n",
    "                  'Loss {loss.val:.4f} ({loss.avg:.4f})\\t'\n",
    "                  'Prec {top1.val:.3f}% ({top1.avg:.3f}%)'.format(\n",
    "                   i, len(val_loader), batch_time=batch_time, loss=losses,\n",
    "                   top1=top1))\n",
    "\n",
    "    print(' * Prec {top1.avg:.3f}% '.format(top1=top1))\n",
    "    return top1.avg\n",
    "\n",
    "def accuracy(output, target, topk=(1,)):\n",
    "    \"\"\"Computes the precision@k for the specified values of k\"\"\"\n",
    "    maxk = max(topk)\n",
    "    batch_size = target.size(0)\n",
    "\n",
    "    _, pred = output.topk(maxk, 1, True, True)\n",
    "    pred = pred.t()\n",
    "    correct = pred.eq(target.view(1, -1).expand_as(pred))\n",
    "\n",
    "    res = []\n",
    "    for k in topk:\n",
    "        correct_k = correct[:k].view(-1).float().sum(0)\n",
    "        res.append(correct_k.mul_(100.0 / batch_size))\n",
    "    return res\n",
    "\n",
    "class AverageMeter(object):\n",
    "    \"\"\"Computes and stores the average and current value\"\"\"\n",
    "    def __init__(self):\n",
    "        self.reset()\n",
    "\n",
    "    def reset(self):\n",
    "        self.val = 0\n",
    "        self.avg = 0\n",
    "        self.sum = 0\n",
    "        self.count = 0\n",
    "\n",
    "    def update(self, val, n=1):\n",
    "        self.val = val\n",
    "        self.sum += val * n\n",
    "        self.count += n\n",
    "        self.avg = self.sum / self.count\n",
    "    \n",
    "def save_checkpoint(state, is_best, fdir):\n",
    "    filepath = os.path.join(fdir, 'checkpoint.pth')\n",
    "    torch.save(state, filepath)\n",
    "    if is_best:\n",
    "        shutil.copyfile(filepath, os.path.join(fdir, 'model_best.pth.tar'))\n",
    "\n",
    "def adjust_learning_rate(optimizer, epoch):\n",
    "    \"\"\"For resnet, the lr starts from 0.1, and is divided by 10 at 80 and 120 epochs\"\"\"\n",
    "    adjust_list = [150, 225]\n",
    "    if epoch in adjust_list:\n",
    "        for param_group in optimizer.param_groups:\n",
    "            param_group['lr'] = param_group['lr'] * 0.1"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1f4608aa",
   "metadata": {},
   "source": [
    "### Loading Pre trained w4a4 model for faster convergence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "33abd675",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "=> Loading checkpoint './result/VGG16_4a4w_quant_noskipblock/checkpoint.pth'\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1037538/1623649740.py:3: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(checkpoint_path)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\tSkipping layer 'features.24.weight': Shape mismatch. New: torch.Size([512, 256, 3, 3]) vs Old: torch.Size([16, 256, 3, 3])\n",
      "\tSkipping layer 'features.24.weight_q': Shape mismatch. New: torch.Size([512, 256, 3, 3]) vs Old: torch.Size([16, 256, 3, 3])\n",
      "\tSkipping layer 'features.25.weight': Shape mismatch. New: torch.Size([512]) vs Old: torch.Size([16])\n",
      "\tSkipping layer 'features.25.bias': Shape mismatch. New: torch.Size([512]) vs Old: torch.Size([16])\n",
      "\tSkipping layer 'features.25.running_mean': Shape mismatch. New: torch.Size([512]) vs Old: torch.Size([16])\n",
      "\tSkipping layer 'features.25.running_var': Shape mismatch. New: torch.Size([512]) vs Old: torch.Size([16])\n",
      "\tSkipping layer 'features.27.weight': Shape mismatch. New: torch.Size([512, 512, 3, 3]) vs Old: torch.Size([16, 16, 3, 3])\n",
      "\tSkipping layer 'features.27.weight_q': Shape mismatch. New: torch.Size([512, 512, 3, 3]) vs Old: torch.Size([16, 16, 3, 3])\n",
      "\tSkipping layer 'features.30.weight': Shape mismatch. New: torch.Size([512, 512, 3, 3]) vs Old: torch.Size([512, 16, 3, 3])\n",
      "\tSkipping layer 'features.30.weight_q': Shape mismatch. New: torch.Size([512, 512, 3, 3]) vs Old: torch.Size([512, 16, 3, 3])\n",
      "=> Partial load complete. Mismatched layers initialized randomly.\n"
     ]
    }
   ],
   "source": [
    "def load_checkpoint_special(model, checkpoint_path):\n",
    "    print(f\"=> Loading checkpoint '{checkpoint_path}'\")\n",
    "    checkpoint = torch.load(checkpoint_path)\n",
    "    pretrained_dict = checkpoint['state_dict']\n",
    "    model_dict = model.state_dict()\n",
    "    pretrained_dict_filtered = {}\n",
    "    for k, v in pretrained_dict.items():\n",
    "        if k in model_dict:\n",
    "            if model_dict[k].shape == v.shape:\n",
    "                pretrained_dict_filtered[k] = v\n",
    "            else:\n",
    "                print(f\"\\tSkipping layer '{k}': Shape mismatch. \"\n",
    "                    f\"New: {model_dict[k].shape} vs Old: {v.shape}\")\n",
    "        else:\n",
    "            print(f\"\\tSkipping layer '{k}': Not found in new model.\")\n",
    "    model_dict.update(pretrained_dict_filtered) \n",
    "    model.load_state_dict(model_dict)\n",
    "    print(\"=> Partial load complete. Mismatched layers initialized randomly.\")\n",
    "\n",
    "load_checkpoint_special(model, './result/VGG16_4a4w_quant_noskipblock/checkpoint.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "997936df",
   "metadata": {},
   "source": [
    "### Chokepoint Block and SkipBlock Optimisation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "8d1a4137",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Not using SkipBlock optimisation\n",
      "VGG_quant(\n",
      "  (features): Sequential(\n",
      "    (0): QuantConv2d(\n",
      "      3, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (1): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (2): ReLU(inplace=True)\n",
      "    (3): QuantConv2d(\n",
      "      64, 64, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (4): BatchNorm2d(64, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (5): ReLU(inplace=True)\n",
      "    (6): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (7): QuantConv2d(\n",
      "      64, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (8): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (9): ReLU(inplace=True)\n",
      "    (10): QuantConv2d(\n",
      "      128, 128, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (11): BatchNorm2d(128, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (12): ReLU(inplace=True)\n",
      "    (13): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (14): QuantConv2d(\n",
      "      128, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (15): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (16): ReLU(inplace=True)\n",
      "    (17): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (18): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (19): ReLU(inplace=True)\n",
      "    (20): QuantConv2d(\n",
      "      256, 256, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (21): BatchNorm2d(256, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (22): ReLU(inplace=True)\n",
      "    (23): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (24): QuantConv2d(\n",
      "      256, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (25): BatchNorm2d(16, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (26): ReLU(inplace=True)\n",
      "    (27): QuantConv2d(\n",
      "      16, 16, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (28): Identity()\n",
      "    (29): ReLU(inplace=True)\n",
      "    (30): QuantConv2d(\n",
      "      16, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (31): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (32): ReLU(inplace=True)\n",
      "    (33): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (34): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (35): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (36): ReLU(inplace=True)\n",
      "    (37): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (38): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (39): ReLU(inplace=True)\n",
      "    (40): QuantConv2d(\n",
      "      512, 512, kernel_size=(3, 3), stride=(1, 1), padding=(1, 1), bias=False\n",
      "      (weight_quant): weight_quantize_fn()\n",
      "    )\n",
      "    (41): BatchNorm2d(512, eps=1e-05, momentum=0.1, affine=True, track_running_stats=True)\n",
      "    (42): ReLU(inplace=True)\n",
      "    (43): MaxPool2d(kernel_size=2, stride=2, padding=0, dilation=1, ceil_mode=False)\n",
      "    (44): AvgPool2d(kernel_size=1, stride=1, padding=0)\n",
      "  )\n",
      "  (classifier): Linear(in_features=512, out_features=10, bias=True)\n",
      ")\n"
     ]
    }
   ],
   "source": [
    "# [SEE custom_vgg.py for details on SkipBlock optimisation]\n",
    "from models.custom_vgg import SkipBlock\n",
    "\n",
    "use_skip_block = False\n",
    "\n",
    "model_name = \"VGG16_2a4w_quant_skipblock\" if use_skip_block else \"VGG16_2a4w_quant_noskipblock\"\n",
    "\n",
    "if use_skip_block:\n",
    "    print(\"Using SkipBlock optimisation\")\n",
    "    skip_block = SkipBlock()\n",
    "    model.features[20] = skip_block\n",
    "    for i in range(21, 33):\n",
    "        model.features[i] = nn.Identity()\n",
    "else:\n",
    "    print(\"Not using SkipBlock optimisation\")\n",
    "    model.features[24] = QuantConv2d(256, 16, kernel_size=3, padding=1, bias=False)\n",
    "    model.features[25] = nn.BatchNorm2d(16)\n",
    "    model.features[26] = nn.ReLU(inplace=True)\n",
    "    \n",
    "    model.features[27] = QuantConv2d(16, 16, kernel_size=3, padding=1, bias=False)\n",
    "    model.features[28] = nn.Identity()\n",
    "    model.features[29] = nn.ReLU(inplace=True)\n",
    "    \n",
    "    model.features[30] = QuantConv2d(16, 512, kernel_size=3, padding=1, bias=False)\n",
    "    model.features[31] = nn.BatchNorm2d(512)\n",
    "    model.features[32] = nn.ReLU(inplace=True)\n",
    "\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0602916e",
   "metadata": {},
   "source": [
    "### Training Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a8a4c837",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: [0][0/391]\tTime 0.174 (0.174)\tData 0.130 (0.130)\tLoss 3.1802 (3.1802)\tPrec 10.156% (10.156%)\n",
      "Epoch: [0][100/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.6310 (2.0794)\tPrec 48.438% (26.911%)\n",
      "Epoch: [0][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.5967 (1.8636)\tPrec 52.344% (37.072%)\n",
      "Epoch: [0][300/391]\tTime 0.034 (0.033)\tData 0.002 (0.002)\tLoss 1.6274 (1.7414)\tPrec 52.344% (43.161%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 1.4094 (1.4094)\tPrec 60.156% (60.156%)\n",
      " * Prec 61.730% \n",
      "best acc: 61.730000\n",
      "Epoch: [1][0/391]\tTime 0.189 (0.189)\tData 0.149 (0.149)\tLoss 1.3061 (1.3061)\tPrec 65.625% (65.625%)\n",
      "Epoch: [1][100/391]\tTime 0.030 (0.035)\tData 0.002 (0.004)\tLoss 1.3399 (1.3717)\tPrec 62.500% (61.680%)\n",
      "Epoch: [1][200/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.2620 (1.3457)\tPrec 68.750% (62.924%)\n",
      "Epoch: [1][300/391]\tTime 0.027 (0.033)\tData 0.002 (0.003)\tLoss 1.2681 (1.3310)\tPrec 65.625% (63.626%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.109 (0.109)\tLoss 1.1909 (1.1909)\tPrec 70.312% (70.312%)\n",
      " * Prec 67.380% \n",
      "best acc: 67.380000\n",
      "Epoch: [2][0/391]\tTime 0.166 (0.166)\tData 0.127 (0.127)\tLoss 1.3524 (1.3524)\tPrec 64.844% (64.844%)\n",
      "Epoch: [2][100/391]\tTime 0.035 (0.034)\tData 0.001 (0.003)\tLoss 1.1256 (1.2511)\tPrec 75.781% (67.528%)\n",
      "Epoch: [2][200/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.1084 (1.2456)\tPrec 74.219% (67.926%)\n",
      "Epoch: [2][300/391]\tTime 0.030 (0.033)\tData 0.002 (0.002)\tLoss 1.2989 (1.2420)\tPrec 61.719% (67.930%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.116 (0.116)\tLoss 1.1769 (1.1769)\tPrec 67.969% (67.969%)\n",
      " * Prec 68.710% \n",
      "best acc: 68.710000\n",
      "Epoch: [3][0/391]\tTime 0.183 (0.183)\tData 0.137 (0.137)\tLoss 1.2073 (1.2073)\tPrec 64.844% (64.844%)\n",
      "Epoch: [3][100/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.2216 (1.1818)\tPrec 66.406% (70.459%)\n",
      "Epoch: [3][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.1766 (1.1788)\tPrec 71.094% (70.620%)\n",
      "Epoch: [3][300/391]\tTime 0.035 (0.034)\tData 0.001 (0.003)\tLoss 1.1023 (1.1713)\tPrec 71.094% (70.998%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 1.1819 (1.1819)\tPrec 71.094% (71.094%)\n",
      " * Prec 69.920% \n",
      "best acc: 69.920000\n",
      "Epoch: [4][0/391]\tTime 0.172 (0.172)\tData 0.129 (0.129)\tLoss 1.1374 (1.1374)\tPrec 71.094% (71.094%)\n",
      "Epoch: [4][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.2164 (1.1501)\tPrec 67.188% (71.867%)\n",
      "Epoch: [4][200/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.0435 (1.1393)\tPrec 76.562% (72.345%)\n",
      "Epoch: [4][300/391]\tTime 0.033 (0.034)\tData 0.003 (0.002)\tLoss 1.1523 (1.1332)\tPrec 72.656% (72.545%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.106 (0.106)\tLoss 1.0431 (1.0431)\tPrec 78.906% (78.906%)\n",
      " * Prec 72.340% \n",
      "best acc: 72.340000\n",
      "Epoch: [5][0/391]\tTime 0.167 (0.167)\tData 0.128 (0.128)\tLoss 1.2361 (1.2361)\tPrec 64.062% (64.062%)\n",
      "Epoch: [5][100/391]\tTime 0.030 (0.035)\tData 0.003 (0.003)\tLoss 1.1126 (1.0956)\tPrec 74.219% (74.582%)\n",
      "Epoch: [5][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.0713 (1.0999)\tPrec 79.688% (74.176%)\n",
      "Epoch: [5][300/391]\tTime 0.035 (0.033)\tData 0.003 (0.003)\tLoss 1.1045 (1.0945)\tPrec 71.875% (74.434%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 1.1015 (1.1015)\tPrec 75.000% (75.000%)\n",
      " * Prec 72.480% \n",
      "best acc: 72.480000\n",
      "Epoch: [6][0/391]\tTime 0.166 (0.166)\tData 0.129 (0.129)\tLoss 1.1545 (1.1545)\tPrec 73.438% (73.438%)\n",
      "Epoch: [6][100/391]\tTime 0.030 (0.035)\tData 0.002 (0.003)\tLoss 1.0063 (1.0685)\tPrec 78.125% (75.588%)\n",
      "Epoch: [6][200/391]\tTime 0.038 (0.034)\tData 0.003 (0.003)\tLoss 0.9904 (1.0618)\tPrec 80.469% (75.890%)\n",
      "Epoch: [6][300/391]\tTime 0.033 (0.033)\tData 0.001 (0.003)\tLoss 1.1576 (1.0587)\tPrec 68.750% (75.901%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.105 (0.105)\tLoss 1.0625 (1.0625)\tPrec 77.344% (77.344%)\n",
      " * Prec 74.000% \n",
      "best acc: 74.000000\n",
      "Epoch: [7][0/391]\tTime 0.175 (0.175)\tData 0.136 (0.136)\tLoss 0.9861 (0.9861)\tPrec 78.906% (78.906%)\n",
      "Epoch: [7][100/391]\tTime 0.037 (0.033)\tData 0.002 (0.003)\tLoss 0.8910 (1.0305)\tPrec 83.594% (76.717%)\n",
      "Epoch: [7][200/391]\tTime 0.038 (0.033)\tData 0.001 (0.002)\tLoss 1.2198 (1.0333)\tPrec 68.750% (76.660%)\n",
      "Epoch: [7][300/391]\tTime 0.035 (0.033)\tData 0.002 (0.002)\tLoss 1.0749 (1.0314)\tPrec 75.000% (76.887%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.116 (0.116)\tLoss 1.0978 (1.0978)\tPrec 74.219% (74.219%)\n",
      " * Prec 74.360% \n",
      "best acc: 74.360000\n",
      "Epoch: [8][0/391]\tTime 0.167 (0.167)\tData 0.132 (0.132)\tLoss 0.9227 (0.9227)\tPrec 83.594% (83.594%)\n",
      "Epoch: [8][100/391]\tTime 0.031 (0.034)\tData 0.003 (0.003)\tLoss 1.0642 (1.0067)\tPrec 78.906% (78.110%)\n",
      "Epoch: [8][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.0533 (1.0154)\tPrec 77.344% (77.554%)\n",
      "Epoch: [8][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 0.9175 (1.0156)\tPrec 82.031% (77.570%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.091 (0.091)\tLoss 1.0676 (1.0676)\tPrec 73.438% (73.438%)\n",
      " * Prec 75.960% \n",
      "best acc: 75.960000\n",
      "Epoch: [9][0/391]\tTime 0.175 (0.175)\tData 0.133 (0.133)\tLoss 1.0244 (1.0244)\tPrec 77.344% (77.344%)\n",
      "Epoch: [9][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.0109 (0.9890)\tPrec 81.250% (78.999%)\n",
      "Epoch: [9][200/391]\tTime 0.038 (0.035)\tData 0.002 (0.003)\tLoss 1.0354 (0.9948)\tPrec 78.906% (78.712%)\n",
      "Epoch: [9][300/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.0450 (0.9882)\tPrec 75.781% (78.847%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.111 (0.111)\tLoss 1.0148 (1.0148)\tPrec 77.344% (77.344%)\n",
      " * Prec 76.200% \n",
      "best acc: 76.200000\n",
      "Epoch: [10][0/391]\tTime 0.176 (0.176)\tData 0.131 (0.131)\tLoss 0.9986 (0.9986)\tPrec 78.906% (78.906%)\n",
      "Epoch: [10][100/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.1580 (0.9625)\tPrec 71.875% (79.633%)\n",
      "Epoch: [10][200/391]\tTime 0.034 (0.034)\tData 0.001 (0.003)\tLoss 0.9111 (0.9726)\tPrec 83.594% (79.291%)\n",
      "Epoch: [10][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.002)\tLoss 1.0543 (0.9691)\tPrec 72.656% (79.431%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.109 (0.109)\tLoss 0.9703 (0.9703)\tPrec 82.812% (82.812%)\n",
      " * Prec 76.370% \n",
      "best acc: 76.370000\n",
      "Epoch: [11][0/391]\tTime 0.167 (0.167)\tData 0.139 (0.139)\tLoss 1.0310 (1.0310)\tPrec 80.469% (80.469%)\n",
      "Epoch: [11][100/391]\tTime 0.030 (0.035)\tData 0.001 (0.004)\tLoss 0.9895 (0.9540)\tPrec 79.688% (80.167%)\n",
      "Epoch: [11][200/391]\tTime 0.024 (0.035)\tData 0.002 (0.003)\tLoss 0.9327 (0.9536)\tPrec 82.812% (80.173%)\n",
      "Epoch: [11][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 0.8793 (0.9492)\tPrec 82.812% (80.360%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.127 (0.127)\tLoss 0.9505 (0.9505)\tPrec 81.250% (81.250%)\n",
      " * Prec 77.730% \n",
      "best acc: 77.730000\n",
      "Epoch: [12][0/391]\tTime 0.177 (0.177)\tData 0.135 (0.135)\tLoss 0.9737 (0.9737)\tPrec 77.344% (77.344%)\n",
      "Epoch: [12][100/391]\tTime 0.035 (0.035)\tData 0.002 (0.003)\tLoss 0.9020 (0.9438)\tPrec 80.469% (80.933%)\n",
      "Epoch: [12][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 0.9777 (0.9391)\tPrec 78.125% (81.083%)\n",
      "Epoch: [12][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 0.7763 (0.9343)\tPrec 88.281% (81.141%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.126 (0.126)\tLoss 0.9886 (0.9886)\tPrec 82.812% (82.812%)\n",
      " * Prec 78.240% \n",
      "best acc: 78.240000\n",
      "Epoch: [13][0/391]\tTime 0.166 (0.166)\tData 0.127 (0.127)\tLoss 0.8977 (0.8977)\tPrec 85.156% (85.156%)\n",
      "Epoch: [13][100/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 0.9220 (0.9184)\tPrec 83.594% (82.147%)\n",
      "Epoch: [13][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 0.9050 (0.9201)\tPrec 82.031% (81.794%)\n",
      "Epoch: [13][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 0.8703 (0.9215)\tPrec 84.375% (81.761%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 0.9431 (0.9431)\tPrec 82.812% (82.812%)\n",
      " * Prec 78.600% \n",
      "best acc: 78.600000\n",
      "Epoch: [14][0/391]\tTime 0.168 (0.168)\tData 0.139 (0.139)\tLoss 0.9064 (0.9064)\tPrec 82.812% (82.812%)\n",
      "Epoch: [14][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.004)\tLoss 0.9774 (0.9080)\tPrec 78.906% (82.341%)\n",
      "Epoch: [14][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 0.8650 (0.9042)\tPrec 79.688% (82.521%)\n",
      "Epoch: [14][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 0.8762 (0.9034)\tPrec 83.594% (82.506%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 0.9187 (0.9187)\tPrec 82.031% (82.031%)\n",
      " * Prec 79.080% \n",
      "best acc: 79.080000\n",
      "Epoch: [15][0/391]\tTime 0.176 (0.176)\tData 0.143 (0.143)\tLoss 0.8618 (0.8618)\tPrec 83.594% (83.594%)\n",
      "Epoch: [15][100/391]\tTime 0.024 (0.035)\tData 0.002 (0.004)\tLoss 0.8156 (0.8930)\tPrec 85.938% (82.929%)\n",
      "Epoch: [15][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 0.9026 (0.8931)\tPrec 84.375% (82.910%)\n",
      "Epoch: [15][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.002)\tLoss 0.9282 (0.8921)\tPrec 78.906% (82.919%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.099 (0.099)\tLoss 0.9971 (0.9971)\tPrec 79.688% (79.688%)\n",
      " * Prec 79.570% \n",
      "best acc: 79.570000\n",
      "Epoch: [16][0/391]\tTime 0.156 (0.156)\tData 0.128 (0.128)\tLoss 0.8470 (0.8470)\tPrec 84.375% (84.375%)\n",
      "Epoch: [16][100/391]\tTime 0.035 (0.035)\tData 0.002 (0.003)\tLoss 0.8124 (0.8786)\tPrec 85.156% (83.176%)\n",
      "Epoch: [16][200/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 0.7861 (0.8849)\tPrec 86.719% (83.081%)\n",
      "Epoch: [16][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.0015 (0.8856)\tPrec 79.688% (82.934%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.103 (0.103)\tLoss 0.9722 (0.9722)\tPrec 81.250% (81.250%)\n",
      " * Prec 79.560% \n",
      "best acc: 79.570000\n",
      "Epoch: [17][0/391]\tTime 0.163 (0.163)\tData 0.131 (0.131)\tLoss 0.8496 (0.8496)\tPrec 83.594% (83.594%)\n",
      "Epoch: [17][100/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 0.9262 (0.8672)\tPrec 79.688% (83.942%)\n",
      "Epoch: [17][200/391]\tTime 0.025 (0.034)\tData 0.002 (0.003)\tLoss 0.9186 (0.8656)\tPrec 80.469% (83.920%)\n",
      "Epoch: [17][300/391]\tTime 0.028 (0.034)\tData 0.002 (0.003)\tLoss 0.7886 (0.8681)\tPrec 89.844% (83.846%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.117 (0.117)\tLoss 0.9203 (0.9203)\tPrec 80.469% (80.469%)\n",
      " * Prec 79.890% \n",
      "best acc: 79.890000\n",
      "Epoch: [18][0/391]\tTime 0.184 (0.184)\tData 0.150 (0.150)\tLoss 0.8244 (0.8244)\tPrec 85.156% (85.156%)\n",
      "Epoch: [18][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.004)\tLoss 0.7995 (0.8549)\tPrec 82.812% (84.506%)\n",
      "Epoch: [18][200/391]\tTime 0.034 (0.034)\tData 0.003 (0.003)\tLoss 0.9759 (0.8583)\tPrec 78.906% (84.363%)\n",
      "Epoch: [18][300/391]\tTime 0.040 (0.034)\tData 0.002 (0.003)\tLoss 0.7581 (0.8624)\tPrec 89.062% (84.157%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.120 (0.120)\tLoss 0.9536 (0.9536)\tPrec 81.250% (81.250%)\n",
      " * Prec 79.340% \n",
      "best acc: 79.890000\n",
      "Epoch: [19][0/391]\tTime 0.170 (0.170)\tData 0.127 (0.127)\tLoss 0.8765 (0.8765)\tPrec 83.594% (83.594%)\n",
      "Epoch: [19][100/391]\tTime 0.030 (0.035)\tData 0.002 (0.003)\tLoss 0.9687 (0.8642)\tPrec 79.688% (84.189%)\n",
      "Epoch: [19][200/391]\tTime 0.036 (0.035)\tData 0.002 (0.003)\tLoss 0.8896 (0.8535)\tPrec 80.469% (84.733%)\n",
      "Epoch: [19][300/391]\tTime 0.032 (0.035)\tData 0.002 (0.003)\tLoss 0.9493 (0.8515)\tPrec 78.906% (84.803%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.110 (0.110)\tLoss 0.9746 (0.9746)\tPrec 77.344% (77.344%)\n",
      " * Prec 79.920% \n",
      "best acc: 79.920000\n",
      "Epoch: [20][0/391]\tTime 0.184 (0.184)\tData 0.144 (0.144)\tLoss 0.8619 (0.8619)\tPrec 83.594% (83.594%)\n",
      "Epoch: [20][100/391]\tTime 0.032 (0.035)\tData 0.003 (0.003)\tLoss 0.8517 (0.8357)\tPrec 84.375% (85.481%)\n",
      "Epoch: [20][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 0.8070 (0.8422)\tPrec 88.281% (85.121%)\n",
      "Epoch: [20][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 0.8003 (0.8392)\tPrec 84.375% (85.200%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 0.9026 (0.9026)\tPrec 80.469% (80.469%)\n",
      " * Prec 79.890% \n",
      "best acc: 79.920000\n",
      "Epoch: [21][0/391]\tTime 0.152 (0.152)\tData 0.120 (0.120)\tLoss 0.7504 (0.7504)\tPrec 89.844% (89.844%)\n",
      "Epoch: [21][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.003)\tLoss 0.8026 (0.8540)\tPrec 88.281% (84.862%)\n",
      "Epoch: [21][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 0.9089 (0.8518)\tPrec 82.031% (84.880%)\n",
      "Epoch: [21][300/391]\tTime 0.036 (0.034)\tData 0.003 (0.003)\tLoss 0.8319 (0.8496)\tPrec 84.375% (84.829%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 0.9194 (0.9194)\tPrec 82.812% (82.812%)\n",
      " * Prec 81.150% \n",
      "best acc: 81.150000\n",
      "Epoch: [22][0/391]\tTime 0.175 (0.175)\tData 0.132 (0.132)\tLoss 0.8573 (0.8573)\tPrec 86.719% (86.719%)\n",
      "Epoch: [22][100/391]\tTime 0.027 (0.035)\tData 0.001 (0.003)\tLoss 0.8359 (0.8257)\tPrec 85.938% (86.108%)\n",
      "Epoch: [22][200/391]\tTime 0.037 (0.034)\tData 0.003 (0.003)\tLoss 0.8633 (0.8254)\tPrec 84.375% (85.910%)\n",
      "Epoch: [22][300/391]\tTime 0.037 (0.034)\tData 0.002 (0.002)\tLoss 0.6784 (0.8242)\tPrec 92.969% (85.841%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 0.8937 (0.8937)\tPrec 83.594% (83.594%)\n",
      " * Prec 81.270% \n",
      "best acc: 81.270000\n",
      "Epoch: [23][0/391]\tTime 0.178 (0.178)\tData 0.143 (0.143)\tLoss 0.7934 (0.7934)\tPrec 86.719% (86.719%)\n",
      "Epoch: [23][100/391]\tTime 0.032 (0.034)\tData 0.002 (0.004)\tLoss 0.8004 (0.8115)\tPrec 84.375% (86.425%)\n",
      "Epoch: [23][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 0.8645 (0.8200)\tPrec 84.375% (85.941%)\n",
      "Epoch: [23][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 0.7499 (0.8169)\tPrec 90.625% (86.179%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.110 (0.110)\tLoss 0.8984 (0.8984)\tPrec 82.812% (82.812%)\n",
      " * Prec 82.630% \n",
      "best acc: 82.630000\n",
      "Epoch: [24][0/391]\tTime 0.179 (0.179)\tData 0.143 (0.143)\tLoss 0.8393 (0.8393)\tPrec 81.250% (81.250%)\n",
      "Epoch: [24][100/391]\tTime 0.032 (0.035)\tData 0.003 (0.004)\tLoss 0.6805 (0.7849)\tPrec 92.188% (87.809%)\n",
      "Epoch: [24][200/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 0.8076 (0.7914)\tPrec 81.250% (87.259%)\n",
      "Epoch: [24][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 0.8259 (0.7941)\tPrec 85.938% (87.163%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.103 (0.103)\tLoss 0.7836 (0.7836)\tPrec 86.719% (86.719%)\n",
      " * Prec 82.140% \n",
      "best acc: 82.630000\n",
      "Epoch: [25][0/391]\tTime 0.172 (0.172)\tData 0.135 (0.135)\tLoss 0.7902 (0.7902)\tPrec 83.594% (83.594%)\n",
      "Epoch: [25][100/391]\tTime 0.041 (0.035)\tData 0.003 (0.003)\tLoss 0.7727 (0.7929)\tPrec 86.719% (86.935%)\n",
      "Epoch: [25][200/391]\tTime 0.037 (0.034)\tData 0.003 (0.003)\tLoss 0.7577 (0.7888)\tPrec 90.625% (87.135%)\n",
      "Epoch: [25][300/391]\tTime 0.029 (0.034)\tData 0.002 (0.003)\tLoss 0.7365 (0.7894)\tPrec 89.844% (87.155%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.120 (0.120)\tLoss 0.8149 (0.8149)\tPrec 86.719% (86.719%)\n",
      " * Prec 83.180% \n",
      "best acc: 83.180000\n",
      "Epoch: [26][0/391]\tTime 0.170 (0.170)\tData 0.131 (0.131)\tLoss 0.8508 (0.8508)\tPrec 86.719% (86.719%)\n",
      "Epoch: [26][100/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 0.7485 (0.7742)\tPrec 90.625% (87.956%)\n",
      "Epoch: [26][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 0.8262 (0.7816)\tPrec 86.719% (87.578%)\n",
      "Epoch: [26][300/391]\tTime 0.036 (0.034)\tData 0.002 (0.002)\tLoss 0.7055 (0.7802)\tPrec 89.844% (87.583%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 0.8360 (0.8360)\tPrec 82.812% (82.812%)\n",
      " * Prec 83.220% \n",
      "best acc: 83.220000\n",
      "Epoch: [27][0/391]\tTime 0.164 (0.164)\tData 0.133 (0.133)\tLoss 0.6448 (0.6448)\tPrec 94.531% (94.531%)\n",
      "Epoch: [27][100/391]\tTime 0.036 (0.035)\tData 0.002 (0.003)\tLoss 0.6790 (0.7697)\tPrec 90.625% (88.196%)\n",
      "Epoch: [27][200/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 0.7954 (0.7673)\tPrec 86.719% (88.180%)\n",
      "Epoch: [27][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 0.8073 (0.7671)\tPrec 88.281% (88.237%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.101 (0.101)\tLoss 0.8698 (0.8698)\tPrec 85.156% (85.156%)\n",
      " * Prec 83.420% \n",
      "best acc: 83.420000\n",
      "Epoch: [28][0/391]\tTime 0.168 (0.168)\tData 0.123 (0.123)\tLoss 0.7375 (0.7375)\tPrec 90.625% (90.625%)\n",
      "Epoch: [28][100/391]\tTime 0.036 (0.035)\tData 0.002 (0.003)\tLoss 0.7733 (0.7545)\tPrec 84.375% (88.552%)\n",
      "Epoch: [28][200/391]\tTime 0.040 (0.034)\tData 0.002 (0.003)\tLoss 0.8587 (0.7618)\tPrec 82.812% (88.421%)\n",
      "Epoch: [28][300/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 0.7050 (0.7581)\tPrec 89.844% (88.639%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.8229 (0.8229)\tPrec 85.938% (85.938%)\n",
      " * Prec 84.350% \n",
      "best acc: 84.350000\n",
      "Epoch: [29][0/391]\tTime 0.173 (0.173)\tData 0.132 (0.132)\tLoss 0.8234 (0.8234)\tPrec 85.156% (85.156%)\n",
      "Epoch: [29][100/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 0.7423 (0.7459)\tPrec 89.062% (89.194%)\n",
      "Epoch: [29][200/391]\tTime 0.041 (0.034)\tData 0.002 (0.003)\tLoss 0.7380 (0.7443)\tPrec 88.281% (89.253%)\n",
      "Epoch: [29][300/391]\tTime 0.029 (0.033)\tData 0.001 (0.002)\tLoss 0.7243 (0.7446)\tPrec 88.281% (89.130%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.117 (0.117)\tLoss 0.7875 (0.7875)\tPrec 84.375% (84.375%)\n",
      " * Prec 83.900% \n",
      "best acc: 84.350000\n",
      "Epoch: [30][0/391]\tTime 0.165 (0.165)\tData 0.132 (0.132)\tLoss 0.7343 (0.7343)\tPrec 89.062% (89.062%)\n",
      "Epoch: [30][100/391]\tTime 0.032 (0.035)\tData 0.002 (0.004)\tLoss 0.7543 (0.7290)\tPrec 89.062% (89.906%)\n",
      "Epoch: [30][200/391]\tTime 0.031 (0.035)\tData 0.002 (0.003)\tLoss 0.7140 (0.7279)\tPrec 90.625% (89.918%)\n",
      "Epoch: [30][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 0.7190 (0.7273)\tPrec 89.062% (89.927%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.087 (0.087)\tLoss 0.7049 (0.7049)\tPrec 92.188% (92.188%)\n",
      " * Prec 84.250% \n",
      "best acc: 84.350000\n",
      "Epoch: [31][0/391]\tTime 0.163 (0.163)\tData 0.135 (0.135)\tLoss 0.7992 (0.7992)\tPrec 88.281% (88.281%)\n",
      "Epoch: [31][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.004)\tLoss 0.8388 (0.7292)\tPrec 85.156% (89.735%)\n",
      "Epoch: [31][200/391]\tTime 0.035 (0.035)\tData 0.002 (0.003)\tLoss 0.7082 (0.7260)\tPrec 89.844% (90.054%)\n",
      "Epoch: [31][300/391]\tTime 0.028 (0.035)\tData 0.002 (0.003)\tLoss 0.8557 (0.7284)\tPrec 83.594% (89.953%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.121 (0.121)\tLoss 0.7366 (0.7366)\tPrec 91.406% (91.406%)\n",
      " * Prec 85.170% \n",
      "best acc: 85.170000\n",
      "Epoch: [32][0/391]\tTime 0.179 (0.179)\tData 0.141 (0.141)\tLoss 0.7112 (0.7112)\tPrec 90.625% (90.625%)\n",
      "Epoch: [32][100/391]\tTime 0.037 (0.035)\tData 0.002 (0.004)\tLoss 0.6481 (0.7043)\tPrec 93.750% (91.151%)\n",
      "Epoch: [32][200/391]\tTime 0.032 (0.035)\tData 0.002 (0.003)\tLoss 0.7446 (0.7087)\tPrec 88.281% (90.917%)\n",
      "Epoch: [32][300/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 0.6817 (0.7108)\tPrec 89.844% (90.794%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.123 (0.123)\tLoss 0.8023 (0.8023)\tPrec 88.281% (88.281%)\n",
      " * Prec 85.330% \n",
      "best acc: 85.330000\n",
      "Epoch: [33][0/391]\tTime 0.164 (0.164)\tData 0.136 (0.136)\tLoss 0.7328 (0.7328)\tPrec 89.062% (89.062%)\n",
      "Epoch: [33][100/391]\tTime 0.032 (0.035)\tData 0.002 (0.004)\tLoss 0.7559 (0.6973)\tPrec 87.500% (91.337%)\n",
      "Epoch: [33][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 0.6584 (0.7030)\tPrec 91.406% (91.150%)\n",
      "Epoch: [33][300/391]\tTime 0.029 (0.034)\tData 0.002 (0.003)\tLoss 0.7438 (0.7054)\tPrec 87.500% (90.999%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 0.8222 (0.8222)\tPrec 85.156% (85.156%)\n",
      " * Prec 85.430% \n",
      "best acc: 85.430000\n",
      "Epoch: [34][0/391]\tTime 0.173 (0.173)\tData 0.131 (0.131)\tLoss 0.7210 (0.7210)\tPrec 89.062% (89.062%)\n",
      "Epoch: [34][100/391]\tTime 0.036 (0.035)\tData 0.003 (0.003)\tLoss 0.8665 (0.6957)\tPrec 85.938% (91.538%)\n",
      "Epoch: [34][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 0.7675 (0.6975)\tPrec 86.719% (91.527%)\n",
      "Epoch: [34][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 0.6756 (0.6944)\tPrec 92.188% (91.619%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.8357 (0.8357)\tPrec 85.938% (85.938%)\n",
      " * Prec 85.580% \n",
      "best acc: 85.580000\n",
      "Epoch: [35][0/391]\tTime 0.170 (0.170)\tData 0.128 (0.128)\tLoss 0.6877 (0.6877)\tPrec 92.969% (92.969%)\n",
      "Epoch: [35][100/391]\tTime 0.027 (0.035)\tData 0.001 (0.003)\tLoss 0.6540 (0.6892)\tPrec 95.312% (91.515%)\n",
      "Epoch: [35][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 0.6488 (0.6821)\tPrec 92.969% (91.931%)\n",
      "Epoch: [35][300/391]\tTime 0.039 (0.034)\tData 0.002 (0.003)\tLoss 0.6103 (0.6829)\tPrec 96.094% (91.920%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.097 (0.097)\tLoss 0.7701 (0.7701)\tPrec 89.844% (89.844%)\n",
      " * Prec 85.930% \n",
      "best acc: 85.930000\n",
      "Epoch: [36][0/391]\tTime 0.177 (0.177)\tData 0.138 (0.138)\tLoss 0.7635 (0.7635)\tPrec 89.062% (89.062%)\n",
      "Epoch: [36][100/391]\tTime 0.031 (0.036)\tData 0.002 (0.004)\tLoss 0.7057 (0.6812)\tPrec 92.969% (92.172%)\n",
      "Epoch: [36][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 0.7106 (0.6816)\tPrec 90.625% (92.137%)\n",
      "Epoch: [36][300/391]\tTime 0.036 (0.034)\tData 0.003 (0.003)\tLoss 0.6672 (0.6806)\tPrec 94.531% (92.115%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.111 (0.111)\tLoss 0.7240 (0.7240)\tPrec 89.844% (89.844%)\n",
      " * Prec 85.790% \n",
      "best acc: 85.930000\n",
      "Epoch: [37][0/391]\tTime 0.164 (0.164)\tData 0.132 (0.132)\tLoss 0.6825 (0.6825)\tPrec 91.406% (91.406%)\n",
      "Epoch: [37][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 0.7078 (0.6751)\tPrec 91.406% (92.265%)\n",
      "Epoch: [37][200/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 0.6641 (0.6729)\tPrec 92.969% (92.370%)\n",
      "Epoch: [37][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.002)\tLoss 0.6750 (0.6726)\tPrec 90.625% (92.393%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 0.7394 (0.7394)\tPrec 88.281% (88.281%)\n",
      " * Prec 86.410% \n",
      "best acc: 86.410000\n",
      "Epoch: [38][0/391]\tTime 0.183 (0.183)\tData 0.142 (0.142)\tLoss 0.6706 (0.6706)\tPrec 94.531% (94.531%)\n",
      "Epoch: [38][100/391]\tTime 0.033 (0.035)\tData 0.001 (0.003)\tLoss 0.6625 (0.6626)\tPrec 92.188% (92.876%)\n",
      "Epoch: [38][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 0.6034 (0.6603)\tPrec 94.531% (92.879%)\n",
      "Epoch: [38][300/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 0.7210 (0.6606)\tPrec 90.625% (92.990%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 0.7942 (0.7942)\tPrec 87.500% (87.500%)\n",
      " * Prec 85.840% \n",
      "best acc: 86.410000\n",
      "Epoch: [39][0/391]\tTime 0.158 (0.158)\tData 0.127 (0.127)\tLoss 0.6136 (0.6136)\tPrec 94.531% (94.531%)\n",
      "Epoch: [39][100/391]\tTime 0.032 (0.035)\tData 0.002 (0.003)\tLoss 0.6534 (0.6551)\tPrec 95.312% (93.348%)\n",
      "Epoch: [39][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 0.6398 (0.6562)\tPrec 92.969% (93.264%)\n",
      "Epoch: [39][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 0.6689 (0.6560)\tPrec 91.406% (93.239%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.7151 (0.7151)\tPrec 91.406% (91.406%)\n",
      " * Prec 86.530% \n",
      "best acc: 86.530000\n",
      "Epoch: [40][0/391]\tTime 0.179 (0.179)\tData 0.137 (0.137)\tLoss 0.6139 (0.6139)\tPrec 94.531% (94.531%)\n",
      "Epoch: [40][100/391]\tTime 0.033 (0.035)\tData 0.003 (0.003)\tLoss 0.6127 (0.6428)\tPrec 96.094% (93.750%)\n",
      "Epoch: [40][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 0.6507 (0.6468)\tPrec 91.406% (93.490%)\n",
      "Epoch: [40][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 0.6056 (0.6495)\tPrec 95.312% (93.345%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 0.8630 (0.8630)\tPrec 86.719% (86.719%)\n",
      " * Prec 86.590% \n",
      "best acc: 86.590000\n",
      "Epoch: [41][0/391]\tTime 0.170 (0.170)\tData 0.132 (0.132)\tLoss 0.5883 (0.5883)\tPrec 96.875% (96.875%)\n",
      "Epoch: [41][100/391]\tTime 0.030 (0.034)\tData 0.002 (0.003)\tLoss 0.6456 (0.6380)\tPrec 92.969% (93.974%)\n",
      "Epoch: [41][200/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 0.6122 (0.6443)\tPrec 93.750% (93.762%)\n",
      "Epoch: [41][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 0.6929 (0.6420)\tPrec 91.406% (93.836%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.100 (0.100)\tLoss 0.7251 (0.7251)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.100% \n",
      "best acc: 87.100000\n",
      "Epoch: [42][0/391]\tTime 0.158 (0.158)\tData 0.124 (0.124)\tLoss 0.6122 (0.6122)\tPrec 94.531% (94.531%)\n",
      "Epoch: [42][100/391]\tTime 0.027 (0.035)\tData 0.002 (0.003)\tLoss 0.6199 (0.6317)\tPrec 94.531% (94.230%)\n",
      "Epoch: [42][200/391]\tTime 0.028 (0.034)\tData 0.002 (0.003)\tLoss 0.6626 (0.6382)\tPrec 92.969% (93.890%)\n",
      "Epoch: [42][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 0.5826 (0.6392)\tPrec 97.656% (93.867%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.096 (0.096)\tLoss 0.6864 (0.6864)\tPrec 92.188% (92.188%)\n",
      " * Prec 87.250% \n",
      "best acc: 87.250000\n",
      "Epoch: [43][0/391]\tTime 0.157 (0.157)\tData 0.121 (0.121)\tLoss 0.6176 (0.6176)\tPrec 96.094% (96.094%)\n",
      "Epoch: [43][100/391]\tTime 0.039 (0.035)\tData 0.002 (0.003)\tLoss 0.7001 (0.6294)\tPrec 92.969% (94.191%)\n",
      "Epoch: [43][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 0.5728 (0.6299)\tPrec 96.094% (94.333%)\n",
      "Epoch: [43][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.002)\tLoss 0.5863 (0.6288)\tPrec 95.312% (94.399%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 0.7367 (0.7367)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.020% \n",
      "best acc: 87.250000\n",
      "Epoch: [44][0/391]\tTime 0.170 (0.170)\tData 0.138 (0.138)\tLoss 0.6121 (0.6121)\tPrec 93.750% (93.750%)\n",
      "Epoch: [44][100/391]\tTime 0.038 (0.035)\tData 0.002 (0.003)\tLoss 0.6068 (0.6262)\tPrec 95.312% (94.346%)\n",
      "Epoch: [44][200/391]\tTime 0.029 (0.034)\tData 0.002 (0.003)\tLoss 0.6864 (0.6261)\tPrec 91.406% (94.415%)\n",
      "Epoch: [44][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 0.6114 (0.6271)\tPrec 96.094% (94.396%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.105 (0.105)\tLoss 0.7444 (0.7444)\tPrec 89.062% (89.062%)\n",
      " * Prec 86.940% \n",
      "best acc: 87.250000\n",
      "Epoch: [45][0/391]\tTime 0.170 (0.170)\tData 0.138 (0.138)\tLoss 0.6690 (0.6690)\tPrec 91.406% (91.406%)\n",
      "Epoch: [45][100/391]\tTime 0.033 (0.035)\tData 0.003 (0.004)\tLoss 0.6175 (0.6091)\tPrec 96.094% (95.196%)\n",
      "Epoch: [45][200/391]\tTime 0.035 (0.034)\tData 0.003 (0.003)\tLoss 0.6126 (0.6115)\tPrec 94.531% (95.052%)\n",
      "Epoch: [45][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 0.5649 (0.6122)\tPrec 97.656% (95.040%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 0.7669 (0.7669)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.090% \n",
      "best acc: 87.250000\n",
      "Epoch: [46][0/391]\tTime 0.181 (0.181)\tData 0.140 (0.140)\tLoss 0.6835 (0.6835)\tPrec 92.188% (92.188%)\n",
      "Epoch: [46][100/391]\tTime 0.035 (0.035)\tData 0.002 (0.004)\tLoss 0.5947 (0.6070)\tPrec 96.094% (95.274%)\n",
      "Epoch: [46][200/391]\tTime 0.032 (0.034)\tData 0.003 (0.003)\tLoss 0.5995 (0.6081)\tPrec 97.656% (95.153%)\n",
      "Epoch: [46][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 0.6827 (0.6080)\tPrec 92.188% (95.222%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.108 (0.108)\tLoss 0.7153 (0.7153)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.020% \n",
      "best acc: 87.250000\n",
      "Epoch: [47][0/391]\tTime 0.191 (0.191)\tData 0.151 (0.151)\tLoss 0.6364 (0.6364)\tPrec 95.312% (95.312%)\n",
      "Epoch: [47][100/391]\tTime 0.024 (0.035)\tData 0.001 (0.004)\tLoss 0.5931 (0.6047)\tPrec 96.094% (95.452%)\n",
      "Epoch: [47][200/391]\tTime 0.035 (0.034)\tData 0.001 (0.003)\tLoss 0.6491 (0.6068)\tPrec 94.531% (95.328%)\n",
      "Epoch: [47][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 0.6597 (0.6077)\tPrec 93.750% (95.287%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 0.7803 (0.7803)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.520% \n",
      "best acc: 87.520000\n",
      "Epoch: [48][0/391]\tTime 0.167 (0.167)\tData 0.129 (0.129)\tLoss 0.6572 (0.6572)\tPrec 92.969% (92.969%)\n",
      "Epoch: [48][100/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 0.6135 (0.6079)\tPrec 95.312% (95.196%)\n",
      "Epoch: [48][200/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 0.6641 (0.6095)\tPrec 92.969% (95.204%)\n",
      "Epoch: [48][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 0.6687 (0.6091)\tPrec 92.188% (95.242%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 0.7510 (0.7510)\tPrec 89.844% (89.844%)\n",
      " * Prec 86.650% \n",
      "best acc: 87.520000\n",
      "Epoch: [49][0/391]\tTime 0.167 (0.167)\tData 0.135 (0.135)\tLoss 0.6224 (0.6224)\tPrec 95.312% (95.312%)\n",
      "Epoch: [49][100/391]\tTime 0.029 (0.035)\tData 0.002 (0.004)\tLoss 0.6226 (0.6032)\tPrec 95.312% (95.459%)\n",
      "Epoch: [49][200/391]\tTime 0.032 (0.035)\tData 0.002 (0.003)\tLoss 0.7163 (0.6047)\tPrec 89.844% (95.417%)\n",
      "Epoch: [49][300/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 0.6236 (0.6069)\tPrec 94.531% (95.292%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.104 (0.104)\tLoss 0.7413 (0.7413)\tPrec 90.625% (90.625%)\n",
      " * Prec 88.020% \n",
      "best acc: 88.020000\n",
      "Epoch: [50][0/391]\tTime 0.166 (0.166)\tData 0.137 (0.137)\tLoss 0.6103 (0.6103)\tPrec 93.750% (93.750%)\n",
      "Epoch: [50][100/391]\tTime 0.034 (0.035)\tData 0.002 (0.003)\tLoss 0.6451 (0.6083)\tPrec 93.750% (95.328%)\n",
      "Epoch: [50][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 0.5934 (0.6094)\tPrec 95.312% (95.246%)\n",
      "Epoch: [50][300/391]\tTime 0.040 (0.034)\tData 0.002 (0.003)\tLoss 0.5886 (0.6090)\tPrec 96.875% (95.261%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 0.8626 (0.8626)\tPrec 85.156% (85.156%)\n",
      " * Prec 87.140% \n",
      "best acc: 88.020000\n",
      "Epoch: [51][0/391]\tTime 0.172 (0.172)\tData 0.129 (0.129)\tLoss 0.6467 (0.6467)\tPrec 92.969% (92.969%)\n",
      "Epoch: [51][100/391]\tTime 0.035 (0.035)\tData 0.002 (0.003)\tLoss 0.5765 (0.6043)\tPrec 95.312% (95.444%)\n",
      "Epoch: [51][200/391]\tTime 0.031 (0.034)\tData 0.003 (0.003)\tLoss 0.5920 (0.6078)\tPrec 96.094% (95.254%)\n",
      "Epoch: [51][300/391]\tTime 0.039 (0.034)\tData 0.003 (0.003)\tLoss 0.6271 (0.6110)\tPrec 92.188% (95.128%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.101 (0.101)\tLoss 0.7322 (0.7322)\tPrec 89.062% (89.062%)\n",
      " * Prec 87.620% \n",
      "best acc: 88.020000\n",
      "Epoch: [52][0/391]\tTime 0.175 (0.175)\tData 0.138 (0.138)\tLoss 0.6238 (0.6238)\tPrec 97.656% (97.656%)\n",
      "Epoch: [52][100/391]\tTime 0.031 (0.035)\tData 0.003 (0.004)\tLoss 0.5275 (0.6133)\tPrec 99.219% (95.104%)\n",
      "Epoch: [52][200/391]\tTime 0.036 (0.035)\tData 0.002 (0.003)\tLoss 0.5577 (0.6121)\tPrec 96.094% (95.149%)\n",
      "Epoch: [52][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 0.6229 (0.6144)\tPrec 94.531% (94.993%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.110 (0.110)\tLoss 0.6796 (0.6796)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.790% \n",
      "best acc: 88.020000\n",
      "Epoch: [53][0/391]\tTime 0.176 (0.176)\tData 0.135 (0.135)\tLoss 0.6900 (0.6900)\tPrec 92.188% (92.188%)\n",
      "Epoch: [53][100/391]\tTime 0.038 (0.035)\tData 0.002 (0.003)\tLoss 0.5964 (0.6107)\tPrec 92.969% (95.212%)\n",
      "Epoch: [53][200/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 0.5870 (0.6117)\tPrec 94.531% (95.165%)\n",
      "Epoch: [53][300/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 0.6340 (0.6142)\tPrec 96.094% (94.952%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.110 (0.110)\tLoss 0.6932 (0.6932)\tPrec 91.406% (91.406%)\n",
      " * Prec 87.750% \n",
      "best acc: 88.020000\n",
      "Epoch: [54][0/391]\tTime 0.174 (0.174)\tData 0.131 (0.131)\tLoss 0.6297 (0.6297)\tPrec 93.750% (93.750%)\n",
      "Epoch: [54][100/391]\tTime 0.039 (0.035)\tData 0.002 (0.003)\tLoss 0.7083 (0.6140)\tPrec 92.188% (95.150%)\n",
      "Epoch: [54][200/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 0.5576 (0.6161)\tPrec 96.875% (94.939%)\n",
      "Epoch: [54][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 0.6396 (0.6197)\tPrec 93.750% (94.791%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 0.7188 (0.7188)\tPrec 89.844% (89.844%)\n",
      " * Prec 87.140% \n",
      "best acc: 88.020000\n",
      "Epoch: [55][0/391]\tTime 0.161 (0.161)\tData 0.122 (0.122)\tLoss 0.5641 (0.5641)\tPrec 96.875% (96.875%)\n",
      "Epoch: [55][100/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 0.6067 (0.6256)\tPrec 96.094% (94.423%)\n",
      "Epoch: [55][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 0.6887 (0.6337)\tPrec 91.406% (94.189%)\n",
      "Epoch: [55][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 0.6030 (0.6387)\tPrec 96.094% (94.028%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.117 (0.117)\tLoss 0.8003 (0.8003)\tPrec 87.500% (87.500%)\n",
      " * Prec 84.890% \n",
      "best acc: 88.020000\n",
      "Epoch: [56][0/391]\tTime 0.168 (0.168)\tData 0.130 (0.130)\tLoss 0.6234 (0.6234)\tPrec 93.750% (93.750%)\n",
      "Epoch: [56][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 0.6968 (0.6914)\tPrec 91.406% (91.638%)\n",
      "Epoch: [56][200/391]\tTime 0.024 (0.034)\tData 0.002 (0.003)\tLoss 0.6236 (0.6515)\tPrec 95.312% (93.357%)\n",
      "Epoch: [56][300/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 0.5919 (0.6365)\tPrec 96.875% (94.041%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.103 (0.103)\tLoss 0.7063 (0.7063)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.760% \n",
      "best acc: 88.020000\n",
      "Epoch: [57][0/391]\tTime 0.174 (0.174)\tData 0.140 (0.140)\tLoss 0.5891 (0.5891)\tPrec 94.531% (94.531%)\n",
      "Epoch: [57][100/391]\tTime 0.034 (0.035)\tData 0.003 (0.003)\tLoss 0.5474 (0.6026)\tPrec 99.219% (95.467%)\n",
      "Epoch: [57][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 0.6730 (0.6052)\tPrec 93.750% (95.328%)\n",
      "Epoch: [57][300/391]\tTime 0.035 (0.034)\tData 0.003 (0.003)\tLoss 0.7066 (0.6069)\tPrec 91.406% (95.263%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.108 (0.108)\tLoss 0.6900 (0.6900)\tPrec 92.969% (92.969%)\n",
      " * Prec 87.820% \n",
      "best acc: 88.020000\n",
      "Epoch: [58][0/391]\tTime 0.188 (0.188)\tData 0.150 (0.150)\tLoss 0.6227 (0.6227)\tPrec 95.312% (95.312%)\n",
      "Epoch: [58][100/391]\tTime 0.032 (0.035)\tData 0.002 (0.004)\tLoss 0.5903 (0.6067)\tPrec 96.875% (95.483%)\n",
      "Epoch: [58][200/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 0.6455 (0.6127)\tPrec 92.188% (95.184%)\n",
      "Epoch: [58][300/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 0.6702 (0.6176)\tPrec 92.969% (94.967%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.100 (0.100)\tLoss 0.6988 (0.6988)\tPrec 91.406% (91.406%)\n",
      " * Prec 86.850% \n",
      "best acc: 88.020000\n",
      "Epoch: [59][0/391]\tTime 0.175 (0.175)\tData 0.137 (0.137)\tLoss 0.6235 (0.6235)\tPrec 94.531% (94.531%)\n",
      "Epoch: [59][100/391]\tTime 0.035 (0.035)\tData 0.001 (0.003)\tLoss 0.5951 (0.6409)\tPrec 96.094% (93.874%)\n",
      "Epoch: [59][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 0.6963 (0.6603)\tPrec 89.062% (93.144%)\n",
      "Epoch: [59][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 0.7989 (0.7231)\tPrec 86.719% (90.563%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 0.8768 (0.8768)\tPrec 82.031% (82.031%)\n",
      " * Prec 81.440% \n",
      "best acc: 88.020000\n",
      "Epoch: [60][0/391]\tTime 0.188 (0.188)\tData 0.146 (0.146)\tLoss 0.7156 (0.7156)\tPrec 89.062% (89.062%)\n",
      "Epoch: [60][100/391]\tTime 0.029 (0.035)\tData 0.002 (0.004)\tLoss 0.8763 (0.8108)\tPrec 83.594% (86.711%)\n",
      "Epoch: [60][200/391]\tTime 0.028 (0.034)\tData 0.002 (0.003)\tLoss 0.5829 (0.7384)\tPrec 96.094% (89.820%)\n",
      "Epoch: [60][300/391]\tTime 0.040 (0.034)\tData 0.003 (0.003)\tLoss 0.6684 (0.7020)\tPrec 90.625% (91.362%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.099 (0.099)\tLoss 0.7361 (0.7361)\tPrec 88.281% (88.281%)\n",
      " * Prec 87.460% \n",
      "best acc: 88.020000\n",
      "Epoch: [61][0/391]\tTime 0.175 (0.175)\tData 0.133 (0.133)\tLoss 0.6861 (0.6861)\tPrec 92.188% (92.188%)\n",
      "Epoch: [61][100/391]\tTime 0.032 (0.035)\tData 0.002 (0.003)\tLoss 0.6638 (0.6272)\tPrec 93.750% (94.384%)\n",
      "Epoch: [61][200/391]\tTime 0.032 (0.034)\tData 0.001 (0.003)\tLoss 0.6080 (0.6312)\tPrec 94.531% (94.251%)\n",
      "Epoch: [61][300/391]\tTime 0.031 (0.034)\tData 0.001 (0.003)\tLoss 0.7291 (0.6355)\tPrec 89.062% (94.061%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.121 (0.121)\tLoss 1.1848 (1.1848)\tPrec 71.875% (71.875%)\n",
      " * Prec 74.240% \n",
      "best acc: 88.020000\n",
      "Epoch: [62][0/391]\tTime 0.177 (0.177)\tData 0.142 (0.142)\tLoss 0.9251 (0.9251)\tPrec 84.375% (84.375%)\n",
      "Epoch: [62][100/391]\tTime 0.031 (0.035)\tData 0.003 (0.004)\tLoss 1.3118 (1.2140)\tPrec 64.062% (69.083%)\n",
      "Epoch: [62][200/391]\tTime 0.030 (0.034)\tData 0.002 (0.003)\tLoss 1.3181 (1.2722)\tPrec 68.750% (66.430%)\n",
      "Epoch: [62][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.2691 (1.2707)\tPrec 64.844% (66.528%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.108 (0.108)\tLoss 1.2031 (1.2031)\tPrec 69.531% (69.531%)\n",
      " * Prec 66.040% \n",
      "best acc: 88.020000\n",
      "Epoch: [63][0/391]\tTime 0.205 (0.205)\tData 0.164 (0.164)\tLoss 1.3552 (1.3552)\tPrec 63.281% (63.281%)\n",
      "Epoch: [63][100/391]\tTime 0.035 (0.035)\tData 0.001 (0.004)\tLoss 1.2424 (1.2161)\tPrec 69.531% (68.487%)\n",
      "Epoch: [63][200/391]\tTime 0.031 (0.034)\tData 0.003 (0.003)\tLoss 1.2341 (1.2133)\tPrec 67.969% (68.528%)\n",
      "Epoch: [63][300/391]\tTime 0.039 (0.034)\tData 0.002 (0.003)\tLoss 1.1641 (1.2120)\tPrec 65.625% (68.644%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.111 (0.111)\tLoss 1.1654 (1.1654)\tPrec 67.188% (67.188%)\n",
      " * Prec 68.180% \n",
      "best acc: 88.020000\n",
      "Epoch: [64][0/391]\tTime 0.166 (0.166)\tData 0.130 (0.130)\tLoss 1.2240 (1.2240)\tPrec 69.531% (69.531%)\n",
      "Epoch: [64][100/391]\tTime 0.029 (0.035)\tData 0.003 (0.003)\tLoss 1.1523 (1.1717)\tPrec 74.219% (70.282%)\n",
      "Epoch: [64][200/391]\tTime 0.037 (0.035)\tData 0.002 (0.003)\tLoss 1.1065 (1.1624)\tPrec 72.656% (70.759%)\n",
      "Epoch: [64][300/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.2116 (1.1584)\tPrec 70.312% (71.099%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.117 (0.117)\tLoss 1.1732 (1.1732)\tPrec 72.656% (72.656%)\n",
      " * Prec 70.040% \n",
      "best acc: 88.020000\n",
      "Epoch: [65][0/391]\tTime 0.163 (0.163)\tData 0.132 (0.132)\tLoss 1.1660 (1.1660)\tPrec 68.750% (68.750%)\n",
      "Epoch: [65][100/391]\tTime 0.030 (0.035)\tData 0.002 (0.003)\tLoss 1.1095 (1.1315)\tPrec 73.438% (71.906%)\n",
      "Epoch: [65][200/391]\tTime 0.035 (0.035)\tData 0.002 (0.003)\tLoss 1.0994 (1.1280)\tPrec 75.000% (72.120%)\n",
      "Epoch: [65][300/391]\tTime 0.037 (0.035)\tData 0.003 (0.003)\tLoss 1.1988 (1.1216)\tPrec 69.531% (72.568%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 1.1514 (1.1514)\tPrec 71.094% (71.094%)\n",
      " * Prec 70.070% \n",
      "best acc: 88.020000\n",
      "Epoch: [66][0/391]\tTime 0.180 (0.180)\tData 0.138 (0.138)\tLoss 1.0971 (1.0971)\tPrec 74.219% (74.219%)\n",
      "Epoch: [66][100/391]\tTime 0.036 (0.035)\tData 0.002 (0.003)\tLoss 1.0724 (1.1103)\tPrec 78.125% (72.919%)\n",
      "Epoch: [66][200/391]\tTime 0.029 (0.034)\tData 0.002 (0.003)\tLoss 1.1383 (1.1058)\tPrec 76.562% (73.247%)\n",
      "Epoch: [66][300/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.1400 (1.1066)\tPrec 71.094% (73.245%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.100 (0.100)\tLoss 1.0448 (1.0448)\tPrec 78.906% (78.906%)\n",
      " * Prec 71.760% \n",
      "best acc: 88.020000\n",
      "Epoch: [67][0/391]\tTime 0.170 (0.170)\tData 0.143 (0.143)\tLoss 0.9326 (0.9326)\tPrec 80.469% (80.469%)\n",
      "Epoch: [67][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.004)\tLoss 1.0991 (1.0729)\tPrec 72.656% (75.155%)\n",
      "Epoch: [67][200/391]\tTime 0.031 (0.034)\tData 0.001 (0.003)\tLoss 1.1509 (1.0714)\tPrec 67.188% (75.109%)\n",
      "Epoch: [67][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.0174 (1.0722)\tPrec 75.781% (74.904%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.099 (0.099)\tLoss 1.0944 (1.0944)\tPrec 74.219% (74.219%)\n",
      " * Prec 72.080% \n",
      "best acc: 88.020000\n",
      "Epoch: [68][0/391]\tTime 0.175 (0.175)\tData 0.135 (0.135)\tLoss 1.0161 (1.0161)\tPrec 74.219% (74.219%)\n",
      "Epoch: [68][100/391]\tTime 0.040 (0.034)\tData 0.001 (0.003)\tLoss 1.0309 (1.0726)\tPrec 77.344% (74.629%)\n",
      "Epoch: [68][200/391]\tTime 0.026 (0.034)\tData 0.001 (0.003)\tLoss 0.9759 (1.0694)\tPrec 79.688% (74.852%)\n",
      "Epoch: [68][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.002)\tLoss 1.0429 (1.0630)\tPrec 76.562% (75.164%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.103 (0.103)\tLoss 1.1057 (1.1057)\tPrec 71.094% (71.094%)\n",
      " * Prec 71.040% \n",
      "best acc: 88.020000\n",
      "Epoch: [69][0/391]\tTime 0.164 (0.164)\tData 0.132 (0.132)\tLoss 0.9853 (0.9853)\tPrec 79.688% (79.688%)\n",
      "Epoch: [69][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.003)\tLoss 1.4794 (1.1981)\tPrec 54.688% (69.137%)\n",
      "Epoch: [69][200/391]\tTime 0.036 (0.034)\tData 0.003 (0.003)\tLoss 1.3353 (1.3095)\tPrec 64.062% (64.276%)\n",
      "Epoch: [69][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.5347 (1.3368)\tPrec 56.250% (63.048%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.125 (0.125)\tLoss 1.3791 (1.3791)\tPrec 63.281% (63.281%)\n",
      " * Prec 60.530% \n",
      "best acc: 88.020000\n",
      "Epoch: [70][0/391]\tTime 0.166 (0.166)\tData 0.142 (0.142)\tLoss 1.4192 (1.4192)\tPrec 60.156% (60.156%)\n",
      "Epoch: [70][100/391]\tTime 0.031 (0.035)\tData 0.001 (0.004)\tLoss 1.4456 (1.3743)\tPrec 59.375% (60.814%)\n",
      "Epoch: [70][200/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.2834 (1.3669)\tPrec 66.406% (61.182%)\n",
      "Epoch: [70][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.3024 (1.3632)\tPrec 67.969% (61.516%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 1.3566 (1.3566)\tPrec 67.188% (67.188%)\n",
      " * Prec 61.130% \n",
      "best acc: 88.020000\n",
      "Epoch: [71][0/391]\tTime 0.182 (0.182)\tData 0.141 (0.141)\tLoss 1.3300 (1.3300)\tPrec 66.406% (66.406%)\n",
      "Epoch: [71][100/391]\tTime 0.026 (0.035)\tData 0.001 (0.004)\tLoss 1.3690 (1.3561)\tPrec 57.812% (61.897%)\n",
      "Epoch: [71][200/391]\tTime 0.035 (0.034)\tData 0.003 (0.003)\tLoss 1.4273 (1.3474)\tPrec 58.594% (62.504%)\n",
      "Epoch: [71][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.4869 (1.3465)\tPrec 60.156% (62.365%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.108 (0.108)\tLoss 1.3994 (1.3994)\tPrec 64.844% (64.844%)\n",
      " * Prec 61.440% \n",
      "best acc: 88.020000\n",
      "Epoch: [72][0/391]\tTime 0.174 (0.174)\tData 0.132 (0.132)\tLoss 1.3960 (1.3960)\tPrec 60.156% (60.156%)\n",
      "Epoch: [72][100/391]\tTime 0.036 (0.035)\tData 0.002 (0.003)\tLoss 1.4683 (1.3580)\tPrec 59.375% (61.765%)\n",
      "Epoch: [72][200/391]\tTime 0.032 (0.034)\tData 0.001 (0.003)\tLoss 1.3018 (1.3453)\tPrec 61.719% (62.465%)\n",
      "Epoch: [72][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.3843 (1.3422)\tPrec 61.719% (62.495%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.116 (0.116)\tLoss 1.3885 (1.3885)\tPrec 60.938% (60.938%)\n",
      " * Prec 61.120% \n",
      "best acc: 88.020000\n",
      "Epoch: [73][0/391]\tTime 0.170 (0.170)\tData 0.137 (0.137)\tLoss 1.2622 (1.2622)\tPrec 66.406% (66.406%)\n",
      "Epoch: [73][100/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.2149 (1.3342)\tPrec 69.531% (62.941%)\n",
      "Epoch: [73][200/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.2191 (1.3350)\tPrec 71.094% (62.768%)\n",
      "Epoch: [73][300/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.3150 (1.3400)\tPrec 64.062% (62.505%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.111 (0.111)\tLoss 1.3361 (1.3361)\tPrec 64.844% (64.844%)\n",
      " * Prec 61.880% \n",
      "best acc: 88.020000\n",
      "Epoch: [74][0/391]\tTime 0.173 (0.173)\tData 0.131 (0.131)\tLoss 1.2886 (1.2886)\tPrec 61.719% (61.719%)\n",
      "Epoch: [74][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.3450 (1.3364)\tPrec 60.156% (62.299%)\n",
      "Epoch: [74][200/391]\tTime 0.030 (0.034)\tData 0.003 (0.003)\tLoss 1.2929 (1.3299)\tPrec 60.156% (62.768%)\n",
      "Epoch: [74][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.1562 (1.3315)\tPrec 71.875% (62.830%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 1.3376 (1.3376)\tPrec 65.625% (65.625%)\n",
      " * Prec 61.730% \n",
      "best acc: 88.020000\n",
      "Epoch: [75][0/391]\tTime 0.164 (0.164)\tData 0.130 (0.130)\tLoss 1.3707 (1.3707)\tPrec 58.594% (58.594%)\n",
      "Epoch: [75][100/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.3446 (1.3139)\tPrec 59.375% (63.598%)\n",
      "Epoch: [75][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.3001 (1.3219)\tPrec 64.844% (63.161%)\n",
      "Epoch: [75][300/391]\tTime 0.028 (0.033)\tData 0.001 (0.003)\tLoss 1.2516 (1.3265)\tPrec 67.969% (63.144%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 1.4252 (1.4252)\tPrec 64.844% (64.844%)\n",
      " * Prec 62.080% \n",
      "best acc: 88.020000\n",
      "Epoch: [76][0/391]\tTime 0.157 (0.157)\tData 0.122 (0.122)\tLoss 1.2920 (1.2920)\tPrec 64.062% (64.062%)\n",
      "Epoch: [76][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.003)\tLoss 1.2364 (1.3257)\tPrec 68.750% (63.390%)\n",
      "Epoch: [76][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.2077 (1.3265)\tPrec 71.875% (63.192%)\n",
      "Epoch: [76][300/391]\tTime 0.035 (0.034)\tData 0.003 (0.003)\tLoss 1.3643 (1.3240)\tPrec 60.938% (63.263%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.101 (0.101)\tLoss 1.3418 (1.3418)\tPrec 66.406% (66.406%)\n",
      " * Prec 62.370% \n",
      "best acc: 88.020000\n",
      "Epoch: [77][0/391]\tTime 0.164 (0.164)\tData 0.124 (0.124)\tLoss 1.3604 (1.3604)\tPrec 57.031% (57.031%)\n",
      "Epoch: [77][100/391]\tTime 0.029 (0.035)\tData 0.002 (0.003)\tLoss 1.3839 (1.3206)\tPrec 53.125% (63.057%)\n",
      "Epoch: [77][200/391]\tTime 0.034 (0.035)\tData 0.002 (0.003)\tLoss 1.2440 (1.3217)\tPrec 67.188% (62.955%)\n",
      "Epoch: [77][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.3362 (1.3165)\tPrec 63.281% (63.338%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.110 (0.110)\tLoss 1.3750 (1.3750)\tPrec 63.281% (63.281%)\n",
      " * Prec 62.370% \n",
      "best acc: 88.020000\n",
      "Epoch: [78][0/391]\tTime 0.166 (0.166)\tData 0.130 (0.130)\tLoss 1.2618 (1.2618)\tPrec 67.969% (67.969%)\n",
      "Epoch: [78][100/391]\tTime 0.031 (0.034)\tData 0.003 (0.003)\tLoss 1.2658 (1.3269)\tPrec 67.188% (63.196%)\n",
      "Epoch: [78][200/391]\tTime 0.036 (0.034)\tData 0.003 (0.003)\tLoss 1.2476 (1.3187)\tPrec 67.188% (63.705%)\n",
      "Epoch: [78][300/391]\tTime 0.032 (0.033)\tData 0.003 (0.002)\tLoss 1.2617 (1.3159)\tPrec 63.281% (63.883%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.118 (0.118)\tLoss 1.3735 (1.3735)\tPrec 65.625% (65.625%)\n",
      " * Prec 62.460% \n",
      "best acc: 88.020000\n",
      "Epoch: [79][0/391]\tTime 0.160 (0.160)\tData 0.128 (0.128)\tLoss 1.2767 (1.2767)\tPrec 67.188% (67.188%)\n",
      "Epoch: [79][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.003)\tLoss 1.4851 (1.3177)\tPrec 56.250% (63.428%)\n",
      "Epoch: [79][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.4421 (1.3141)\tPrec 64.844% (63.713%)\n",
      "Epoch: [79][300/391]\tTime 0.033 (0.034)\tData 0.003 (0.003)\tLoss 1.3184 (1.3141)\tPrec 60.938% (63.710%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 1.3174 (1.3174)\tPrec 63.281% (63.281%)\n",
      " * Prec 62.340% \n",
      "best acc: 88.020000\n",
      "Epoch: [80][0/391]\tTime 0.186 (0.186)\tData 0.152 (0.152)\tLoss 1.2560 (1.2560)\tPrec 67.969% (67.969%)\n",
      "Epoch: [80][100/391]\tTime 0.026 (0.034)\tData 0.001 (0.004)\tLoss 1.5332 (1.3224)\tPrec 51.562% (62.763%)\n",
      "Epoch: [80][200/391]\tTime 0.026 (0.034)\tData 0.002 (0.003)\tLoss 1.3559 (1.3145)\tPrec 64.062% (63.340%)\n",
      "Epoch: [80][300/391]\tTime 0.034 (0.033)\tData 0.002 (0.002)\tLoss 1.3332 (1.3165)\tPrec 64.844% (63.232%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 1.3134 (1.3134)\tPrec 64.062% (64.062%)\n",
      " * Prec 62.300% \n",
      "best acc: 88.020000\n",
      "Epoch: [81][0/391]\tTime 0.157 (0.157)\tData 0.125 (0.125)\tLoss 1.3562 (1.3562)\tPrec 60.938% (60.938%)\n",
      "Epoch: [81][100/391]\tTime 0.034 (0.035)\tData 0.002 (0.004)\tLoss 1.3185 (1.3214)\tPrec 61.719% (63.227%)\n",
      "Epoch: [81][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.3501 (1.3216)\tPrec 60.156% (63.301%)\n",
      "Epoch: [81][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.4843 (1.3196)\tPrec 57.031% (63.613%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 1.3584 (1.3584)\tPrec 63.281% (63.281%)\n",
      " * Prec 62.610% \n",
      "best acc: 88.020000\n",
      "Epoch: [82][0/391]\tTime 0.174 (0.174)\tData 0.136 (0.136)\tLoss 1.4090 (1.4090)\tPrec 61.719% (61.719%)\n",
      "Epoch: [82][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.2743 (1.3245)\tPrec 64.844% (63.335%)\n",
      "Epoch: [82][200/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.3998 (1.3122)\tPrec 57.812% (63.759%)\n",
      "Epoch: [82][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.4008 (1.3112)\tPrec 60.156% (63.774%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.110 (0.110)\tLoss 1.3444 (1.3444)\tPrec 65.625% (65.625%)\n",
      " * Prec 62.620% \n",
      "best acc: 88.020000\n",
      "Epoch: [83][0/391]\tTime 0.171 (0.171)\tData 0.132 (0.132)\tLoss 1.4584 (1.4584)\tPrec 57.031% (57.031%)\n",
      "Epoch: [83][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.1939 (1.3124)\tPrec 66.406% (63.451%)\n",
      "Epoch: [83][200/391]\tTime 0.029 (0.034)\tData 0.002 (0.003)\tLoss 1.1907 (1.3132)\tPrec 64.844% (63.584%)\n",
      "Epoch: [83][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.2359 (1.3137)\tPrec 70.312% (63.541%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.103 (0.103)\tLoss 1.3415 (1.3415)\tPrec 66.406% (66.406%)\n",
      " * Prec 62.530% \n",
      "best acc: 88.020000\n",
      "Epoch: [84][0/391]\tTime 0.168 (0.168)\tData 0.132 (0.132)\tLoss 1.3183 (1.3183)\tPrec 61.719% (61.719%)\n",
      "Epoch: [84][100/391]\tTime 0.039 (0.034)\tData 0.002 (0.003)\tLoss 1.4274 (1.3080)\tPrec 60.938% (64.055%)\n",
      "Epoch: [84][200/391]\tTime 0.037 (0.034)\tData 0.003 (0.003)\tLoss 1.3514 (1.3070)\tPrec 59.375% (64.035%)\n",
      "Epoch: [84][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.002)\tLoss 1.3938 (1.3076)\tPrec 59.375% (63.946%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 1.3601 (1.3601)\tPrec 62.500% (62.500%)\n",
      " * Prec 62.700% \n",
      "best acc: 88.020000\n",
      "Epoch: [85][0/391]\tTime 0.167 (0.167)\tData 0.136 (0.136)\tLoss 1.3945 (1.3945)\tPrec 56.250% (56.250%)\n",
      "Epoch: [85][100/391]\tTime 0.028 (0.034)\tData 0.001 (0.004)\tLoss 1.4204 (1.3133)\tPrec 57.031% (64.016%)\n",
      "Epoch: [85][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.2867 (1.3139)\tPrec 60.938% (63.736%)\n",
      "Epoch: [85][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.2659 (1.3112)\tPrec 67.969% (63.803%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.111 (0.111)\tLoss 1.3516 (1.3516)\tPrec 63.281% (63.281%)\n",
      " * Prec 62.320% \n",
      "best acc: 88.020000\n",
      "Epoch: [86][0/391]\tTime 0.171 (0.171)\tData 0.136 (0.136)\tLoss 1.3431 (1.3431)\tPrec 62.500% (62.500%)\n",
      "Epoch: [86][100/391]\tTime 0.034 (0.034)\tData 0.002 (0.004)\tLoss 1.3509 (1.3053)\tPrec 61.719% (63.885%)\n",
      "Epoch: [86][200/391]\tTime 0.030 (0.034)\tData 0.003 (0.003)\tLoss 1.4735 (1.3055)\tPrec 56.250% (63.923%)\n",
      "Epoch: [86][300/391]\tTime 0.029 (0.034)\tData 0.002 (0.003)\tLoss 1.3838 (1.3054)\tPrec 57.812% (63.907%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.105 (0.105)\tLoss 1.2886 (1.2886)\tPrec 64.844% (64.844%)\n",
      " * Prec 62.710% \n",
      "best acc: 88.020000\n",
      "Epoch: [87][0/391]\tTime 0.177 (0.177)\tData 0.136 (0.136)\tLoss 1.2754 (1.2754)\tPrec 64.844% (64.844%)\n",
      "Epoch: [87][100/391]\tTime 0.039 (0.035)\tData 0.003 (0.003)\tLoss 1.1410 (1.3090)\tPrec 72.656% (64.333%)\n",
      "Epoch: [87][200/391]\tTime 0.024 (0.034)\tData 0.002 (0.003)\tLoss 1.3240 (1.3090)\tPrec 59.375% (64.020%)\n",
      "Epoch: [87][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.3214 (1.3087)\tPrec 64.062% (63.969%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 1.3463 (1.3463)\tPrec 65.625% (65.625%)\n",
      " * Prec 62.730% \n",
      "best acc: 88.020000\n",
      "Epoch: [88][0/391]\tTime 0.186 (0.186)\tData 0.145 (0.145)\tLoss 1.3364 (1.3364)\tPrec 63.281% (63.281%)\n",
      "Epoch: [88][100/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.4474 (1.3105)\tPrec 55.469% (63.861%)\n",
      "Epoch: [88][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.1992 (1.3132)\tPrec 69.531% (63.573%)\n",
      "Epoch: [88][300/391]\tTime 0.037 (0.033)\tData 0.003 (0.002)\tLoss 1.2647 (1.3081)\tPrec 67.188% (63.733%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.109 (0.109)\tLoss 1.3326 (1.3326)\tPrec 65.625% (65.625%)\n",
      " * Prec 62.710% \n",
      "best acc: 88.020000\n",
      "Epoch: [89][0/391]\tTime 0.185 (0.185)\tData 0.145 (0.145)\tLoss 1.2562 (1.2562)\tPrec 67.969% (67.969%)\n",
      "Epoch: [89][100/391]\tTime 0.037 (0.035)\tData 0.003 (0.004)\tLoss 1.3709 (1.2870)\tPrec 64.844% (64.581%)\n",
      "Epoch: [89][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.1218 (1.2980)\tPrec 70.312% (64.261%)\n",
      "Epoch: [89][300/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.3515 (1.3022)\tPrec 60.938% (63.933%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.130 (0.130)\tLoss 1.3214 (1.3214)\tPrec 67.969% (67.969%)\n",
      " * Prec 62.360% \n",
      "best acc: 88.020000\n",
      "Epoch: [90][0/391]\tTime 0.170 (0.170)\tData 0.129 (0.129)\tLoss 1.3915 (1.3915)\tPrec 56.250% (56.250%)\n",
      "Epoch: [90][100/391]\tTime 0.024 (0.035)\tData 0.001 (0.003)\tLoss 1.2381 (1.3112)\tPrec 64.844% (63.653%)\n",
      "Epoch: [90][200/391]\tTime 0.038 (0.034)\tData 0.003 (0.003)\tLoss 1.2043 (1.3057)\tPrec 67.969% (63.950%)\n",
      "Epoch: [90][300/391]\tTime 0.027 (0.034)\tData 0.002 (0.003)\tLoss 1.3148 (1.3029)\tPrec 66.406% (64.112%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 1.3954 (1.3954)\tPrec 63.281% (63.281%)\n",
      " * Prec 63.370% \n",
      "best acc: 88.020000\n",
      "Epoch: [91][0/391]\tTime 0.178 (0.178)\tData 0.141 (0.141)\tLoss 1.2117 (1.2117)\tPrec 67.969% (67.969%)\n",
      "Epoch: [91][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.004)\tLoss 1.2588 (1.3165)\tPrec 65.625% (63.459%)\n",
      "Epoch: [91][200/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.2104 (1.3095)\tPrec 67.969% (64.028%)\n",
      "Epoch: [91][300/391]\tTime 0.027 (0.034)\tData 0.002 (0.003)\tLoss 1.3018 (1.3067)\tPrec 62.500% (64.140%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.110 (0.110)\tLoss 1.3587 (1.3587)\tPrec 63.281% (63.281%)\n",
      " * Prec 62.840% \n",
      "best acc: 88.020000\n",
      "Epoch: [92][0/391]\tTime 0.173 (0.173)\tData 0.139 (0.139)\tLoss 1.2959 (1.2959)\tPrec 63.281% (63.281%)\n",
      "Epoch: [92][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.004)\tLoss 1.2846 (1.2949)\tPrec 64.062% (64.751%)\n",
      "Epoch: [92][200/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.3645 (1.2959)\tPrec 64.062% (64.568%)\n",
      "Epoch: [92][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.3214 (1.2979)\tPrec 66.406% (64.317%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.120 (0.120)\tLoss 1.3933 (1.3933)\tPrec 64.062% (64.062%)\n",
      " * Prec 63.250% \n",
      "best acc: 88.020000\n",
      "Epoch: [93][0/391]\tTime 0.171 (0.171)\tData 0.139 (0.139)\tLoss 1.3446 (1.3446)\tPrec 63.281% (63.281%)\n",
      "Epoch: [93][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.004)\tLoss 1.3552 (1.3082)\tPrec 67.969% (63.738%)\n",
      "Epoch: [93][200/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.2814 (1.3040)\tPrec 61.719% (64.016%)\n",
      "Epoch: [93][300/391]\tTime 0.031 (0.034)\tData 0.003 (0.003)\tLoss 1.2656 (1.3064)\tPrec 65.625% (63.930%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.120 (0.120)\tLoss 1.3567 (1.3567)\tPrec 65.625% (65.625%)\n",
      " * Prec 62.960% \n",
      "best acc: 88.020000\n",
      "Epoch: [94][0/391]\tTime 0.155 (0.155)\tData 0.124 (0.124)\tLoss 1.3501 (1.3501)\tPrec 63.281% (63.281%)\n",
      "Epoch: [94][100/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.4354 (1.2991)\tPrec 60.156% (64.349%)\n",
      "Epoch: [94][200/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.2434 (1.3051)\tPrec 63.281% (64.028%)\n",
      "Epoch: [94][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.2769 (1.3036)\tPrec 67.969% (64.166%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.115 (0.115)\tLoss 1.3609 (1.3609)\tPrec 61.719% (61.719%)\n",
      " * Prec 62.840% \n",
      "best acc: 88.020000\n",
      "Epoch: [95][0/391]\tTime 0.165 (0.165)\tData 0.130 (0.130)\tLoss 1.3922 (1.3922)\tPrec 57.812% (57.812%)\n",
      "Epoch: [95][100/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.2254 (1.3040)\tPrec 67.188% (64.341%)\n",
      "Epoch: [95][200/391]\tTime 0.025 (0.034)\tData 0.001 (0.003)\tLoss 1.3546 (1.2978)\tPrec 63.281% (64.424%)\n",
      "Epoch: [95][300/391]\tTime 0.036 (0.033)\tData 0.002 (0.002)\tLoss 1.3217 (1.3007)\tPrec 64.062% (64.218%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 1.3153 (1.3153)\tPrec 68.750% (68.750%)\n",
      " * Prec 63.160% \n",
      "best acc: 88.020000\n",
      "Epoch: [96][0/391]\tTime 0.174 (0.174)\tData 0.142 (0.142)\tLoss 1.2792 (1.2792)\tPrec 64.844% (64.844%)\n",
      "Epoch: [96][100/391]\tTime 0.034 (0.035)\tData 0.003 (0.004)\tLoss 1.2932 (1.2954)\tPrec 64.062% (64.480%)\n",
      "Epoch: [96][200/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.2963 (1.2988)\tPrec 65.625% (64.455%)\n",
      "Epoch: [96][300/391]\tTime 0.040 (0.034)\tData 0.003 (0.003)\tLoss 1.2873 (1.3010)\tPrec 61.719% (64.216%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.119 (0.119)\tLoss 1.3541 (1.3541)\tPrec 67.188% (67.188%)\n",
      " * Prec 63.240% \n",
      "best acc: 88.020000\n",
      "Epoch: [97][0/391]\tTime 0.187 (0.187)\tData 0.147 (0.147)\tLoss 1.2246 (1.2246)\tPrec 67.188% (67.188%)\n",
      "Epoch: [97][100/391]\tTime 0.028 (0.035)\tData 0.002 (0.004)\tLoss 1.2557 (1.3051)\tPrec 64.062% (63.800%)\n",
      "Epoch: [97][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3075 (1.3026)\tPrec 62.500% (63.895%)\n",
      "Epoch: [97][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.4416 (1.3037)\tPrec 57.812% (63.899%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.110 (0.110)\tLoss 1.3203 (1.3203)\tPrec 64.844% (64.844%)\n",
      " * Prec 62.360% \n",
      "best acc: 88.020000\n",
      "Epoch: [98][0/391]\tTime 0.160 (0.160)\tData 0.126 (0.126)\tLoss 1.3382 (1.3382)\tPrec 66.406% (66.406%)\n",
      "Epoch: [98][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.2587 (1.3009)\tPrec 68.750% (64.179%)\n",
      "Epoch: [98][200/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.1993 (1.2972)\tPrec 71.875% (64.234%)\n",
      "Epoch: [98][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.2925 (1.2960)\tPrec 64.062% (64.371%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 1.3503 (1.3503)\tPrec 64.844% (64.844%)\n",
      " * Prec 62.780% \n",
      "best acc: 88.020000\n",
      "Epoch: [99][0/391]\tTime 0.166 (0.166)\tData 0.126 (0.126)\tLoss 1.3019 (1.3019)\tPrec 66.406% (66.406%)\n",
      "Epoch: [99][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.003)\tLoss 1.4516 (1.2962)\tPrec 61.719% (64.573%)\n",
      "Epoch: [99][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.1263 (1.2973)\tPrec 68.750% (64.171%)\n",
      "Epoch: [99][300/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.3793 (1.2939)\tPrec 61.719% (64.371%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.103 (0.103)\tLoss 1.2833 (1.2833)\tPrec 67.969% (67.969%)\n",
      " * Prec 62.870% \n",
      "best acc: 88.020000\n",
      "Epoch: [100][0/391]\tTime 0.163 (0.163)\tData 0.128 (0.128)\tLoss 1.3114 (1.3114)\tPrec 63.281% (63.281%)\n",
      "Epoch: [100][100/391]\tTime 0.030 (0.035)\tData 0.002 (0.003)\tLoss 1.2132 (1.2871)\tPrec 69.531% (65.339%)\n",
      "Epoch: [100][200/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.3465 (1.2948)\tPrec 63.281% (64.712%)\n",
      "Epoch: [100][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.3405 (1.2975)\tPrec 65.625% (64.722%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.106 (0.106)\tLoss 1.3700 (1.3700)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.090% \n",
      "best acc: 88.020000\n",
      "Epoch: [101][0/391]\tTime 0.161 (0.161)\tData 0.129 (0.129)\tLoss 1.3693 (1.3693)\tPrec 58.594% (58.594%)\n",
      "Epoch: [101][100/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.1928 (1.2997)\tPrec 66.406% (64.503%)\n",
      "Epoch: [101][200/391]\tTime 0.039 (0.034)\tData 0.002 (0.003)\tLoss 1.3310 (1.2986)\tPrec 67.188% (64.296%)\n",
      "Epoch: [101][300/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.4285 (1.2975)\tPrec 57.031% (64.410%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.118 (0.118)\tLoss 1.3416 (1.3416)\tPrec 62.500% (62.500%)\n",
      " * Prec 62.840% \n",
      "best acc: 88.020000\n",
      "Epoch: [102][0/391]\tTime 0.160 (0.160)\tData 0.132 (0.132)\tLoss 1.3232 (1.3232)\tPrec 60.156% (60.156%)\n",
      "Epoch: [102][100/391]\tTime 0.038 (0.035)\tData 0.002 (0.003)\tLoss 1.4253 (1.3002)\tPrec 51.562% (63.962%)\n",
      "Epoch: [102][200/391]\tTime 0.026 (0.034)\tData 0.001 (0.003)\tLoss 1.2668 (1.3012)\tPrec 67.188% (64.179%)\n",
      "Epoch: [102][300/391]\tTime 0.037 (0.034)\tData 0.002 (0.002)\tLoss 1.3209 (1.2976)\tPrec 62.500% (64.286%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.108 (0.108)\tLoss 1.3636 (1.3636)\tPrec 63.281% (63.281%)\n",
      " * Prec 62.540% \n",
      "best acc: 88.020000\n",
      "Epoch: [103][0/391]\tTime 0.181 (0.181)\tData 0.141 (0.141)\tLoss 1.3215 (1.3215)\tPrec 62.500% (62.500%)\n",
      "Epoch: [103][100/391]\tTime 0.035 (0.035)\tData 0.003 (0.004)\tLoss 1.2031 (1.2912)\tPrec 64.844% (65.060%)\n",
      "Epoch: [103][200/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.2541 (1.2874)\tPrec 65.625% (65.050%)\n",
      "Epoch: [103][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3361 (1.2933)\tPrec 65.625% (64.756%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 1.3029 (1.3029)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.020% \n",
      "best acc: 88.020000\n",
      "Epoch: [104][0/391]\tTime 0.172 (0.172)\tData 0.131 (0.131)\tLoss 1.2675 (1.2675)\tPrec 64.844% (64.844%)\n",
      "Epoch: [104][100/391]\tTime 0.032 (0.035)\tData 0.001 (0.003)\tLoss 1.3628 (1.2840)\tPrec 62.500% (64.720%)\n",
      "Epoch: [104][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.2813 (1.2905)\tPrec 64.844% (64.381%)\n",
      "Epoch: [104][300/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.3106 (1.2957)\tPrec 63.281% (64.239%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 1.2828 (1.2828)\tPrec 69.531% (69.531%)\n",
      " * Prec 62.750% \n",
      "best acc: 88.020000\n",
      "Epoch: [105][0/391]\tTime 0.179 (0.179)\tData 0.139 (0.139)\tLoss 1.3628 (1.3628)\tPrec 59.375% (59.375%)\n",
      "Epoch: [105][100/391]\tTime 0.038 (0.034)\tData 0.002 (0.004)\tLoss 1.1463 (1.2917)\tPrec 71.094% (64.550%)\n",
      "Epoch: [105][200/391]\tTime 0.037 (0.034)\tData 0.003 (0.003)\tLoss 1.2276 (1.2984)\tPrec 65.625% (64.136%)\n",
      "Epoch: [105][300/391]\tTime 0.035 (0.034)\tData 0.003 (0.003)\tLoss 1.3178 (1.2978)\tPrec 63.281% (64.120%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.116 (0.116)\tLoss 1.2896 (1.2896)\tPrec 64.844% (64.844%)\n",
      " * Prec 62.370% \n",
      "best acc: 88.020000\n",
      "Epoch: [106][0/391]\tTime 0.171 (0.171)\tData 0.148 (0.148)\tLoss 1.2251 (1.2251)\tPrec 67.188% (67.188%)\n",
      "Epoch: [106][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.004)\tLoss 1.3390 (1.2976)\tPrec 61.719% (64.712%)\n",
      "Epoch: [106][200/391]\tTime 0.035 (0.034)\tData 0.001 (0.003)\tLoss 1.3493 (1.2972)\tPrec 62.500% (64.556%)\n",
      "Epoch: [106][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3919 (1.2977)\tPrec 61.719% (64.517%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.119 (0.119)\tLoss 1.4196 (1.4196)\tPrec 62.500% (62.500%)\n",
      " * Prec 62.980% \n",
      "best acc: 88.020000\n",
      "Epoch: [107][0/391]\tTime 0.192 (0.192)\tData 0.151 (0.151)\tLoss 1.3102 (1.3102)\tPrec 60.938% (60.938%)\n",
      "Epoch: [107][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.004)\tLoss 1.3890 (1.2962)\tPrec 60.156% (64.186%)\n",
      "Epoch: [107][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.3540 (1.2934)\tPrec 54.688% (64.451%)\n",
      "Epoch: [107][300/391]\tTime 0.030 (0.034)\tData 0.003 (0.003)\tLoss 1.3638 (1.2908)\tPrec 62.500% (64.608%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.108 (0.108)\tLoss 1.3358 (1.3358)\tPrec 63.281% (63.281%)\n",
      " * Prec 63.320% \n",
      "best acc: 88.020000\n",
      "Epoch: [108][0/391]\tTime 0.171 (0.171)\tData 0.144 (0.144)\tLoss 1.2668 (1.2668)\tPrec 64.844% (64.844%)\n",
      "Epoch: [108][100/391]\tTime 0.037 (0.034)\tData 0.002 (0.004)\tLoss 1.1949 (1.2911)\tPrec 67.188% (64.534%)\n",
      "Epoch: [108][200/391]\tTime 0.037 (0.034)\tData 0.003 (0.003)\tLoss 1.4273 (1.2929)\tPrec 58.594% (64.541%)\n",
      "Epoch: [108][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.1925 (1.2961)\tPrec 62.500% (64.301%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.106 (0.106)\tLoss 1.3547 (1.3547)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.020% \n",
      "best acc: 88.020000\n",
      "Epoch: [109][0/391]\tTime 0.179 (0.179)\tData 0.145 (0.145)\tLoss 1.2044 (1.2044)\tPrec 71.094% (71.094%)\n",
      "Epoch: [109][100/391]\tTime 0.030 (0.035)\tData 0.002 (0.004)\tLoss 1.2254 (1.2905)\tPrec 67.188% (65.014%)\n",
      "Epoch: [109][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.4314 (1.2967)\tPrec 54.688% (64.533%)\n",
      "Epoch: [109][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.2578 (1.2965)\tPrec 71.094% (64.504%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.105 (0.105)\tLoss 1.3399 (1.3399)\tPrec 64.062% (64.062%)\n",
      " * Prec 62.620% \n",
      "best acc: 88.020000\n",
      "Epoch: [110][0/391]\tTime 0.174 (0.174)\tData 0.132 (0.132)\tLoss 1.3621 (1.3621)\tPrec 61.719% (61.719%)\n",
      "Epoch: [110][100/391]\tTime 0.033 (0.035)\tData 0.003 (0.003)\tLoss 1.2832 (1.2879)\tPrec 67.969% (64.619%)\n",
      "Epoch: [110][200/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.3216 (1.2936)\tPrec 60.938% (64.362%)\n",
      "Epoch: [110][300/391]\tTime 0.039 (0.034)\tData 0.002 (0.002)\tLoss 1.2752 (1.2978)\tPrec 66.406% (64.174%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.117 (0.117)\tLoss 1.3275 (1.3275)\tPrec 63.281% (63.281%)\n",
      " * Prec 63.060% \n",
      "best acc: 88.020000\n",
      "Epoch: [111][0/391]\tTime 0.181 (0.181)\tData 0.140 (0.140)\tLoss 1.4618 (1.4618)\tPrec 53.125% (53.125%)\n",
      "Epoch: [111][100/391]\tTime 0.029 (0.035)\tData 0.002 (0.003)\tLoss 1.2961 (1.2942)\tPrec 66.406% (64.093%)\n",
      "Epoch: [111][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3417 (1.2890)\tPrec 61.719% (64.548%)\n",
      "Epoch: [111][300/391]\tTime 0.040 (0.034)\tData 0.003 (0.003)\tLoss 1.3704 (1.2891)\tPrec 60.156% (64.595%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 1.3422 (1.3422)\tPrec 67.969% (67.969%)\n",
      " * Prec 63.140% \n",
      "best acc: 88.020000\n",
      "Epoch: [112][0/391]\tTime 0.168 (0.168)\tData 0.134 (0.134)\tLoss 1.3788 (1.3788)\tPrec 61.719% (61.719%)\n",
      "Epoch: [112][100/391]\tTime 0.029 (0.035)\tData 0.003 (0.003)\tLoss 1.2256 (1.2966)\tPrec 71.875% (64.163%)\n",
      "Epoch: [112][200/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.3246 (1.2919)\tPrec 64.062% (64.288%)\n",
      "Epoch: [112][300/391]\tTime 0.030 (0.034)\tData 0.003 (0.003)\tLoss 1.3553 (1.2890)\tPrec 62.500% (64.509%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.117 (0.117)\tLoss 1.3215 (1.3215)\tPrec 67.188% (67.188%)\n",
      " * Prec 63.200% \n",
      "best acc: 88.020000\n",
      "Epoch: [113][0/391]\tTime 0.184 (0.184)\tData 0.143 (0.143)\tLoss 1.3671 (1.3671)\tPrec 64.062% (64.062%)\n",
      "Epoch: [113][100/391]\tTime 0.030 (0.035)\tData 0.002 (0.003)\tLoss 1.1499 (1.2851)\tPrec 67.969% (64.720%)\n",
      "Epoch: [113][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3102 (1.2918)\tPrec 60.938% (64.708%)\n",
      "Epoch: [113][300/391]\tTime 0.025 (0.034)\tData 0.001 (0.003)\tLoss 1.2698 (1.2928)\tPrec 67.969% (64.579%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.106 (0.106)\tLoss 1.3300 (1.3300)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.220% \n",
      "best acc: 88.020000\n",
      "Epoch: [114][0/391]\tTime 0.164 (0.164)\tData 0.130 (0.130)\tLoss 1.2754 (1.2754)\tPrec 64.062% (64.062%)\n",
      "Epoch: [114][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.003)\tLoss 1.3359 (1.3003)\tPrec 65.625% (63.970%)\n",
      "Epoch: [114][200/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.2074 (1.3011)\tPrec 67.969% (63.868%)\n",
      "Epoch: [114][300/391]\tTime 0.035 (0.034)\tData 0.003 (0.003)\tLoss 1.2477 (1.2927)\tPrec 64.844% (64.501%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 1.3735 (1.3735)\tPrec 64.844% (64.844%)\n",
      " * Prec 62.880% \n",
      "best acc: 88.020000\n",
      "Epoch: [115][0/391]\tTime 0.184 (0.184)\tData 0.151 (0.151)\tLoss 1.2690 (1.2690)\tPrec 65.625% (65.625%)\n",
      "Epoch: [115][100/391]\tTime 0.034 (0.035)\tData 0.002 (0.004)\tLoss 1.2491 (1.2987)\tPrec 71.094% (64.604%)\n",
      "Epoch: [115][200/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.2565 (1.2918)\tPrec 64.844% (64.793%)\n",
      "Epoch: [115][300/391]\tTime 0.027 (0.034)\tData 0.002 (0.003)\tLoss 1.2224 (1.2910)\tPrec 67.188% (64.735%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.110 (0.110)\tLoss 1.3861 (1.3861)\tPrec 61.719% (61.719%)\n",
      " * Prec 62.940% \n",
      "best acc: 88.020000\n",
      "Epoch: [116][0/391]\tTime 0.175 (0.175)\tData 0.133 (0.133)\tLoss 1.2835 (1.2835)\tPrec 60.938% (60.938%)\n",
      "Epoch: [116][100/391]\tTime 0.037 (0.034)\tData 0.003 (0.003)\tLoss 1.3025 (1.2829)\tPrec 61.719% (64.759%)\n",
      "Epoch: [116][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.2626 (1.2829)\tPrec 67.188% (64.852%)\n",
      "Epoch: [116][300/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.2498 (1.2880)\tPrec 67.188% (64.753%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.106 (0.106)\tLoss 1.3090 (1.3090)\tPrec 69.531% (69.531%)\n",
      " * Prec 63.130% \n",
      "best acc: 88.020000\n",
      "Epoch: [117][0/391]\tTime 0.167 (0.167)\tData 0.133 (0.133)\tLoss 1.3858 (1.3858)\tPrec 62.500% (62.500%)\n",
      "Epoch: [117][100/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.2978 (1.2903)\tPrec 65.625% (64.774%)\n",
      "Epoch: [117][200/391]\tTime 0.026 (0.034)\tData 0.002 (0.003)\tLoss 1.3549 (1.2884)\tPrec 63.281% (64.918%)\n",
      "Epoch: [117][300/391]\tTime 0.032 (0.034)\tData 0.001 (0.003)\tLoss 1.2871 (1.2869)\tPrec 65.625% (64.966%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.103 (0.103)\tLoss 1.3843 (1.3843)\tPrec 60.938% (60.938%)\n",
      " * Prec 62.890% \n",
      "best acc: 88.020000\n",
      "Epoch: [118][0/391]\tTime 0.174 (0.174)\tData 0.141 (0.141)\tLoss 1.1643 (1.1643)\tPrec 71.875% (71.875%)\n",
      "Epoch: [118][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.004)\tLoss 1.3790 (1.2745)\tPrec 61.719% (65.184%)\n",
      "Epoch: [118][200/391]\tTime 0.039 (0.034)\tData 0.003 (0.003)\tLoss 1.2399 (1.2847)\tPrec 67.969% (64.782%)\n",
      "Epoch: [118][300/391]\tTime 0.031 (0.034)\tData 0.001 (0.003)\tLoss 1.3113 (1.2847)\tPrec 65.625% (64.818%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.108 (0.108)\tLoss 1.3050 (1.3050)\tPrec 67.969% (67.969%)\n",
      " * Prec 62.910% \n",
      "best acc: 88.020000\n",
      "Epoch: [119][0/391]\tTime 0.154 (0.154)\tData 0.127 (0.127)\tLoss 1.2839 (1.2839)\tPrec 66.406% (66.406%)\n",
      "Epoch: [119][100/391]\tTime 0.024 (0.034)\tData 0.002 (0.003)\tLoss 1.3660 (1.2712)\tPrec 60.938% (65.617%)\n",
      "Epoch: [119][200/391]\tTime 0.041 (0.034)\tData 0.002 (0.003)\tLoss 1.2562 (1.2801)\tPrec 66.406% (65.139%)\n",
      "Epoch: [119][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3953 (1.2841)\tPrec 57.031% (64.942%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 1.3310 (1.3310)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.340% \n",
      "best acc: 88.020000\n",
      "Epoch: [120][0/391]\tTime 0.180 (0.180)\tData 0.146 (0.146)\tLoss 1.3097 (1.3097)\tPrec 64.062% (64.062%)\n",
      "Epoch: [120][100/391]\tTime 0.034 (0.035)\tData 0.002 (0.003)\tLoss 1.2120 (1.2895)\tPrec 68.750% (64.619%)\n",
      "Epoch: [120][200/391]\tTime 0.029 (0.034)\tData 0.002 (0.003)\tLoss 1.3326 (1.2898)\tPrec 60.938% (64.712%)\n",
      "Epoch: [120][300/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.3755 (1.2883)\tPrec 60.156% (64.859%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.117 (0.117)\tLoss 1.3645 (1.3645)\tPrec 63.281% (63.281%)\n",
      " * Prec 63.130% \n",
      "best acc: 88.020000\n",
      "Epoch: [121][0/391]\tTime 0.185 (0.185)\tData 0.150 (0.150)\tLoss 1.2325 (1.2325)\tPrec 70.312% (70.312%)\n",
      "Epoch: [121][100/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.3384 (1.2866)\tPrec 64.844% (65.084%)\n",
      "Epoch: [121][200/391]\tTime 0.026 (0.034)\tData 0.002 (0.003)\tLoss 1.2495 (1.2879)\tPrec 67.969% (64.910%)\n",
      "Epoch: [121][300/391]\tTime 0.029 (0.034)\tData 0.002 (0.002)\tLoss 1.2266 (1.2901)\tPrec 69.531% (64.693%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.121 (0.121)\tLoss 1.4242 (1.4242)\tPrec 62.500% (62.500%)\n",
      " * Prec 63.080% \n",
      "best acc: 88.020000\n",
      "Epoch: [122][0/391]\tTime 0.175 (0.175)\tData 0.142 (0.142)\tLoss 1.2569 (1.2569)\tPrec 64.844% (64.844%)\n",
      "Epoch: [122][100/391]\tTime 0.029 (0.035)\tData 0.002 (0.003)\tLoss 1.2772 (1.2856)\tPrec 67.969% (64.604%)\n",
      "Epoch: [122][200/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.2695 (1.2880)\tPrec 64.844% (64.412%)\n",
      "Epoch: [122][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.3577 (1.2885)\tPrec 61.719% (64.615%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 1.3751 (1.3751)\tPrec 64.844% (64.844%)\n",
      " * Prec 62.880% \n",
      "best acc: 88.020000\n",
      "Epoch: [123][0/391]\tTime 0.159 (0.159)\tData 0.122 (0.122)\tLoss 1.2384 (1.2384)\tPrec 67.188% (67.188%)\n",
      "Epoch: [123][100/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.3140 (1.2855)\tPrec 63.281% (64.735%)\n",
      "Epoch: [123][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.2154 (1.2917)\tPrec 67.969% (64.447%)\n",
      "Epoch: [123][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.3071 (1.2877)\tPrec 65.625% (64.670%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.104 (0.104)\tLoss 1.3804 (1.3804)\tPrec 64.062% (64.062%)\n",
      " * Prec 63.140% \n",
      "best acc: 88.020000\n",
      "Epoch: [124][0/391]\tTime 0.173 (0.173)\tData 0.132 (0.132)\tLoss 1.3441 (1.3441)\tPrec 63.281% (63.281%)\n",
      "Epoch: [124][100/391]\tTime 0.034 (0.034)\tData 0.003 (0.003)\tLoss 1.3277 (1.2850)\tPrec 63.281% (65.068%)\n",
      "Epoch: [124][200/391]\tTime 0.029 (0.034)\tData 0.002 (0.003)\tLoss 1.2243 (1.2813)\tPrec 67.969% (65.061%)\n",
      "Epoch: [124][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.3274 (1.2832)\tPrec 63.281% (64.922%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.110 (0.110)\tLoss 1.4027 (1.4027)\tPrec 62.500% (62.500%)\n",
      " * Prec 63.650% \n",
      "best acc: 88.020000\n",
      "Epoch: [125][0/391]\tTime 0.182 (0.182)\tData 0.148 (0.148)\tLoss 1.3221 (1.3221)\tPrec 64.062% (64.062%)\n",
      "Epoch: [125][100/391]\tTime 0.029 (0.035)\tData 0.001 (0.004)\tLoss 1.2409 (1.2844)\tPrec 68.750% (65.246%)\n",
      "Epoch: [125][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.2932 (1.2849)\tPrec 64.062% (64.980%)\n",
      "Epoch: [125][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.4452 (1.2847)\tPrec 57.812% (64.784%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.115 (0.115)\tLoss 1.2956 (1.2956)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.540% \n",
      "best acc: 88.020000\n",
      "Epoch: [126][0/391]\tTime 0.174 (0.174)\tData 0.136 (0.136)\tLoss 1.2498 (1.2498)\tPrec 66.406% (66.406%)\n",
      "Epoch: [126][100/391]\tTime 0.036 (0.035)\tData 0.002 (0.003)\tLoss 1.2699 (1.2725)\tPrec 67.188% (65.470%)\n",
      "Epoch: [126][200/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.2153 (1.2831)\tPrec 71.094% (64.840%)\n",
      "Epoch: [126][300/391]\tTime 0.029 (0.034)\tData 0.002 (0.003)\tLoss 1.2172 (1.2826)\tPrec 64.062% (64.724%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.099 (0.099)\tLoss 1.3648 (1.3648)\tPrec 63.281% (63.281%)\n",
      " * Prec 63.430% \n",
      "best acc: 88.020000\n",
      "Epoch: [127][0/391]\tTime 0.182 (0.182)\tData 0.142 (0.142)\tLoss 1.3054 (1.3054)\tPrec 60.938% (60.938%)\n",
      "Epoch: [127][100/391]\tTime 0.030 (0.035)\tData 0.002 (0.003)\tLoss 1.2229 (1.2823)\tPrec 61.719% (65.053%)\n",
      "Epoch: [127][200/391]\tTime 0.035 (0.034)\tData 0.003 (0.003)\tLoss 1.1519 (1.2828)\tPrec 71.094% (65.190%)\n",
      "Epoch: [127][300/391]\tTime 0.036 (0.033)\tData 0.002 (0.003)\tLoss 1.3394 (1.2851)\tPrec 62.500% (64.896%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.104 (0.104)\tLoss 1.3316 (1.3316)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.300% \n",
      "best acc: 88.020000\n",
      "Epoch: [128][0/391]\tTime 0.160 (0.160)\tData 0.129 (0.129)\tLoss 1.1587 (1.1587)\tPrec 71.094% (71.094%)\n",
      "Epoch: [128][100/391]\tTime 0.038 (0.035)\tData 0.003 (0.003)\tLoss 1.2438 (1.2889)\tPrec 62.500% (64.588%)\n",
      "Epoch: [128][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.3523 (1.2877)\tPrec 64.062% (64.778%)\n",
      "Epoch: [128][300/391]\tTime 0.031 (0.034)\tData 0.003 (0.003)\tLoss 1.3891 (1.2880)\tPrec 57.812% (64.634%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 1.3873 (1.3873)\tPrec 64.062% (64.062%)\n",
      " * Prec 63.450% \n",
      "best acc: 88.020000\n",
      "Epoch: [129][0/391]\tTime 0.173 (0.173)\tData 0.140 (0.140)\tLoss 1.2303 (1.2303)\tPrec 67.969% (67.969%)\n",
      "Epoch: [129][100/391]\tTime 0.035 (0.035)\tData 0.002 (0.004)\tLoss 1.3175 (1.2700)\tPrec 60.156% (65.223%)\n",
      "Epoch: [129][200/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.3042 (1.2809)\tPrec 64.062% (64.921%)\n",
      "Epoch: [129][300/391]\tTime 0.030 (0.034)\tData 0.002 (0.003)\tLoss 1.2500 (1.2800)\tPrec 64.844% (65.046%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.108 (0.108)\tLoss 1.3207 (1.3207)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.520% \n",
      "best acc: 88.020000\n",
      "Epoch: [130][0/391]\tTime 0.173 (0.173)\tData 0.144 (0.144)\tLoss 1.3053 (1.3053)\tPrec 62.500% (62.500%)\n",
      "Epoch: [130][100/391]\tTime 0.032 (0.035)\tData 0.002 (0.004)\tLoss 1.2354 (1.2779)\tPrec 66.406% (65.107%)\n",
      "Epoch: [130][200/391]\tTime 0.041 (0.034)\tData 0.003 (0.003)\tLoss 1.1321 (1.2810)\tPrec 71.094% (64.867%)\n",
      "Epoch: [130][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.4243 (1.2819)\tPrec 58.594% (64.903%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 1.3781 (1.3781)\tPrec 63.281% (63.281%)\n",
      " * Prec 63.420% \n",
      "best acc: 88.020000\n",
      "Epoch: [131][0/391]\tTime 0.159 (0.159)\tData 0.129 (0.129)\tLoss 1.3425 (1.3425)\tPrec 63.281% (63.281%)\n",
      "Epoch: [131][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.004)\tLoss 1.2517 (1.2697)\tPrec 64.062% (65.695%)\n",
      "Epoch: [131][200/391]\tTime 0.027 (0.034)\tData 0.002 (0.003)\tLoss 1.3304 (1.2744)\tPrec 58.594% (65.473%)\n",
      "Epoch: [131][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.2933 (1.2763)\tPrec 64.062% (65.391%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.110 (0.110)\tLoss 1.3399 (1.3399)\tPrec 63.281% (63.281%)\n",
      " * Prec 63.050% \n",
      "best acc: 88.020000\n",
      "Epoch: [132][0/391]\tTime 0.181 (0.181)\tData 0.140 (0.140)\tLoss 1.2412 (1.2412)\tPrec 64.844% (64.844%)\n",
      "Epoch: [132][100/391]\tTime 0.030 (0.035)\tData 0.002 (0.004)\tLoss 1.1821 (1.2735)\tPrec 71.875% (65.540%)\n",
      "Epoch: [132][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.2612 (1.2761)\tPrec 63.281% (65.407%)\n",
      "Epoch: [132][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.3048 (1.2773)\tPrec 55.469% (65.293%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 1.3855 (1.3855)\tPrec 61.719% (61.719%)\n",
      " * Prec 63.060% \n",
      "best acc: 88.020000\n",
      "Epoch: [133][0/391]\tTime 0.153 (0.153)\tData 0.126 (0.126)\tLoss 1.2735 (1.2735)\tPrec 66.406% (66.406%)\n",
      "Epoch: [133][100/391]\tTime 0.028 (0.035)\tData 0.002 (0.004)\tLoss 1.3144 (1.2695)\tPrec 64.844% (65.625%)\n",
      "Epoch: [133][200/391]\tTime 0.039 (0.034)\tData 0.002 (0.003)\tLoss 1.2857 (1.2767)\tPrec 64.844% (65.182%)\n",
      "Epoch: [133][300/391]\tTime 0.033 (0.034)\tData 0.003 (0.003)\tLoss 1.2588 (1.2788)\tPrec 66.406% (64.927%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.110 (0.110)\tLoss 1.3473 (1.3473)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.330% \n",
      "best acc: 88.020000\n",
      "Epoch: [134][0/391]\tTime 0.180 (0.180)\tData 0.135 (0.135)\tLoss 1.1966 (1.1966)\tPrec 62.500% (62.500%)\n",
      "Epoch: [134][100/391]\tTime 0.030 (0.034)\tData 0.003 (0.003)\tLoss 1.3275 (1.2790)\tPrec 59.375% (65.060%)\n",
      "Epoch: [134][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.4003 (1.2800)\tPrec 63.281% (65.112%)\n",
      "Epoch: [134][300/391]\tTime 0.034 (0.033)\tData 0.002 (0.002)\tLoss 1.2480 (1.2817)\tPrec 66.406% (64.948%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.097 (0.097)\tLoss 1.4150 (1.4150)\tPrec 61.719% (61.719%)\n",
      " * Prec 63.590% \n",
      "best acc: 88.020000\n",
      "Epoch: [135][0/391]\tTime 0.193 (0.193)\tData 0.152 (0.152)\tLoss 1.1319 (1.1319)\tPrec 71.094% (71.094%)\n",
      "Epoch: [135][100/391]\tTime 0.037 (0.035)\tData 0.002 (0.004)\tLoss 1.2593 (1.2792)\tPrec 62.500% (64.681%)\n",
      "Epoch: [135][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3305 (1.2853)\tPrec 60.156% (64.611%)\n",
      "Epoch: [135][300/391]\tTime 0.035 (0.034)\tData 0.003 (0.003)\tLoss 1.1524 (1.2853)\tPrec 71.094% (64.735%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.100 (0.100)\tLoss 1.3776 (1.3776)\tPrec 63.281% (63.281%)\n",
      " * Prec 62.610% \n",
      "best acc: 88.020000\n",
      "Epoch: [136][0/391]\tTime 0.170 (0.170)\tData 0.135 (0.135)\tLoss 1.3010 (1.3010)\tPrec 66.406% (66.406%)\n",
      "Epoch: [136][100/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.3008 (1.2905)\tPrec 62.500% (64.434%)\n",
      "Epoch: [136][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.1855 (1.2830)\tPrec 68.750% (65.034%)\n",
      "Epoch: [136][300/391]\tTime 0.038 (0.034)\tData 0.001 (0.003)\tLoss 1.2884 (1.2871)\tPrec 66.406% (64.685%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.120 (0.120)\tLoss 1.3734 (1.3734)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.800% \n",
      "best acc: 88.020000\n",
      "Epoch: [137][0/391]\tTime 0.174 (0.174)\tData 0.133 (0.133)\tLoss 1.3564 (1.3564)\tPrec 58.594% (58.594%)\n",
      "Epoch: [137][100/391]\tTime 0.030 (0.035)\tData 0.003 (0.004)\tLoss 1.1714 (1.2885)\tPrec 71.094% (64.295%)\n",
      "Epoch: [137][200/391]\tTime 0.034 (0.034)\tData 0.001 (0.003)\tLoss 1.3782 (1.2866)\tPrec 64.844% (64.548%)\n",
      "Epoch: [137][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.3141 (1.2826)\tPrec 64.062% (64.870%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.101 (0.101)\tLoss 1.3692 (1.3692)\tPrec 64.062% (64.062%)\n",
      " * Prec 63.220% \n",
      "best acc: 88.020000\n",
      "Epoch: [138][0/391]\tTime 0.161 (0.161)\tData 0.128 (0.128)\tLoss 1.3869 (1.3869)\tPrec 60.938% (60.938%)\n",
      "Epoch: [138][100/391]\tTime 0.035 (0.035)\tData 0.003 (0.004)\tLoss 1.3059 (1.2817)\tPrec 62.500% (64.681%)\n",
      "Epoch: [138][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.4209 (1.2862)\tPrec 58.594% (64.669%)\n",
      "Epoch: [138][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.3080 (1.2836)\tPrec 66.406% (64.750%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 1.3699 (1.3699)\tPrec 63.281% (63.281%)\n",
      " * Prec 62.940% \n",
      "best acc: 88.020000\n",
      "Epoch: [139][0/391]\tTime 0.181 (0.181)\tData 0.138 (0.138)\tLoss 1.2979 (1.2979)\tPrec 64.062% (64.062%)\n",
      "Epoch: [139][100/391]\tTime 0.032 (0.035)\tData 0.002 (0.003)\tLoss 1.3624 (1.2706)\tPrec 59.375% (65.563%)\n",
      "Epoch: [139][200/391]\tTime 0.037 (0.034)\tData 0.003 (0.003)\tLoss 1.1929 (1.2761)\tPrec 68.750% (65.314%)\n",
      "Epoch: [139][300/391]\tTime 0.040 (0.034)\tData 0.002 (0.003)\tLoss 1.3538 (1.2790)\tPrec 62.500% (65.145%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.109 (0.109)\tLoss 1.3112 (1.3112)\tPrec 63.281% (63.281%)\n",
      " * Prec 63.550% \n",
      "best acc: 88.020000\n",
      "Epoch: [140][0/391]\tTime 0.187 (0.187)\tData 0.152 (0.152)\tLoss 1.1187 (1.1187)\tPrec 74.219% (74.219%)\n",
      "Epoch: [140][100/391]\tTime 0.034 (0.035)\tData 0.002 (0.004)\tLoss 1.2931 (1.2781)\tPrec 61.719% (65.664%)\n",
      "Epoch: [140][200/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.1728 (1.2753)\tPrec 67.188% (65.419%)\n",
      "Epoch: [140][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.3078 (1.2751)\tPrec 64.062% (65.459%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 1.3589 (1.3589)\tPrec 67.188% (67.188%)\n",
      " * Prec 63.480% \n",
      "best acc: 88.020000\n",
      "Epoch: [141][0/391]\tTime 0.180 (0.180)\tData 0.141 (0.141)\tLoss 1.2676 (1.2676)\tPrec 61.719% (61.719%)\n",
      "Epoch: [141][100/391]\tTime 0.032 (0.035)\tData 0.002 (0.004)\tLoss 1.1957 (1.2762)\tPrec 67.969% (65.633%)\n",
      "Epoch: [141][200/391]\tTime 0.032 (0.035)\tData 0.002 (0.003)\tLoss 1.3924 (1.2773)\tPrec 59.375% (65.116%)\n",
      "Epoch: [141][300/391]\tTime 0.027 (0.034)\tData 0.001 (0.003)\tLoss 1.2734 (1.2784)\tPrec 64.844% (65.072%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 1.3570 (1.3570)\tPrec 64.062% (64.062%)\n",
      " * Prec 63.690% \n",
      "best acc: 88.020000\n",
      "Epoch: [142][0/391]\tTime 0.187 (0.187)\tData 0.145 (0.145)\tLoss 1.1858 (1.1858)\tPrec 73.438% (73.438%)\n",
      "Epoch: [142][100/391]\tTime 0.034 (0.034)\tData 0.003 (0.004)\tLoss 1.1812 (1.2765)\tPrec 71.875% (64.898%)\n",
      "Epoch: [142][200/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.1879 (1.2790)\tPrec 70.312% (64.945%)\n",
      "Epoch: [142][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.2489 (1.2807)\tPrec 68.750% (64.836%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 1.3208 (1.3208)\tPrec 63.281% (63.281%)\n",
      " * Prec 64.130% \n",
      "best acc: 88.020000\n",
      "Epoch: [143][0/391]\tTime 0.139 (0.139)\tData 0.117 (0.117)\tLoss 1.0805 (1.0805)\tPrec 74.219% (74.219%)\n",
      "Epoch: [143][100/391]\tTime 0.039 (0.035)\tData 0.002 (0.004)\tLoss 1.2214 (1.2682)\tPrec 64.844% (65.377%)\n",
      "Epoch: [143][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.1368 (1.2725)\tPrec 71.094% (65.252%)\n",
      "Epoch: [143][300/391]\tTime 0.031 (0.033)\tData 0.003 (0.003)\tLoss 1.4572 (1.2747)\tPrec 59.375% (65.046%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.101 (0.101)\tLoss 1.3325 (1.3325)\tPrec 66.406% (66.406%)\n",
      " * Prec 63.400% \n",
      "best acc: 88.020000\n",
      "Epoch: [144][0/391]\tTime 0.161 (0.161)\tData 0.131 (0.131)\tLoss 1.2539 (1.2539)\tPrec 64.062% (64.062%)\n",
      "Epoch: [144][100/391]\tTime 0.037 (0.035)\tData 0.002 (0.004)\tLoss 1.1657 (1.2671)\tPrec 69.531% (65.463%)\n",
      "Epoch: [144][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.2346 (1.2775)\tPrec 64.062% (65.050%)\n",
      "Epoch: [144][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.1953 (1.2757)\tPrec 66.406% (65.158%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 1.3507 (1.3507)\tPrec 63.281% (63.281%)\n",
      " * Prec 63.460% \n",
      "best acc: 88.020000\n",
      "Epoch: [145][0/391]\tTime 0.157 (0.157)\tData 0.120 (0.120)\tLoss 1.2825 (1.2825)\tPrec 67.188% (67.188%)\n",
      "Epoch: [145][100/391]\tTime 0.030 (0.035)\tData 0.003 (0.004)\tLoss 1.1913 (1.2715)\tPrec 71.875% (65.517%)\n",
      "Epoch: [145][200/391]\tTime 0.036 (0.035)\tData 0.002 (0.003)\tLoss 1.2768 (1.2772)\tPrec 63.281% (65.065%)\n",
      "Epoch: [145][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.4332 (1.2746)\tPrec 53.906% (65.285%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.104 (0.104)\tLoss 1.3209 (1.3209)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.320% \n",
      "best acc: 88.020000\n",
      "Epoch: [146][0/391]\tTime 0.176 (0.176)\tData 0.134 (0.134)\tLoss 1.1922 (1.1922)\tPrec 68.750% (68.750%)\n",
      "Epoch: [146][100/391]\tTime 0.034 (0.035)\tData 0.003 (0.003)\tLoss 1.3559 (1.2743)\tPrec 59.375% (64.983%)\n",
      "Epoch: [146][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.2580 (1.2785)\tPrec 67.188% (64.778%)\n",
      "Epoch: [146][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.4180 (1.2758)\tPrec 63.281% (65.067%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.108 (0.108)\tLoss 1.3504 (1.3504)\tPrec 64.844% (64.844%)\n",
      " * Prec 62.830% \n",
      "best acc: 88.020000\n",
      "Epoch: [147][0/391]\tTime 0.169 (0.169)\tData 0.127 (0.127)\tLoss 1.2604 (1.2604)\tPrec 62.500% (62.500%)\n",
      "Epoch: [147][100/391]\tTime 0.038 (0.035)\tData 0.003 (0.003)\tLoss 1.2234 (1.2780)\tPrec 68.750% (65.060%)\n",
      "Epoch: [147][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.4465 (1.2824)\tPrec 57.812% (65.135%)\n",
      "Epoch: [147][300/391]\tTime 0.037 (0.034)\tData 0.003 (0.002)\tLoss 1.3281 (1.2840)\tPrec 63.281% (65.059%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.125 (0.125)\tLoss 1.3558 (1.3558)\tPrec 67.188% (67.188%)\n",
      " * Prec 62.940% \n",
      "best acc: 88.020000\n",
      "Epoch: [148][0/391]\tTime 0.163 (0.163)\tData 0.131 (0.131)\tLoss 1.3353 (1.3353)\tPrec 61.719% (61.719%)\n",
      "Epoch: [148][100/391]\tTime 0.030 (0.035)\tData 0.003 (0.003)\tLoss 1.3674 (1.2852)\tPrec 61.719% (64.875%)\n",
      "Epoch: [148][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3797 (1.2826)\tPrec 57.031% (64.805%)\n",
      "Epoch: [148][300/391]\tTime 0.030 (0.034)\tData 0.002 (0.003)\tLoss 1.2166 (1.2793)\tPrec 67.188% (65.093%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.121 (0.121)\tLoss 1.3266 (1.3266)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.430% \n",
      "best acc: 88.020000\n",
      "Epoch: [149][0/391]\tTime 0.163 (0.163)\tData 0.125 (0.125)\tLoss 1.2842 (1.2842)\tPrec 63.281% (63.281%)\n",
      "Epoch: [149][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.003)\tLoss 1.2403 (1.2698)\tPrec 67.188% (65.586%)\n",
      "Epoch: [149][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3406 (1.2724)\tPrec 64.062% (65.341%)\n",
      "Epoch: [149][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3019 (1.2734)\tPrec 64.062% (65.288%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.117 (0.117)\tLoss 1.3239 (1.3239)\tPrec 66.406% (66.406%)\n",
      " * Prec 63.920% \n",
      "best acc: 88.020000\n",
      "Epoch: [150][0/391]\tTime 0.165 (0.165)\tData 0.129 (0.129)\tLoss 1.3258 (1.3258)\tPrec 64.062% (64.062%)\n",
      "Epoch: [150][100/391]\tTime 0.034 (0.035)\tData 0.002 (0.003)\tLoss 1.2877 (1.2794)\tPrec 64.062% (65.563%)\n",
      "Epoch: [150][200/391]\tTime 0.032 (0.034)\tData 0.003 (0.003)\tLoss 1.3761 (1.2825)\tPrec 57.812% (64.980%)\n",
      "Epoch: [150][300/391]\tTime 0.037 (0.033)\tData 0.002 (0.003)\tLoss 1.3448 (1.2811)\tPrec 62.500% (65.038%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 1.3556 (1.3556)\tPrec 62.500% (62.500%)\n",
      " * Prec 63.360% \n",
      "best acc: 88.020000\n",
      "Epoch: [151][0/391]\tTime 0.189 (0.189)\tData 0.149 (0.149)\tLoss 1.2880 (1.2880)\tPrec 61.719% (61.719%)\n",
      "Epoch: [151][100/391]\tTime 0.039 (0.035)\tData 0.003 (0.004)\tLoss 1.2293 (1.2774)\tPrec 64.844% (65.122%)\n",
      "Epoch: [151][200/391]\tTime 0.036 (0.034)\tData 0.003 (0.003)\tLoss 1.3563 (1.2814)\tPrec 60.938% (64.867%)\n",
      "Epoch: [151][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.2422 (1.2798)\tPrec 68.750% (64.971%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.111 (0.111)\tLoss 1.3502 (1.3502)\tPrec 67.969% (67.969%)\n",
      " * Prec 64.110% \n",
      "best acc: 88.020000\n",
      "Epoch: [152][0/391]\tTime 0.168 (0.168)\tData 0.130 (0.130)\tLoss 1.2755 (1.2755)\tPrec 64.844% (64.844%)\n",
      "Epoch: [152][100/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.3183 (1.2749)\tPrec 65.625% (65.393%)\n",
      "Epoch: [152][200/391]\tTime 0.036 (0.033)\tData 0.003 (0.003)\tLoss 1.1483 (1.2757)\tPrec 72.656% (65.221%)\n",
      "Epoch: [152][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.002)\tLoss 1.2046 (1.2764)\tPrec 67.969% (65.150%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.101 (0.101)\tLoss 1.3112 (1.3112)\tPrec 67.188% (67.188%)\n",
      " * Prec 63.470% \n",
      "best acc: 88.020000\n",
      "Epoch: [153][0/391]\tTime 0.177 (0.177)\tData 0.144 (0.144)\tLoss 1.2232 (1.2232)\tPrec 68.750% (68.750%)\n",
      "Epoch: [153][100/391]\tTime 0.032 (0.035)\tData 0.002 (0.004)\tLoss 1.2493 (1.2669)\tPrec 67.188% (65.749%)\n",
      "Epoch: [153][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.2485 (1.2786)\tPrec 59.375% (65.034%)\n",
      "Epoch: [153][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.1412 (1.2787)\tPrec 72.656% (64.924%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.099 (0.099)\tLoss 1.2992 (1.2992)\tPrec 67.188% (67.188%)\n",
      " * Prec 64.060% \n",
      "best acc: 88.020000\n",
      "Epoch: [154][0/391]\tTime 0.172 (0.172)\tData 0.136 (0.136)\tLoss 1.1133 (1.1133)\tPrec 71.094% (71.094%)\n",
      "Epoch: [154][100/391]\tTime 0.034 (0.035)\tData 0.003 (0.004)\tLoss 1.2596 (1.2614)\tPrec 63.281% (65.834%)\n",
      "Epoch: [154][200/391]\tTime 0.031 (0.034)\tData 0.003 (0.003)\tLoss 1.3375 (1.2778)\tPrec 64.062% (65.349%)\n",
      "Epoch: [154][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.3172 (1.2760)\tPrec 62.500% (65.246%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.117 (0.117)\tLoss 1.3364 (1.3364)\tPrec 64.062% (64.062%)\n",
      " * Prec 63.190% \n",
      "best acc: 88.020000\n",
      "Epoch: [155][0/391]\tTime 0.171 (0.171)\tData 0.132 (0.132)\tLoss 1.3725 (1.3725)\tPrec 60.938% (60.938%)\n",
      "Epoch: [155][100/391]\tTime 0.038 (0.035)\tData 0.002 (0.004)\tLoss 1.3599 (1.2781)\tPrec 58.594% (65.130%)\n",
      "Epoch: [155][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.1406 (1.2778)\tPrec 70.312% (65.124%)\n",
      "Epoch: [155][300/391]\tTime 0.039 (0.034)\tData 0.002 (0.002)\tLoss 1.2647 (1.2728)\tPrec 64.062% (65.251%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.121 (0.121)\tLoss 1.3395 (1.3395)\tPrec 66.406% (66.406%)\n",
      " * Prec 62.880% \n",
      "best acc: 88.020000\n",
      "Epoch: [156][0/391]\tTime 0.179 (0.179)\tData 0.135 (0.135)\tLoss 1.3416 (1.3416)\tPrec 58.594% (58.594%)\n",
      "Epoch: [156][100/391]\tTime 0.035 (0.035)\tData 0.002 (0.003)\tLoss 1.3198 (1.2719)\tPrec 55.469% (65.300%)\n",
      "Epoch: [156][200/391]\tTime 0.036 (0.035)\tData 0.002 (0.003)\tLoss 1.1502 (1.2795)\tPrec 67.969% (65.085%)\n",
      "Epoch: [156][300/391]\tTime 0.033 (0.034)\tData 0.001 (0.002)\tLoss 1.3552 (1.2790)\tPrec 60.156% (65.054%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.111 (0.111)\tLoss 1.3482 (1.3482)\tPrec 61.719% (61.719%)\n",
      " * Prec 63.250% \n",
      "best acc: 88.020000\n",
      "Epoch: [157][0/391]\tTime 0.170 (0.170)\tData 0.130 (0.130)\tLoss 1.2816 (1.2816)\tPrec 64.844% (64.844%)\n",
      "Epoch: [157][100/391]\tTime 0.035 (0.035)\tData 0.002 (0.003)\tLoss 1.2664 (1.2555)\tPrec 63.281% (66.329%)\n",
      "Epoch: [157][200/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.2923 (1.2727)\tPrec 69.531% (65.419%)\n",
      "Epoch: [157][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.2065 (1.2742)\tPrec 68.750% (65.386%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.103 (0.103)\tLoss 1.3893 (1.3893)\tPrec 61.719% (61.719%)\n",
      " * Prec 63.040% \n",
      "best acc: 88.020000\n",
      "Epoch: [158][0/391]\tTime 0.177 (0.177)\tData 0.135 (0.135)\tLoss 1.4360 (1.4360)\tPrec 57.812% (57.812%)\n",
      "Epoch: [158][100/391]\tTime 0.026 (0.034)\tData 0.001 (0.003)\tLoss 1.2539 (1.2736)\tPrec 64.062% (65.300%)\n",
      "Epoch: [158][200/391]\tTime 0.036 (0.033)\tData 0.002 (0.003)\tLoss 1.2314 (1.2692)\tPrec 67.188% (65.392%)\n",
      "Epoch: [158][300/391]\tTime 0.032 (0.033)\tData 0.002 (0.002)\tLoss 1.3507 (1.2760)\tPrec 61.719% (65.238%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.101 (0.101)\tLoss 1.3670 (1.3670)\tPrec 62.500% (62.500%)\n",
      " * Prec 63.160% \n",
      "best acc: 88.020000\n",
      "Epoch: [159][0/391]\tTime 0.172 (0.172)\tData 0.130 (0.130)\tLoss 1.2317 (1.2317)\tPrec 67.188% (67.188%)\n",
      "Epoch: [159][100/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.4080 (1.2749)\tPrec 60.938% (65.200%)\n",
      "Epoch: [159][200/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.1741 (1.2757)\tPrec 68.750% (65.178%)\n",
      "Epoch: [159][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.1941 (1.2730)\tPrec 70.312% (65.334%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.115 (0.115)\tLoss 1.3190 (1.3190)\tPrec 64.844% (64.844%)\n",
      " * Prec 62.950% \n",
      "best acc: 88.020000\n",
      "Epoch: [160][0/391]\tTime 0.178 (0.178)\tData 0.145 (0.145)\tLoss 1.2065 (1.2065)\tPrec 69.531% (69.531%)\n",
      "Epoch: [160][100/391]\tTime 0.031 (0.034)\tData 0.003 (0.003)\tLoss 1.2487 (1.2752)\tPrec 68.750% (65.285%)\n",
      "Epoch: [160][200/391]\tTime 0.032 (0.034)\tData 0.003 (0.003)\tLoss 1.2969 (1.2711)\tPrec 59.375% (65.365%)\n",
      "Epoch: [160][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.2775 (1.2762)\tPrec 67.188% (65.179%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.122 (0.122)\tLoss 1.3608 (1.3608)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.290% \n",
      "best acc: 88.020000\n",
      "Epoch: [161][0/391]\tTime 0.169 (0.169)\tData 0.131 (0.131)\tLoss 1.2144 (1.2144)\tPrec 70.312% (70.312%)\n",
      "Epoch: [161][100/391]\tTime 0.034 (0.034)\tData 0.003 (0.003)\tLoss 1.3243 (1.2810)\tPrec 61.719% (65.494%)\n",
      "Epoch: [161][200/391]\tTime 0.033 (0.034)\tData 0.001 (0.003)\tLoss 1.2262 (1.2748)\tPrec 66.406% (65.777%)\n",
      "Epoch: [161][300/391]\tTime 0.035 (0.034)\tData 0.003 (0.003)\tLoss 1.2160 (1.2760)\tPrec 67.969% (65.558%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.117 (0.117)\tLoss 1.3590 (1.3590)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.510% \n",
      "best acc: 88.020000\n",
      "Epoch: [162][0/391]\tTime 0.172 (0.172)\tData 0.146 (0.146)\tLoss 1.2915 (1.2915)\tPrec 64.844% (64.844%)\n",
      "Epoch: [162][100/391]\tTime 0.029 (0.035)\tData 0.002 (0.004)\tLoss 1.1256 (1.2610)\tPrec 67.188% (65.501%)\n",
      "Epoch: [162][200/391]\tTime 0.033 (0.034)\tData 0.003 (0.003)\tLoss 1.2557 (1.2734)\tPrec 64.844% (65.159%)\n",
      "Epoch: [162][300/391]\tTime 0.032 (0.034)\tData 0.001 (0.003)\tLoss 1.2287 (1.2758)\tPrec 67.188% (65.059%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.105 (0.105)\tLoss 1.3563 (1.3563)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.490% \n",
      "best acc: 88.020000\n",
      "Epoch: [163][0/391]\tTime 0.165 (0.165)\tData 0.128 (0.128)\tLoss 1.3328 (1.3328)\tPrec 61.719% (61.719%)\n",
      "Epoch: [163][100/391]\tTime 0.036 (0.035)\tData 0.002 (0.003)\tLoss 1.2567 (1.2885)\tPrec 69.531% (64.364%)\n",
      "Epoch: [163][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3171 (1.2789)\tPrec 63.281% (65.034%)\n",
      "Epoch: [163][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.1980 (1.2755)\tPrec 67.188% (65.311%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 1.2924 (1.2924)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.480% \n",
      "best acc: 88.020000\n",
      "Epoch: [164][0/391]\tTime 0.182 (0.182)\tData 0.138 (0.138)\tLoss 1.3723 (1.3723)\tPrec 60.938% (60.938%)\n",
      "Epoch: [164][100/391]\tTime 0.039 (0.035)\tData 0.002 (0.004)\tLoss 1.3897 (1.2662)\tPrec 60.938% (65.509%)\n",
      "Epoch: [164][200/391]\tTime 0.030 (0.034)\tData 0.001 (0.003)\tLoss 1.2213 (1.2709)\tPrec 67.188% (65.240%)\n",
      "Epoch: [164][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.4223 (1.2677)\tPrec 60.938% (65.376%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.108 (0.108)\tLoss 1.3044 (1.3044)\tPrec 66.406% (66.406%)\n",
      " * Prec 63.800% \n",
      "best acc: 88.020000\n",
      "Epoch: [165][0/391]\tTime 0.175 (0.175)\tData 0.141 (0.141)\tLoss 1.1620 (1.1620)\tPrec 71.875% (71.875%)\n",
      "Epoch: [165][100/391]\tTime 0.033 (0.036)\tData 0.002 (0.004)\tLoss 1.2542 (1.2718)\tPrec 64.844% (65.424%)\n",
      "Epoch: [165][200/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.2791 (1.2772)\tPrec 62.500% (65.248%)\n",
      "Epoch: [165][300/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.2341 (1.2797)\tPrec 64.062% (65.015%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.115 (0.115)\tLoss 1.3784 (1.3784)\tPrec 64.062% (64.062%)\n",
      " * Prec 64.410% \n",
      "best acc: 88.020000\n",
      "Epoch: [166][0/391]\tTime 0.169 (0.169)\tData 0.132 (0.132)\tLoss 1.2028 (1.2028)\tPrec 69.531% (69.531%)\n",
      "Epoch: [166][100/391]\tTime 0.027 (0.035)\tData 0.002 (0.003)\tLoss 1.4193 (1.2779)\tPrec 60.156% (65.014%)\n",
      "Epoch: [166][200/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.3947 (1.2796)\tPrec 64.844% (65.058%)\n",
      "Epoch: [166][300/391]\tTime 0.037 (0.034)\tData 0.003 (0.003)\tLoss 1.1311 (1.2766)\tPrec 70.312% (65.171%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 1.2900 (1.2900)\tPrec 67.969% (67.969%)\n",
      " * Prec 63.760% \n",
      "best acc: 88.020000\n",
      "Epoch: [167][0/391]\tTime 0.170 (0.170)\tData 0.141 (0.141)\tLoss 1.2043 (1.2043)\tPrec 69.531% (69.531%)\n",
      "Epoch: [167][100/391]\tTime 0.029 (0.034)\tData 0.002 (0.003)\tLoss 1.2518 (1.2781)\tPrec 64.062% (65.478%)\n",
      "Epoch: [167][200/391]\tTime 0.034 (0.034)\tData 0.003 (0.003)\tLoss 1.3269 (1.2766)\tPrec 64.844% (65.466%)\n",
      "Epoch: [167][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3733 (1.2739)\tPrec 60.156% (65.526%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.099 (0.099)\tLoss 1.2613 (1.2613)\tPrec 68.750% (68.750%)\n",
      " * Prec 63.480% \n",
      "best acc: 88.020000\n",
      "Epoch: [168][0/391]\tTime 0.171 (0.171)\tData 0.132 (0.132)\tLoss 1.3934 (1.3934)\tPrec 62.500% (62.500%)\n",
      "Epoch: [168][100/391]\tTime 0.029 (0.035)\tData 0.002 (0.004)\tLoss 1.2438 (1.2639)\tPrec 67.188% (65.633%)\n",
      "Epoch: [168][200/391]\tTime 0.036 (0.035)\tData 0.003 (0.003)\tLoss 1.3258 (1.2672)\tPrec 62.500% (65.505%)\n",
      "Epoch: [168][300/391]\tTime 0.036 (0.035)\tData 0.002 (0.003)\tLoss 1.2465 (1.2697)\tPrec 66.406% (65.360%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 1.3714 (1.3714)\tPrec 64.062% (64.062%)\n",
      " * Prec 63.410% \n",
      "best acc: 88.020000\n",
      "Epoch: [169][0/391]\tTime 0.158 (0.158)\tData 0.127 (0.127)\tLoss 1.2692 (1.2692)\tPrec 67.969% (67.969%)\n",
      "Epoch: [169][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.3055 (1.2698)\tPrec 67.188% (65.849%)\n",
      "Epoch: [169][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.2486 (1.2758)\tPrec 62.500% (65.555%)\n",
      "Epoch: [169][300/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.2217 (1.2723)\tPrec 67.969% (65.498%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.116 (0.116)\tLoss 1.3706 (1.3706)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.640% \n",
      "best acc: 88.020000\n",
      "Epoch: [170][0/391]\tTime 0.171 (0.171)\tData 0.131 (0.131)\tLoss 1.2020 (1.2020)\tPrec 71.094% (71.094%)\n",
      "Epoch: [170][100/391]\tTime 0.034 (0.035)\tData 0.002 (0.003)\tLoss 1.2159 (1.2737)\tPrec 68.750% (65.339%)\n",
      "Epoch: [170][200/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.4223 (1.2796)\tPrec 57.812% (65.085%)\n",
      "Epoch: [170][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.3731 (1.2776)\tPrec 63.281% (65.163%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 1.3379 (1.3379)\tPrec 66.406% (66.406%)\n",
      " * Prec 62.810% \n",
      "best acc: 88.020000\n",
      "Epoch: [171][0/391]\tTime 0.173 (0.173)\tData 0.138 (0.138)\tLoss 1.3179 (1.3179)\tPrec 59.375% (59.375%)\n",
      "Epoch: [171][100/391]\tTime 0.030 (0.035)\tData 0.002 (0.004)\tLoss 1.2443 (1.2728)\tPrec 66.406% (65.138%)\n",
      "Epoch: [171][200/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.1734 (1.2719)\tPrec 70.312% (65.279%)\n",
      "Epoch: [171][300/391]\tTime 0.030 (0.034)\tData 0.002 (0.003)\tLoss 1.2345 (1.2695)\tPrec 69.531% (65.415%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 1.3537 (1.3537)\tPrec 61.719% (61.719%)\n",
      " * Prec 62.940% \n",
      "best acc: 88.020000\n",
      "Epoch: [172][0/391]\tTime 0.173 (0.173)\tData 0.137 (0.137)\tLoss 1.3676 (1.3676)\tPrec 57.812% (57.812%)\n",
      "Epoch: [172][100/391]\tTime 0.034 (0.035)\tData 0.002 (0.004)\tLoss 1.2035 (1.2587)\tPrec 66.406% (66.252%)\n",
      "Epoch: [172][200/391]\tTime 0.039 (0.034)\tData 0.003 (0.003)\tLoss 1.2299 (1.2694)\tPrec 70.312% (65.730%)\n",
      "Epoch: [172][300/391]\tTime 0.036 (0.034)\tData 0.001 (0.003)\tLoss 1.2246 (1.2711)\tPrec 67.188% (65.581%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 1.3537 (1.3537)\tPrec 63.281% (63.281%)\n",
      " * Prec 64.060% \n",
      "best acc: 88.020000\n",
      "Epoch: [173][0/391]\tTime 0.182 (0.182)\tData 0.146 (0.146)\tLoss 1.3341 (1.3341)\tPrec 67.188% (67.188%)\n",
      "Epoch: [173][100/391]\tTime 0.038 (0.035)\tData 0.002 (0.004)\tLoss 1.3139 (1.2612)\tPrec 67.188% (66.035%)\n",
      "Epoch: [173][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.1564 (1.2684)\tPrec 69.531% (65.438%)\n",
      "Epoch: [173][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.4321 (1.2727)\tPrec 60.938% (65.386%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.115 (0.115)\tLoss 1.3102 (1.3102)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.880% \n",
      "best acc: 88.020000\n",
      "Epoch: [174][0/391]\tTime 0.157 (0.157)\tData 0.130 (0.130)\tLoss 1.2746 (1.2746)\tPrec 64.844% (64.844%)\n",
      "Epoch: [174][100/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.3024 (1.2704)\tPrec 67.188% (65.610%)\n",
      "Epoch: [174][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.4173 (1.2778)\tPrec 59.375% (65.306%)\n",
      "Epoch: [174][300/391]\tTime 0.039 (0.034)\tData 0.002 (0.002)\tLoss 1.2081 (1.2734)\tPrec 72.656% (65.347%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.117 (0.117)\tLoss 1.2936 (1.2936)\tPrec 68.750% (68.750%)\n",
      " * Prec 63.920% \n",
      "best acc: 88.020000\n",
      "Epoch: [175][0/391]\tTime 0.151 (0.151)\tData 0.123 (0.123)\tLoss 1.4054 (1.4054)\tPrec 62.500% (62.500%)\n",
      "Epoch: [175][100/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3490 (1.2746)\tPrec 61.719% (64.983%)\n",
      "Epoch: [175][200/391]\tTime 0.034 (0.033)\tData 0.001 (0.003)\tLoss 1.2820 (1.2690)\tPrec 59.375% (65.104%)\n",
      "Epoch: [175][300/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 1.2292 (1.2698)\tPrec 66.406% (65.210%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.105 (0.105)\tLoss 1.3411 (1.3411)\tPrec 66.406% (66.406%)\n",
      " * Prec 63.430% \n",
      "best acc: 88.020000\n",
      "Epoch: [176][0/391]\tTime 0.179 (0.179)\tData 0.144 (0.144)\tLoss 1.3025 (1.3025)\tPrec 64.844% (64.844%)\n",
      "Epoch: [176][100/391]\tTime 0.037 (0.035)\tData 0.002 (0.004)\tLoss 1.2353 (1.2635)\tPrec 70.312% (65.594%)\n",
      "Epoch: [176][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.1922 (1.2619)\tPrec 73.438% (65.641%)\n",
      "Epoch: [176][300/391]\tTime 0.034 (0.034)\tData 0.003 (0.003)\tLoss 1.3104 (1.2643)\tPrec 63.281% (65.487%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.093 (0.093)\tLoss 1.3458 (1.3458)\tPrec 67.969% (67.969%)\n",
      " * Prec 63.610% \n",
      "best acc: 88.020000\n",
      "Epoch: [177][0/391]\tTime 0.176 (0.176)\tData 0.132 (0.132)\tLoss 1.2524 (1.2524)\tPrec 59.375% (59.375%)\n",
      "Epoch: [177][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.003)\tLoss 1.2279 (1.2683)\tPrec 64.844% (65.447%)\n",
      "Epoch: [177][200/391]\tTime 0.029 (0.034)\tData 0.002 (0.003)\tLoss 1.2093 (1.2686)\tPrec 70.312% (65.551%)\n",
      "Epoch: [177][300/391]\tTime 0.039 (0.034)\tData 0.003 (0.003)\tLoss 1.3540 (1.2710)\tPrec 60.938% (65.433%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.111 (0.111)\tLoss 1.3138 (1.3138)\tPrec 70.312% (70.312%)\n",
      " * Prec 63.480% \n",
      "best acc: 88.020000\n",
      "Epoch: [178][0/391]\tTime 0.164 (0.164)\tData 0.139 (0.139)\tLoss 1.3436 (1.3436)\tPrec 61.719% (61.719%)\n",
      "Epoch: [178][100/391]\tTime 0.035 (0.034)\tData 0.003 (0.003)\tLoss 1.3234 (1.2768)\tPrec 62.500% (65.130%)\n",
      "Epoch: [178][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.1654 (1.2744)\tPrec 71.875% (65.174%)\n",
      "Epoch: [178][300/391]\tTime 0.032 (0.033)\tData 0.002 (0.002)\tLoss 1.2050 (1.2729)\tPrec 67.969% (65.205%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 1.3773 (1.3773)\tPrec 61.719% (61.719%)\n",
      " * Prec 63.010% \n",
      "best acc: 88.020000\n",
      "Epoch: [179][0/391]\tTime 0.172 (0.172)\tData 0.135 (0.135)\tLoss 1.2109 (1.2109)\tPrec 72.656% (72.656%)\n",
      "Epoch: [179][100/391]\tTime 0.032 (0.035)\tData 0.001 (0.003)\tLoss 1.3854 (1.2701)\tPrec 61.719% (65.741%)\n",
      "Epoch: [179][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.2412 (1.2688)\tPrec 66.406% (65.676%)\n",
      "Epoch: [179][300/391]\tTime 0.040 (0.034)\tData 0.002 (0.002)\tLoss 1.2853 (1.2676)\tPrec 64.844% (65.786%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.111 (0.111)\tLoss 1.3637 (1.3637)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.620% \n",
      "best acc: 88.020000\n",
      "Epoch: [180][0/391]\tTime 0.186 (0.186)\tData 0.144 (0.144)\tLoss 1.1583 (1.1583)\tPrec 69.531% (69.531%)\n",
      "Epoch: [180][100/391]\tTime 0.030 (0.035)\tData 0.002 (0.004)\tLoss 1.1368 (1.2759)\tPrec 72.656% (65.122%)\n",
      "Epoch: [180][200/391]\tTime 0.038 (0.034)\tData 0.003 (0.003)\tLoss 1.1458 (1.2723)\tPrec 68.750% (65.279%)\n",
      "Epoch: [180][300/391]\tTime 0.038 (0.034)\tData 0.003 (0.003)\tLoss 1.2345 (1.2727)\tPrec 67.969% (65.088%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 1.3319 (1.3319)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.050% \n",
      "best acc: 88.020000\n",
      "Epoch: [181][0/391]\tTime 0.179 (0.179)\tData 0.139 (0.139)\tLoss 1.2241 (1.2241)\tPrec 67.188% (67.188%)\n",
      "Epoch: [181][100/391]\tTime 0.036 (0.035)\tData 0.002 (0.004)\tLoss 1.3091 (1.2726)\tPrec 63.281% (65.285%)\n",
      "Epoch: [181][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.2724 (1.2750)\tPrec 67.969% (65.256%)\n",
      "Epoch: [181][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.2026 (1.2716)\tPrec 71.875% (65.410%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.108 (0.108)\tLoss 1.3251 (1.3251)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.630% \n",
      "best acc: 88.020000\n",
      "Epoch: [182][0/391]\tTime 0.178 (0.178)\tData 0.143 (0.143)\tLoss 1.4913 (1.4913)\tPrec 55.469% (55.469%)\n",
      "Epoch: [182][100/391]\tTime 0.036 (0.035)\tData 0.002 (0.004)\tLoss 1.2536 (1.2779)\tPrec 65.625% (64.913%)\n",
      "Epoch: [182][200/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.2886 (1.2742)\tPrec 63.281% (65.046%)\n",
      "Epoch: [182][300/391]\tTime 0.035 (0.034)\tData 0.003 (0.003)\tLoss 1.1678 (1.2736)\tPrec 66.406% (65.173%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.100 (0.100)\tLoss 1.3594 (1.3594)\tPrec 61.719% (61.719%)\n",
      " * Prec 63.520% \n",
      "best acc: 88.020000\n",
      "Epoch: [183][0/391]\tTime 0.165 (0.165)\tData 0.131 (0.131)\tLoss 1.2769 (1.2769)\tPrec 64.844% (64.844%)\n",
      "Epoch: [183][100/391]\tTime 0.032 (0.035)\tData 0.002 (0.003)\tLoss 1.2997 (1.2658)\tPrec 67.188% (65.679%)\n",
      "Epoch: [183][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.1405 (1.2683)\tPrec 68.750% (65.260%)\n",
      "Epoch: [183][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3436 (1.2732)\tPrec 60.156% (65.051%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.103 (0.103)\tLoss 1.3464 (1.3464)\tPrec 67.188% (67.188%)\n",
      " * Prec 63.640% \n",
      "best acc: 88.020000\n",
      "Epoch: [184][0/391]\tTime 0.181 (0.181)\tData 0.145 (0.145)\tLoss 1.2777 (1.2777)\tPrec 67.969% (67.969%)\n",
      "Epoch: [184][100/391]\tTime 0.027 (0.035)\tData 0.001 (0.004)\tLoss 1.2997 (1.2759)\tPrec 67.969% (65.377%)\n",
      "Epoch: [184][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3422 (1.2671)\tPrec 61.719% (65.656%)\n",
      "Epoch: [184][300/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.3703 (1.2661)\tPrec 60.938% (65.695%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 1.3205 (1.3205)\tPrec 68.750% (68.750%)\n",
      " * Prec 62.880% \n",
      "best acc: 88.020000\n",
      "Epoch: [185][0/391]\tTime 0.167 (0.167)\tData 0.134 (0.134)\tLoss 1.2773 (1.2773)\tPrec 60.938% (60.938%)\n",
      "Epoch: [185][100/391]\tTime 0.029 (0.035)\tData 0.003 (0.004)\tLoss 1.3058 (1.2638)\tPrec 57.812% (65.416%)\n",
      "Epoch: [185][200/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.3736 (1.2673)\tPrec 64.844% (65.248%)\n",
      "Epoch: [185][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.2144 (1.2698)\tPrec 72.656% (65.269%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.109 (0.109)\tLoss 1.3373 (1.3373)\tPrec 64.062% (64.062%)\n",
      " * Prec 63.730% \n",
      "best acc: 88.020000\n",
      "Epoch: [186][0/391]\tTime 0.161 (0.161)\tData 0.134 (0.134)\tLoss 1.0970 (1.0970)\tPrec 73.438% (73.438%)\n",
      "Epoch: [186][100/391]\tTime 0.038 (0.034)\tData 0.003 (0.004)\tLoss 1.2609 (1.2643)\tPrec 66.406% (65.486%)\n",
      "Epoch: [186][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.3471 (1.2726)\tPrec 62.500% (65.221%)\n",
      "Epoch: [186][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.1227 (1.2717)\tPrec 71.875% (65.295%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 1.3186 (1.3186)\tPrec 64.062% (64.062%)\n",
      " * Prec 62.670% \n",
      "best acc: 88.020000\n",
      "Epoch: [187][0/391]\tTime 0.173 (0.173)\tData 0.131 (0.131)\tLoss 1.3090 (1.3090)\tPrec 63.281% (63.281%)\n",
      "Epoch: [187][100/391]\tTime 0.034 (0.035)\tData 0.001 (0.003)\tLoss 1.4073 (1.2711)\tPrec 62.500% (65.323%)\n",
      "Epoch: [187][200/391]\tTime 0.033 (0.034)\tData 0.001 (0.003)\tLoss 1.2591 (1.2693)\tPrec 64.844% (65.427%)\n",
      "Epoch: [187][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.2778 (1.2711)\tPrec 66.406% (65.474%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 1.3443 (1.3443)\tPrec 67.188% (67.188%)\n",
      " * Prec 63.530% \n",
      "best acc: 88.020000\n",
      "Epoch: [188][0/391]\tTime 0.159 (0.159)\tData 0.129 (0.129)\tLoss 1.1720 (1.1720)\tPrec 69.531% (69.531%)\n",
      "Epoch: [188][100/391]\tTime 0.028 (0.034)\tData 0.001 (0.003)\tLoss 1.2869 (1.2646)\tPrec 61.719% (65.362%)\n",
      "Epoch: [188][200/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.3971 (1.2723)\tPrec 57.812% (65.155%)\n",
      "Epoch: [188][300/391]\tTime 0.039 (0.034)\tData 0.002 (0.003)\tLoss 1.3760 (1.2689)\tPrec 62.500% (65.410%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 1.3244 (1.3244)\tPrec 66.406% (66.406%)\n",
      " * Prec 63.840% \n",
      "best acc: 88.020000\n",
      "Epoch: [189][0/391]\tTime 0.184 (0.184)\tData 0.140 (0.140)\tLoss 1.3441 (1.3441)\tPrec 61.719% (61.719%)\n",
      "Epoch: [189][100/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.1621 (1.2675)\tPrec 67.188% (64.975%)\n",
      "Epoch: [189][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.1553 (1.2689)\tPrec 68.750% (65.229%)\n",
      "Epoch: [189][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.002)\tLoss 1.3335 (1.2733)\tPrec 62.500% (65.067%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 1.3429 (1.3429)\tPrec 63.281% (63.281%)\n",
      " * Prec 63.910% \n",
      "best acc: 88.020000\n",
      "Epoch: [190][0/391]\tTime 0.172 (0.172)\tData 0.131 (0.131)\tLoss 1.2256 (1.2256)\tPrec 68.750% (68.750%)\n",
      "Epoch: [190][100/391]\tTime 0.028 (0.035)\tData 0.001 (0.003)\tLoss 1.3212 (1.2543)\tPrec 65.625% (66.004%)\n",
      "Epoch: [190][200/391]\tTime 0.034 (0.034)\tData 0.001 (0.003)\tLoss 1.1122 (1.2657)\tPrec 71.875% (65.423%)\n",
      "Epoch: [190][300/391]\tTime 0.037 (0.034)\tData 0.003 (0.002)\tLoss 1.2923 (1.2681)\tPrec 64.062% (65.391%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 1.3567 (1.3567)\tPrec 67.969% (67.969%)\n",
      " * Prec 63.360% \n",
      "best acc: 88.020000\n",
      "Epoch: [191][0/391]\tTime 0.156 (0.156)\tData 0.128 (0.128)\tLoss 1.1563 (1.1563)\tPrec 71.094% (71.094%)\n",
      "Epoch: [191][100/391]\tTime 0.038 (0.035)\tData 0.002 (0.003)\tLoss 1.4144 (1.2672)\tPrec 61.719% (65.555%)\n",
      "Epoch: [191][200/391]\tTime 0.030 (0.034)\tData 0.003 (0.003)\tLoss 1.2046 (1.2685)\tPrec 66.406% (65.365%)\n",
      "Epoch: [191][300/391]\tTime 0.039 (0.034)\tData 0.002 (0.003)\tLoss 1.3739 (1.2660)\tPrec 62.500% (65.373%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 1.3142 (1.3142)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.950% \n",
      "best acc: 88.020000\n",
      "Epoch: [192][0/391]\tTime 0.165 (0.165)\tData 0.130 (0.130)\tLoss 1.2168 (1.2168)\tPrec 68.750% (68.750%)\n",
      "Epoch: [192][100/391]\tTime 0.032 (0.035)\tData 0.002 (0.003)\tLoss 1.3489 (1.2668)\tPrec 63.281% (65.563%)\n",
      "Epoch: [192][200/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.2422 (1.2631)\tPrec 67.188% (65.606%)\n",
      "Epoch: [192][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.3017 (1.2655)\tPrec 63.281% (65.358%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.122 (0.122)\tLoss 1.3508 (1.3508)\tPrec 66.406% (66.406%)\n",
      " * Prec 63.680% \n",
      "best acc: 88.020000\n",
      "Epoch: [193][0/391]\tTime 0.188 (0.188)\tData 0.151 (0.151)\tLoss 1.2584 (1.2584)\tPrec 64.062% (64.062%)\n",
      "Epoch: [193][100/391]\tTime 0.032 (0.035)\tData 0.002 (0.004)\tLoss 1.2963 (1.2605)\tPrec 67.969% (65.710%)\n",
      "Epoch: [193][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3279 (1.2609)\tPrec 64.062% (65.885%)\n",
      "Epoch: [193][300/391]\tTime 0.037 (0.034)\tData 0.003 (0.003)\tLoss 1.4144 (1.2614)\tPrec 59.375% (65.770%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.119 (0.119)\tLoss 1.3241 (1.3241)\tPrec 64.062% (64.062%)\n",
      " * Prec 63.860% \n",
      "best acc: 88.020000\n",
      "Epoch: [194][0/391]\tTime 0.185 (0.185)\tData 0.147 (0.147)\tLoss 1.3792 (1.3792)\tPrec 61.719% (61.719%)\n",
      "Epoch: [194][100/391]\tTime 0.035 (0.035)\tData 0.002 (0.004)\tLoss 1.4041 (1.2726)\tPrec 56.250% (65.076%)\n",
      "Epoch: [194][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.2080 (1.2725)\tPrec 67.188% (65.322%)\n",
      "Epoch: [194][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.2502 (1.2659)\tPrec 66.406% (65.583%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.110 (0.110)\tLoss 1.3104 (1.3104)\tPrec 69.531% (69.531%)\n",
      " * Prec 63.770% \n",
      "best acc: 88.020000\n",
      "Epoch: [195][0/391]\tTime 0.177 (0.177)\tData 0.135 (0.135)\tLoss 1.1886 (1.1886)\tPrec 70.312% (70.312%)\n",
      "Epoch: [195][100/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.3085 (1.2612)\tPrec 64.844% (65.540%)\n",
      "Epoch: [195][200/391]\tTime 0.038 (0.034)\tData 0.003 (0.003)\tLoss 1.2408 (1.2588)\tPrec 66.406% (65.699%)\n",
      "Epoch: [195][300/391]\tTime 0.036 (0.034)\tData 0.003 (0.003)\tLoss 1.2728 (1.2632)\tPrec 64.844% (65.565%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.104 (0.104)\tLoss 1.3461 (1.3461)\tPrec 62.500% (62.500%)\n",
      " * Prec 63.160% \n",
      "best acc: 88.020000\n",
      "Epoch: [196][0/391]\tTime 0.165 (0.165)\tData 0.131 (0.131)\tLoss 1.4457 (1.4457)\tPrec 59.375% (59.375%)\n",
      "Epoch: [196][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.003)\tLoss 1.2902 (1.2618)\tPrec 65.625% (65.610%)\n",
      "Epoch: [196][200/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.2385 (1.2681)\tPrec 67.969% (65.372%)\n",
      "Epoch: [196][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3197 (1.2666)\tPrec 62.500% (65.459%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 1.3422 (1.3422)\tPrec 62.500% (62.500%)\n",
      " * Prec 63.350% \n",
      "best acc: 88.020000\n",
      "Epoch: [197][0/391]\tTime 0.165 (0.165)\tData 0.131 (0.131)\tLoss 1.2764 (1.2764)\tPrec 71.094% (71.094%)\n",
      "Epoch: [197][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.003)\tLoss 1.2719 (1.2607)\tPrec 64.844% (65.888%)\n",
      "Epoch: [197][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.2837 (1.2661)\tPrec 67.969% (65.641%)\n",
      "Epoch: [197][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.2556 (1.2676)\tPrec 69.531% (65.646%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.109 (0.109)\tLoss 1.3481 (1.3481)\tPrec 67.188% (67.188%)\n",
      " * Prec 63.390% \n",
      "best acc: 88.020000\n",
      "Epoch: [198][0/391]\tTime 0.167 (0.167)\tData 0.129 (0.129)\tLoss 1.3013 (1.3013)\tPrec 65.625% (65.625%)\n",
      "Epoch: [198][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.1894 (1.2639)\tPrec 71.094% (65.726%)\n",
      "Epoch: [198][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.2611 (1.2615)\tPrec 63.281% (65.819%)\n",
      "Epoch: [198][300/391]\tTime 0.030 (0.034)\tData 0.002 (0.003)\tLoss 1.1567 (1.2632)\tPrec 72.656% (65.708%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.124 (0.124)\tLoss 1.3349 (1.3349)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.230% \n",
      "best acc: 88.020000\n",
      "Epoch: [199][0/391]\tTime 0.175 (0.175)\tData 0.139 (0.139)\tLoss 1.0854 (1.0854)\tPrec 72.656% (72.656%)\n",
      "Epoch: [199][100/391]\tTime 0.032 (0.034)\tData 0.003 (0.003)\tLoss 1.3991 (1.2728)\tPrec 60.156% (64.952%)\n",
      "Epoch: [199][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.2838 (1.2725)\tPrec 61.719% (65.038%)\n",
      "Epoch: [199][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.3399 (1.2699)\tPrec 65.625% (65.197%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.117 (0.117)\tLoss 1.3251 (1.3251)\tPrec 64.062% (64.062%)\n",
      " * Prec 64.260% \n",
      "best acc: 88.020000\n",
      "Epoch: [200][0/391]\tTime 0.168 (0.168)\tData 0.131 (0.131)\tLoss 1.2514 (1.2514)\tPrec 62.500% (62.500%)\n",
      "Epoch: [200][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.2507 (1.2670)\tPrec 67.188% (65.486%)\n",
      "Epoch: [200][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.1416 (1.2682)\tPrec 73.438% (65.501%)\n",
      "Epoch: [200][300/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.2439 (1.2680)\tPrec 66.406% (65.591%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 1.3228 (1.3228)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.730% \n",
      "best acc: 88.020000\n",
      "Epoch: [201][0/391]\tTime 0.173 (0.173)\tData 0.139 (0.139)\tLoss 1.1954 (1.1954)\tPrec 71.875% (71.875%)\n",
      "Epoch: [201][100/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.2315 (1.2652)\tPrec 62.500% (65.664%)\n",
      "Epoch: [201][200/391]\tTime 0.040 (0.034)\tData 0.002 (0.003)\tLoss 1.2831 (1.2681)\tPrec 65.625% (65.590%)\n",
      "Epoch: [201][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.3542 (1.2658)\tPrec 60.938% (65.628%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 1.3521 (1.3521)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.950% \n",
      "best acc: 88.020000\n",
      "Epoch: [202][0/391]\tTime 0.187 (0.187)\tData 0.142 (0.142)\tLoss 1.2222 (1.2222)\tPrec 69.531% (69.531%)\n",
      "Epoch: [202][100/391]\tTime 0.038 (0.034)\tData 0.002 (0.004)\tLoss 1.2518 (1.2613)\tPrec 67.188% (65.408%)\n",
      "Epoch: [202][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.1942 (1.2605)\tPrec 66.406% (65.730%)\n",
      "Epoch: [202][300/391]\tTime 0.037 (0.034)\tData 0.003 (0.003)\tLoss 1.1689 (1.2659)\tPrec 71.094% (65.516%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 1.2803 (1.2803)\tPrec 68.750% (68.750%)\n",
      " * Prec 64.010% \n",
      "best acc: 88.020000\n",
      "Epoch: [203][0/391]\tTime 0.161 (0.161)\tData 0.135 (0.135)\tLoss 1.1858 (1.1858)\tPrec 71.094% (71.094%)\n",
      "Epoch: [203][100/391]\tTime 0.026 (0.035)\tData 0.002 (0.004)\tLoss 1.3075 (1.2803)\tPrec 62.500% (65.138%)\n",
      "Epoch: [203][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.1861 (1.2733)\tPrec 68.750% (65.392%)\n",
      "Epoch: [203][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.1133 (1.2673)\tPrec 75.781% (65.545%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.130 (0.130)\tLoss 1.3362 (1.3362)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.530% \n",
      "best acc: 88.020000\n",
      "Epoch: [204][0/391]\tTime 0.170 (0.170)\tData 0.131 (0.131)\tLoss 1.3061 (1.3061)\tPrec 59.375% (59.375%)\n",
      "Epoch: [204][100/391]\tTime 0.035 (0.035)\tData 0.002 (0.003)\tLoss 1.3242 (1.2706)\tPrec 62.500% (65.532%)\n",
      "Epoch: [204][200/391]\tTime 0.035 (0.035)\tData 0.002 (0.003)\tLoss 1.1630 (1.2680)\tPrec 72.656% (65.734%)\n",
      "Epoch: [204][300/391]\tTime 0.034 (0.035)\tData 0.003 (0.003)\tLoss 1.2913 (1.2625)\tPrec 63.281% (65.970%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.104 (0.104)\tLoss 1.3172 (1.3172)\tPrec 66.406% (66.406%)\n",
      " * Prec 63.820% \n",
      "best acc: 88.020000\n",
      "Epoch: [205][0/391]\tTime 0.166 (0.166)\tData 0.134 (0.134)\tLoss 1.2397 (1.2397)\tPrec 68.750% (68.750%)\n",
      "Epoch: [205][100/391]\tTime 0.037 (0.035)\tData 0.003 (0.004)\tLoss 1.3051 (1.2652)\tPrec 62.500% (65.664%)\n",
      "Epoch: [205][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.2630 (1.2660)\tPrec 67.969% (65.784%)\n",
      "Epoch: [205][300/391]\tTime 0.036 (0.033)\tData 0.003 (0.003)\tLoss 1.2345 (1.2681)\tPrec 66.406% (65.550%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.104 (0.104)\tLoss 1.3222 (1.3222)\tPrec 70.312% (70.312%)\n",
      " * Prec 63.090% \n",
      "best acc: 88.020000\n",
      "Epoch: [206][0/391]\tTime 0.176 (0.176)\tData 0.136 (0.136)\tLoss 1.1750 (1.1750)\tPrec 70.312% (70.312%)\n",
      "Epoch: [206][100/391]\tTime 0.030 (0.034)\tData 0.002 (0.003)\tLoss 1.2864 (1.2658)\tPrec 62.500% (65.563%)\n",
      "Epoch: [206][200/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.3102 (1.2666)\tPrec 65.625% (65.345%)\n",
      "Epoch: [206][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.3006 (1.2634)\tPrec 60.156% (65.482%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.105 (0.105)\tLoss 1.3387 (1.3387)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.840% \n",
      "best acc: 88.020000\n",
      "Epoch: [207][0/391]\tTime 0.174 (0.174)\tData 0.139 (0.139)\tLoss 1.3063 (1.3063)\tPrec 66.406% (66.406%)\n",
      "Epoch: [207][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.004)\tLoss 1.2064 (1.2755)\tPrec 71.094% (65.246%)\n",
      "Epoch: [207][200/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.2676 (1.2713)\tPrec 61.719% (65.415%)\n",
      "Epoch: [207][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.1649 (1.2690)\tPrec 69.531% (65.384%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 1.3417 (1.3417)\tPrec 67.188% (67.188%)\n",
      " * Prec 63.640% \n",
      "best acc: 88.020000\n",
      "Epoch: [208][0/391]\tTime 0.170 (0.170)\tData 0.140 (0.140)\tLoss 1.2728 (1.2728)\tPrec 68.750% (68.750%)\n",
      "Epoch: [208][100/391]\tTime 0.032 (0.035)\tData 0.002 (0.004)\tLoss 1.4467 (1.2588)\tPrec 58.594% (66.066%)\n",
      "Epoch: [208][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.1237 (1.2627)\tPrec 71.094% (65.831%)\n",
      "Epoch: [208][300/391]\tTime 0.030 (0.034)\tData 0.002 (0.003)\tLoss 1.4090 (1.2637)\tPrec 59.375% (65.874%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 1.2769 (1.2769)\tPrec 70.312% (70.312%)\n",
      " * Prec 63.470% \n",
      "best acc: 88.020000\n",
      "Epoch: [209][0/391]\tTime 0.165 (0.165)\tData 0.132 (0.132)\tLoss 1.1650 (1.1650)\tPrec 70.312% (70.312%)\n",
      "Epoch: [209][100/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3243 (1.2523)\tPrec 64.062% (66.406%)\n",
      "Epoch: [209][200/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.2037 (1.2578)\tPrec 72.656% (65.998%)\n",
      "Epoch: [209][300/391]\tTime 0.039 (0.033)\tData 0.001 (0.003)\tLoss 1.3686 (1.2638)\tPrec 61.719% (65.628%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.100 (0.100)\tLoss 1.2989 (1.2989)\tPrec 64.062% (64.062%)\n",
      " * Prec 64.060% \n",
      "best acc: 88.020000\n",
      "Epoch: [210][0/391]\tTime 0.165 (0.165)\tData 0.121 (0.121)\tLoss 1.1533 (1.1533)\tPrec 68.750% (68.750%)\n",
      "Epoch: [210][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.003)\tLoss 1.3586 (1.2571)\tPrec 65.625% (65.656%)\n",
      "Epoch: [210][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.1484 (1.2645)\tPrec 75.000% (65.287%)\n",
      "Epoch: [210][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3891 (1.2687)\tPrec 60.938% (65.163%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.127 (0.127)\tLoss 1.3594 (1.3594)\tPrec 67.188% (67.188%)\n",
      " * Prec 63.530% \n",
      "best acc: 88.020000\n",
      "Epoch: [211][0/391]\tTime 0.164 (0.164)\tData 0.128 (0.128)\tLoss 1.1542 (1.1542)\tPrec 71.094% (71.094%)\n",
      "Epoch: [211][100/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.3695 (1.2569)\tPrec 57.812% (66.368%)\n",
      "Epoch: [211][200/391]\tTime 0.037 (0.034)\tData 0.003 (0.003)\tLoss 1.1307 (1.2618)\tPrec 75.000% (65.784%)\n",
      "Epoch: [211][300/391]\tTime 0.029 (0.033)\tData 0.002 (0.002)\tLoss 1.2690 (1.2624)\tPrec 64.844% (65.757%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 1.3295 (1.3295)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.470% \n",
      "best acc: 88.020000\n",
      "Epoch: [212][0/391]\tTime 0.171 (0.171)\tData 0.135 (0.135)\tLoss 1.3562 (1.3562)\tPrec 61.719% (61.719%)\n",
      "Epoch: [212][100/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.3191 (1.2604)\tPrec 70.312% (65.772%)\n",
      "Epoch: [212][200/391]\tTime 0.032 (0.033)\tData 0.002 (0.003)\tLoss 1.1753 (1.2614)\tPrec 70.312% (65.823%)\n",
      "Epoch: [212][300/391]\tTime 0.034 (0.033)\tData 0.002 (0.003)\tLoss 1.1413 (1.2622)\tPrec 71.094% (65.654%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.101 (0.101)\tLoss 1.2935 (1.2935)\tPrec 63.281% (63.281%)\n",
      " * Prec 63.840% \n",
      "best acc: 88.020000\n",
      "Epoch: [213][0/391]\tTime 0.179 (0.179)\tData 0.140 (0.140)\tLoss 1.2565 (1.2565)\tPrec 65.625% (65.625%)\n",
      "Epoch: [213][100/391]\tTime 0.023 (0.035)\tData 0.001 (0.003)\tLoss 1.2703 (1.2673)\tPrec 64.062% (65.377%)\n",
      "Epoch: [213][200/391]\tTime 0.029 (0.034)\tData 0.002 (0.003)\tLoss 1.3813 (1.2749)\tPrec 59.375% (65.007%)\n",
      "Epoch: [213][300/391]\tTime 0.038 (0.034)\tData 0.003 (0.003)\tLoss 1.1958 (1.2663)\tPrec 69.531% (65.446%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.120 (0.120)\tLoss 1.2602 (1.2602)\tPrec 68.750% (68.750%)\n",
      " * Prec 64.050% \n",
      "best acc: 88.020000\n",
      "Epoch: [214][0/391]\tTime 0.174 (0.174)\tData 0.139 (0.139)\tLoss 1.3321 (1.3321)\tPrec 64.062% (64.062%)\n",
      "Epoch: [214][100/391]\tTime 0.034 (0.035)\tData 0.002 (0.004)\tLoss 1.3105 (1.2731)\tPrec 61.719% (65.114%)\n",
      "Epoch: [214][200/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.2660 (1.2647)\tPrec 66.406% (65.590%)\n",
      "Epoch: [214][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.2016 (1.2631)\tPrec 67.969% (65.708%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.106 (0.106)\tLoss 1.3121 (1.3121)\tPrec 69.531% (69.531%)\n",
      " * Prec 64.050% \n",
      "best acc: 88.020000\n",
      "Epoch: [215][0/391]\tTime 0.189 (0.189)\tData 0.150 (0.150)\tLoss 1.2903 (1.2903)\tPrec 62.500% (62.500%)\n",
      "Epoch: [215][100/391]\tTime 0.031 (0.034)\tData 0.002 (0.004)\tLoss 1.1970 (1.2553)\tPrec 71.094% (65.880%)\n",
      "Epoch: [215][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.1784 (1.2601)\tPrec 67.969% (65.784%)\n",
      "Epoch: [215][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.2650 (1.2602)\tPrec 66.406% (65.770%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 1.3023 (1.3023)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.800% \n",
      "best acc: 88.020000\n",
      "Epoch: [216][0/391]\tTime 0.164 (0.164)\tData 0.127 (0.127)\tLoss 1.4399 (1.4399)\tPrec 54.688% (54.688%)\n",
      "Epoch: [216][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.2109 (1.2535)\tPrec 71.875% (65.733%)\n",
      "Epoch: [216][200/391]\tTime 0.038 (0.034)\tData 0.001 (0.003)\tLoss 1.3749 (1.2610)\tPrec 62.500% (65.765%)\n",
      "Epoch: [216][300/391]\tTime 0.034 (0.034)\tData 0.001 (0.003)\tLoss 1.3243 (1.2604)\tPrec 64.844% (65.911%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.124 (0.124)\tLoss 1.3619 (1.3619)\tPrec 63.281% (63.281%)\n",
      " * Prec 63.940% \n",
      "best acc: 88.020000\n",
      "Epoch: [217][0/391]\tTime 0.167 (0.167)\tData 0.128 (0.128)\tLoss 1.3433 (1.3433)\tPrec 62.500% (62.500%)\n",
      "Epoch: [217][100/391]\tTime 0.032 (0.035)\tData 0.002 (0.004)\tLoss 1.2390 (1.2663)\tPrec 67.188% (65.470%)\n",
      "Epoch: [217][200/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.2291 (1.2601)\tPrec 62.500% (65.730%)\n",
      "Epoch: [217][300/391]\tTime 0.030 (0.034)\tData 0.002 (0.003)\tLoss 1.2507 (1.2631)\tPrec 63.281% (65.664%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.104 (0.104)\tLoss 1.2819 (1.2819)\tPrec 66.406% (66.406%)\n",
      " * Prec 63.730% \n",
      "best acc: 88.020000\n",
      "Epoch: [218][0/391]\tTime 0.173 (0.173)\tData 0.135 (0.135)\tLoss 1.3378 (1.3378)\tPrec 60.156% (60.156%)\n",
      "Epoch: [218][100/391]\tTime 0.030 (0.035)\tData 0.001 (0.003)\tLoss 1.4145 (1.2653)\tPrec 58.594% (65.478%)\n",
      "Epoch: [218][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.1945 (1.2646)\tPrec 66.406% (65.450%)\n",
      "Epoch: [218][300/391]\tTime 0.040 (0.034)\tData 0.001 (0.003)\tLoss 1.2593 (1.2664)\tPrec 69.531% (65.425%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.104 (0.104)\tLoss 1.3247 (1.3247)\tPrec 67.188% (67.188%)\n",
      " * Prec 64.180% \n",
      "best acc: 88.020000\n",
      "Epoch: [219][0/391]\tTime 0.172 (0.172)\tData 0.140 (0.140)\tLoss 1.3362 (1.3362)\tPrec 65.625% (65.625%)\n",
      "Epoch: [219][100/391]\tTime 0.030 (0.034)\tData 0.003 (0.003)\tLoss 1.2741 (1.2547)\tPrec 69.531% (65.803%)\n",
      "Epoch: [219][200/391]\tTime 0.036 (0.033)\tData 0.003 (0.003)\tLoss 1.2008 (1.2602)\tPrec 67.188% (65.536%)\n",
      "Epoch: [219][300/391]\tTime 0.034 (0.033)\tData 0.002 (0.002)\tLoss 1.1937 (1.2635)\tPrec 71.094% (65.511%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.097 (0.097)\tLoss 1.3447 (1.3447)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.900% \n",
      "best acc: 88.020000\n",
      "Epoch: [220][0/391]\tTime 0.168 (0.168)\tData 0.128 (0.128)\tLoss 1.2459 (1.2459)\tPrec 61.719% (61.719%)\n",
      "Epoch: [220][100/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.2131 (1.2650)\tPrec 66.406% (65.571%)\n",
      "Epoch: [220][200/391]\tTime 0.032 (0.034)\tData 0.001 (0.003)\tLoss 1.3418 (1.2581)\tPrec 60.938% (66.018%)\n",
      "Epoch: [220][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.2623 (1.2618)\tPrec 60.938% (65.931%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 1.3225 (1.3225)\tPrec 64.844% (64.844%)\n",
      " * Prec 64.370% \n",
      "best acc: 88.020000\n",
      "Epoch: [221][0/391]\tTime 0.167 (0.167)\tData 0.137 (0.137)\tLoss 1.2411 (1.2411)\tPrec 67.969% (67.969%)\n",
      "Epoch: [221][100/391]\tTime 0.034 (0.035)\tData 0.003 (0.003)\tLoss 1.2923 (1.2545)\tPrec 63.281% (65.656%)\n",
      "Epoch: [221][200/391]\tTime 0.034 (0.034)\tData 0.001 (0.003)\tLoss 1.2466 (1.2552)\tPrec 64.844% (65.734%)\n",
      "Epoch: [221][300/391]\tTime 0.030 (0.034)\tData 0.002 (0.003)\tLoss 1.3520 (1.2563)\tPrec 59.375% (65.734%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.111 (0.111)\tLoss 1.3358 (1.3358)\tPrec 64.844% (64.844%)\n",
      " * Prec 64.240% \n",
      "best acc: 88.020000\n",
      "Epoch: [222][0/391]\tTime 0.157 (0.157)\tData 0.129 (0.129)\tLoss 1.2811 (1.2811)\tPrec 67.969% (67.969%)\n",
      "Epoch: [222][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.2682 (1.2672)\tPrec 67.969% (65.130%)\n",
      "Epoch: [222][200/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.2730 (1.2680)\tPrec 64.844% (65.384%)\n",
      "Epoch: [222][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.002)\tLoss 1.2431 (1.2651)\tPrec 65.625% (65.576%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.111 (0.111)\tLoss 1.3515 (1.3515)\tPrec 61.719% (61.719%)\n",
      " * Prec 63.660% \n",
      "best acc: 88.020000\n",
      "Epoch: [223][0/391]\tTime 0.166 (0.166)\tData 0.134 (0.134)\tLoss 1.1251 (1.1251)\tPrec 74.219% (74.219%)\n",
      "Epoch: [223][100/391]\tTime 0.034 (0.035)\tData 0.002 (0.004)\tLoss 1.3066 (1.2594)\tPrec 67.969% (66.174%)\n",
      "Epoch: [223][200/391]\tTime 0.039 (0.034)\tData 0.002 (0.003)\tLoss 1.4891 (1.2666)\tPrec 53.906% (65.683%)\n",
      "Epoch: [223][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.2852 (1.2681)\tPrec 64.062% (65.503%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 1.3770 (1.3770)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.950% \n",
      "best acc: 88.020000\n",
      "Epoch: [224][0/391]\tTime 0.180 (0.180)\tData 0.145 (0.145)\tLoss 1.2233 (1.2233)\tPrec 67.188% (67.188%)\n",
      "Epoch: [224][100/391]\tTime 0.030 (0.035)\tData 0.003 (0.004)\tLoss 1.4658 (1.2645)\tPrec 54.688% (65.718%)\n",
      "Epoch: [224][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.2444 (1.2606)\tPrec 67.188% (65.897%)\n",
      "Epoch: [224][300/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.0213 (1.2591)\tPrec 81.250% (65.887%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.122 (0.122)\tLoss 1.3937 (1.3937)\tPrec 60.938% (60.938%)\n",
      " * Prec 64.340% \n",
      "best acc: 88.020000\n",
      "Epoch: [225][0/391]\tTime 0.163 (0.163)\tData 0.131 (0.131)\tLoss 1.2149 (1.2149)\tPrec 66.406% (66.406%)\n",
      "Epoch: [225][100/391]\tTime 0.028 (0.035)\tData 0.002 (0.003)\tLoss 1.5063 (1.2655)\tPrec 56.250% (65.602%)\n",
      "Epoch: [225][200/391]\tTime 0.037 (0.034)\tData 0.003 (0.003)\tLoss 1.2713 (1.2613)\tPrec 60.938% (65.578%)\n",
      "Epoch: [225][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.002)\tLoss 1.1824 (1.2592)\tPrec 65.625% (65.778%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.094 (0.094)\tLoss 1.3337 (1.3337)\tPrec 62.500% (62.500%)\n",
      " * Prec 63.780% \n",
      "best acc: 88.020000\n",
      "Epoch: [226][0/391]\tTime 0.182 (0.182)\tData 0.147 (0.147)\tLoss 1.2367 (1.2367)\tPrec 65.625% (65.625%)\n",
      "Epoch: [226][100/391]\tTime 0.028 (0.035)\tData 0.002 (0.004)\tLoss 1.3001 (1.2705)\tPrec 63.281% (65.300%)\n",
      "Epoch: [226][200/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.3647 (1.2580)\tPrec 61.719% (65.777%)\n",
      "Epoch: [226][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.3063 (1.2600)\tPrec 64.844% (65.542%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.109 (0.109)\tLoss 1.3046 (1.3046)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.590% \n",
      "best acc: 88.020000\n",
      "Epoch: [227][0/391]\tTime 0.175 (0.175)\tData 0.132 (0.132)\tLoss 1.2424 (1.2424)\tPrec 63.281% (63.281%)\n",
      "Epoch: [227][100/391]\tTime 0.035 (0.035)\tData 0.002 (0.003)\tLoss 1.3022 (1.2587)\tPrec 63.281% (65.517%)\n",
      "Epoch: [227][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.2282 (1.2569)\tPrec 63.281% (65.734%)\n",
      "Epoch: [227][300/391]\tTime 0.027 (0.034)\tData 0.002 (0.003)\tLoss 1.2272 (1.2611)\tPrec 67.969% (65.570%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 1.3371 (1.3371)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.730% \n",
      "best acc: 88.020000\n",
      "Epoch: [228][0/391]\tTime 0.190 (0.190)\tData 0.148 (0.148)\tLoss 1.3408 (1.3408)\tPrec 64.844% (64.844%)\n",
      "Epoch: [228][100/391]\tTime 0.035 (0.034)\tData 0.002 (0.004)\tLoss 1.2553 (1.2522)\tPrec 64.844% (66.600%)\n",
      "Epoch: [228][200/391]\tTime 0.030 (0.034)\tData 0.002 (0.003)\tLoss 1.2436 (1.2606)\tPrec 65.625% (66.181%)\n",
      "Epoch: [228][300/391]\tTime 0.038 (0.034)\tData 0.003 (0.003)\tLoss 1.2822 (1.2600)\tPrec 65.625% (66.020%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.105 (0.105)\tLoss 1.3309 (1.3309)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.840% \n",
      "best acc: 88.020000\n",
      "Epoch: [229][0/391]\tTime 0.185 (0.185)\tData 0.150 (0.150)\tLoss 1.2141 (1.2141)\tPrec 68.750% (68.750%)\n",
      "Epoch: [229][100/391]\tTime 0.034 (0.035)\tData 0.002 (0.004)\tLoss 1.3406 (1.2547)\tPrec 60.938% (66.128%)\n",
      "Epoch: [229][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.3767 (1.2556)\tPrec 60.156% (66.010%)\n",
      "Epoch: [229][300/391]\tTime 0.030 (0.034)\tData 0.002 (0.003)\tLoss 1.2213 (1.2562)\tPrec 65.625% (66.056%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 1.4202 (1.4202)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.420% \n",
      "best acc: 88.020000\n",
      "Epoch: [230][0/391]\tTime 0.171 (0.171)\tData 0.136 (0.136)\tLoss 1.2418 (1.2418)\tPrec 65.625% (65.625%)\n",
      "Epoch: [230][100/391]\tTime 0.034 (0.036)\tData 0.002 (0.004)\tLoss 1.2211 (1.2634)\tPrec 71.094% (66.120%)\n",
      "Epoch: [230][200/391]\tTime 0.034 (0.035)\tData 0.003 (0.003)\tLoss 1.2891 (1.2643)\tPrec 68.750% (65.777%)\n",
      "Epoch: [230][300/391]\tTime 0.029 (0.035)\tData 0.002 (0.003)\tLoss 1.2656 (1.2627)\tPrec 64.844% (65.708%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 1.3274 (1.3274)\tPrec 63.281% (63.281%)\n",
      " * Prec 63.520% \n",
      "best acc: 88.020000\n",
      "Epoch: [231][0/391]\tTime 0.166 (0.166)\tData 0.132 (0.132)\tLoss 1.3869 (1.3869)\tPrec 65.625% (65.625%)\n",
      "Epoch: [231][100/391]\tTime 0.034 (0.035)\tData 0.002 (0.003)\tLoss 1.4848 (1.2632)\tPrec 58.594% (65.122%)\n",
      "Epoch: [231][200/391]\tTime 0.030 (0.034)\tData 0.002 (0.003)\tLoss 1.1987 (1.2555)\tPrec 65.625% (65.854%)\n",
      "Epoch: [231][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.2829 (1.2608)\tPrec 59.375% (65.750%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 1.3237 (1.3237)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.760% \n",
      "best acc: 88.020000\n",
      "Epoch: [232][0/391]\tTime 0.172 (0.172)\tData 0.137 (0.137)\tLoss 1.3482 (1.3482)\tPrec 62.500% (62.500%)\n",
      "Epoch: [232][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.1979 (1.2672)\tPrec 67.188% (65.439%)\n",
      "Epoch: [232][200/391]\tTime 0.038 (0.035)\tData 0.002 (0.003)\tLoss 1.3202 (1.2657)\tPrec 60.938% (65.431%)\n",
      "Epoch: [232][300/391]\tTime 0.037 (0.035)\tData 0.001 (0.003)\tLoss 1.3313 (1.2647)\tPrec 64.844% (65.438%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.111 (0.111)\tLoss 1.2973 (1.2973)\tPrec 68.750% (68.750%)\n",
      " * Prec 63.880% \n",
      "best acc: 88.020000\n",
      "Epoch: [233][0/391]\tTime 0.168 (0.168)\tData 0.132 (0.132)\tLoss 1.2822 (1.2822)\tPrec 64.062% (64.062%)\n",
      "Epoch: [233][100/391]\tTime 0.033 (0.035)\tData 0.003 (0.004)\tLoss 1.2372 (1.2585)\tPrec 68.750% (65.695%)\n",
      "Epoch: [233][200/391]\tTime 0.036 (0.035)\tData 0.002 (0.003)\tLoss 1.3912 (1.2611)\tPrec 57.812% (65.493%)\n",
      "Epoch: [233][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.2647 (1.2616)\tPrec 64.844% (65.526%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.120 (0.120)\tLoss 1.2942 (1.2942)\tPrec 67.188% (67.188%)\n",
      " * Prec 63.680% \n",
      "best acc: 88.020000\n",
      "Epoch: [234][0/391]\tTime 0.161 (0.161)\tData 0.121 (0.121)\tLoss 1.2838 (1.2838)\tPrec 66.406% (66.406%)\n",
      "Epoch: [234][100/391]\tTime 0.039 (0.035)\tData 0.001 (0.003)\tLoss 1.1210 (1.2662)\tPrec 71.875% (65.037%)\n",
      "Epoch: [234][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3068 (1.2660)\tPrec 61.719% (65.361%)\n",
      "Epoch: [234][300/391]\tTime 0.028 (0.033)\tData 0.002 (0.002)\tLoss 1.2735 (1.2651)\tPrec 62.500% (65.498%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 1.3246 (1.3246)\tPrec 65.625% (65.625%)\n",
      " * Prec 64.040% \n",
      "best acc: 88.020000\n",
      "Epoch: [235][0/391]\tTime 0.161 (0.161)\tData 0.129 (0.129)\tLoss 1.3011 (1.3011)\tPrec 63.281% (63.281%)\n",
      "Epoch: [235][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.004)\tLoss 1.2009 (1.2693)\tPrec 66.406% (65.153%)\n",
      "Epoch: [235][200/391]\tTime 0.025 (0.034)\tData 0.002 (0.003)\tLoss 1.3375 (1.2721)\tPrec 63.281% (64.937%)\n",
      "Epoch: [235][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.2572 (1.2633)\tPrec 64.062% (65.345%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.108 (0.108)\tLoss 1.3400 (1.3400)\tPrec 60.938% (60.938%)\n",
      " * Prec 63.700% \n",
      "best acc: 88.020000\n",
      "Epoch: [236][0/391]\tTime 0.189 (0.189)\tData 0.149 (0.149)\tLoss 1.3654 (1.3654)\tPrec 67.969% (67.969%)\n",
      "Epoch: [236][100/391]\tTime 0.039 (0.035)\tData 0.002 (0.004)\tLoss 1.3165 (1.2635)\tPrec 59.375% (66.066%)\n",
      "Epoch: [236][200/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.1824 (1.2696)\tPrec 64.062% (65.769%)\n",
      "Epoch: [236][300/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.1667 (1.2634)\tPrec 68.750% (65.929%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 1.3616 (1.3616)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.780% \n",
      "best acc: 88.020000\n",
      "Epoch: [237][0/391]\tTime 0.175 (0.175)\tData 0.141 (0.141)\tLoss 1.2862 (1.2862)\tPrec 64.062% (64.062%)\n",
      "Epoch: [237][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.004)\tLoss 1.2357 (1.2478)\tPrec 68.750% (66.120%)\n",
      "Epoch: [237][200/391]\tTime 0.037 (0.034)\tData 0.003 (0.003)\tLoss 1.2456 (1.2522)\tPrec 64.844% (65.979%)\n",
      "Epoch: [237][300/391]\tTime 0.038 (0.034)\tData 0.003 (0.003)\tLoss 1.1998 (1.2543)\tPrec 67.188% (65.874%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.123 (0.123)\tLoss 1.3298 (1.3298)\tPrec 62.500% (62.500%)\n",
      " * Prec 63.680% \n",
      "best acc: 88.020000\n",
      "Epoch: [238][0/391]\tTime 0.179 (0.179)\tData 0.138 (0.138)\tLoss 1.4086 (1.4086)\tPrec 59.375% (59.375%)\n",
      "Epoch: [238][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.3539 (1.2633)\tPrec 62.500% (65.269%)\n",
      "Epoch: [238][200/391]\tTime 0.026 (0.034)\tData 0.001 (0.003)\tLoss 1.1508 (1.2555)\tPrec 71.094% (65.788%)\n",
      "Epoch: [238][300/391]\tTime 0.039 (0.033)\tData 0.003 (0.002)\tLoss 1.2087 (1.2553)\tPrec 67.188% (65.833%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 1.3209 (1.3209)\tPrec 66.406% (66.406%)\n",
      " * Prec 64.030% \n",
      "best acc: 88.020000\n",
      "Epoch: [239][0/391]\tTime 0.192 (0.192)\tData 0.149 (0.149)\tLoss 1.2953 (1.2953)\tPrec 64.062% (64.062%)\n",
      "Epoch: [239][100/391]\tTime 0.030 (0.035)\tData 0.001 (0.004)\tLoss 1.2052 (1.2641)\tPrec 69.531% (66.027%)\n",
      "Epoch: [239][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.2149 (1.2568)\tPrec 69.531% (66.029%)\n",
      "Epoch: [239][300/391]\tTime 0.035 (0.034)\tData 0.003 (0.003)\tLoss 1.3106 (1.2578)\tPrec 60.156% (66.025%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.108 (0.108)\tLoss 1.3747 (1.3747)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.860% \n",
      "best acc: 88.020000\n",
      "Epoch: [240][0/391]\tTime 0.175 (0.175)\tData 0.131 (0.131)\tLoss 1.3259 (1.3259)\tPrec 60.938% (60.938%)\n",
      "Epoch: [240][100/391]\tTime 0.029 (0.035)\tData 0.002 (0.003)\tLoss 1.2676 (1.2584)\tPrec 64.062% (65.470%)\n",
      "Epoch: [240][200/391]\tTime 0.030 (0.034)\tData 0.003 (0.003)\tLoss 1.2929 (1.2568)\tPrec 66.406% (65.940%)\n",
      "Epoch: [240][300/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.2006 (1.2601)\tPrec 72.656% (65.708%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 1.3661 (1.3661)\tPrec 64.844% (64.844%)\n",
      " * Prec 64.250% \n",
      "best acc: 88.020000\n",
      "Epoch: [241][0/391]\tTime 0.180 (0.180)\tData 0.143 (0.143)\tLoss 1.3069 (1.3069)\tPrec 60.938% (60.938%)\n",
      "Epoch: [241][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.3399 (1.2522)\tPrec 61.719% (65.996%)\n",
      "Epoch: [241][200/391]\tTime 0.041 (0.034)\tData 0.003 (0.003)\tLoss 1.2850 (1.2525)\tPrec 67.969% (66.060%)\n",
      "Epoch: [241][300/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.2059 (1.2543)\tPrec 69.531% (65.923%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.126 (0.126)\tLoss 1.3383 (1.3383)\tPrec 61.719% (61.719%)\n",
      " * Prec 63.660% \n",
      "best acc: 88.020000\n",
      "Epoch: [242][0/391]\tTime 0.166 (0.166)\tData 0.130 (0.130)\tLoss 1.2936 (1.2936)\tPrec 65.625% (65.625%)\n",
      "Epoch: [242][100/391]\tTime 0.035 (0.035)\tData 0.003 (0.003)\tLoss 1.1863 (1.2551)\tPrec 69.531% (65.656%)\n",
      "Epoch: [242][200/391]\tTime 0.034 (0.034)\tData 0.003 (0.003)\tLoss 1.3744 (1.2583)\tPrec 62.500% (65.660%)\n",
      "Epoch: [242][300/391]\tTime 0.027 (0.034)\tData 0.001 (0.003)\tLoss 1.2142 (1.2575)\tPrec 67.969% (65.687%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.117 (0.117)\tLoss 1.3452 (1.3452)\tPrec 67.969% (67.969%)\n",
      " * Prec 63.580% \n",
      "best acc: 88.020000\n",
      "Epoch: [243][0/391]\tTime 0.172 (0.172)\tData 0.134 (0.134)\tLoss 1.3202 (1.3202)\tPrec 61.719% (61.719%)\n",
      "Epoch: [243][100/391]\tTime 0.037 (0.035)\tData 0.003 (0.003)\tLoss 1.2435 (1.2546)\tPrec 67.188% (66.282%)\n",
      "Epoch: [243][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.2536 (1.2490)\tPrec 64.844% (66.317%)\n",
      "Epoch: [243][300/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.1878 (1.2550)\tPrec 64.844% (66.040%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 1.3364 (1.3364)\tPrec 67.188% (67.188%)\n",
      " * Prec 64.090% \n",
      "best acc: 88.020000\n",
      "Epoch: [244][0/391]\tTime 0.170 (0.170)\tData 0.129 (0.129)\tLoss 1.2681 (1.2681)\tPrec 67.969% (67.969%)\n",
      "Epoch: [244][100/391]\tTime 0.037 (0.035)\tData 0.002 (0.003)\tLoss 1.2139 (1.2734)\tPrec 66.406% (65.269%)\n",
      "Epoch: [244][200/391]\tTime 0.037 (0.034)\tData 0.003 (0.003)\tLoss 1.1530 (1.2656)\tPrec 68.750% (65.485%)\n",
      "Epoch: [244][300/391]\tTime 0.030 (0.034)\tData 0.003 (0.003)\tLoss 1.1593 (1.2607)\tPrec 74.219% (65.804%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.100 (0.100)\tLoss 1.2411 (1.2411)\tPrec 67.969% (67.969%)\n",
      " * Prec 63.840% \n",
      "best acc: 88.020000\n",
      "Epoch: [245][0/391]\tTime 0.176 (0.176)\tData 0.131 (0.131)\tLoss 1.2994 (1.2994)\tPrec 66.406% (66.406%)\n",
      "Epoch: [245][100/391]\tTime 0.038 (0.035)\tData 0.002 (0.003)\tLoss 1.4089 (1.2593)\tPrec 56.250% (65.509%)\n",
      "Epoch: [245][200/391]\tTime 0.029 (0.034)\tData 0.002 (0.003)\tLoss 1.3175 (1.2561)\tPrec 61.719% (65.641%)\n",
      "Epoch: [245][300/391]\tTime 0.028 (0.034)\tData 0.002 (0.003)\tLoss 1.3121 (1.2561)\tPrec 60.938% (65.713%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.116 (0.116)\tLoss 1.3304 (1.3304)\tPrec 69.531% (69.531%)\n",
      " * Prec 63.900% \n",
      "best acc: 88.020000\n",
      "Epoch: [246][0/391]\tTime 0.162 (0.162)\tData 0.132 (0.132)\tLoss 1.3010 (1.3010)\tPrec 64.844% (64.844%)\n",
      "Epoch: [246][100/391]\tTime 0.038 (0.035)\tData 0.003 (0.003)\tLoss 1.3161 (1.2571)\tPrec 62.500% (65.625%)\n",
      "Epoch: [246][200/391]\tTime 0.035 (0.035)\tData 0.002 (0.003)\tLoss 1.3310 (1.2589)\tPrec 63.281% (65.753%)\n",
      "Epoch: [246][300/391]\tTime 0.033 (0.034)\tData 0.003 (0.003)\tLoss 1.1216 (1.2587)\tPrec 71.094% (65.848%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.120 (0.120)\tLoss 1.2993 (1.2993)\tPrec 67.969% (67.969%)\n",
      " * Prec 63.350% \n",
      "best acc: 88.020000\n",
      "Epoch: [247][0/391]\tTime 0.163 (0.163)\tData 0.122 (0.122)\tLoss 1.2853 (1.2853)\tPrec 67.188% (67.188%)\n",
      "Epoch: [247][100/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.3941 (1.2573)\tPrec 58.594% (66.228%)\n",
      "Epoch: [247][200/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.2764 (1.2607)\tPrec 64.844% (65.936%)\n",
      "Epoch: [247][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.002)\tLoss 1.1904 (1.2608)\tPrec 72.656% (65.890%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.117 (0.117)\tLoss 1.3602 (1.3602)\tPrec 67.188% (67.188%)\n",
      " * Prec 63.940% \n",
      "best acc: 88.020000\n",
      "Epoch: [248][0/391]\tTime 0.160 (0.160)\tData 0.132 (0.132)\tLoss 1.2072 (1.2072)\tPrec 66.406% (66.406%)\n",
      "Epoch: [248][100/391]\tTime 0.030 (0.035)\tData 0.002 (0.004)\tLoss 1.1592 (1.2509)\tPrec 71.875% (65.958%)\n",
      "Epoch: [248][200/391]\tTime 0.027 (0.034)\tData 0.002 (0.003)\tLoss 1.2978 (1.2531)\tPrec 67.188% (66.181%)\n",
      "Epoch: [248][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.2449 (1.2586)\tPrec 67.969% (65.947%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.100 (0.100)\tLoss 1.3436 (1.3436)\tPrec 63.281% (63.281%)\n",
      " * Prec 64.120% \n",
      "best acc: 88.020000\n",
      "Epoch: [249][0/391]\tTime 0.183 (0.183)\tData 0.142 (0.142)\tLoss 1.2176 (1.2176)\tPrec 70.312% (70.312%)\n",
      "Epoch: [249][100/391]\tTime 0.030 (0.034)\tData 0.002 (0.003)\tLoss 1.2949 (1.2504)\tPrec 63.281% (66.043%)\n",
      "Epoch: [249][200/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.1566 (1.2533)\tPrec 68.750% (66.107%)\n",
      "Epoch: [249][300/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.2694 (1.2570)\tPrec 64.844% (65.840%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 1.3441 (1.3441)\tPrec 66.406% (66.406%)\n",
      " * Prec 63.470% \n",
      "best acc: 88.020000\n",
      "Epoch: [250][0/391]\tTime 0.169 (0.169)\tData 0.130 (0.130)\tLoss 1.2535 (1.2535)\tPrec 65.625% (65.625%)\n",
      "Epoch: [250][100/391]\tTime 0.037 (0.035)\tData 0.002 (0.003)\tLoss 1.2444 (1.2582)\tPrec 66.406% (65.888%)\n",
      "Epoch: [250][200/391]\tTime 0.035 (0.035)\tData 0.002 (0.003)\tLoss 1.1207 (1.2594)\tPrec 71.875% (66.002%)\n",
      "Epoch: [250][300/391]\tTime 0.038 (0.035)\tData 0.002 (0.003)\tLoss 1.2169 (1.2599)\tPrec 65.625% (65.830%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 1.2980 (1.2980)\tPrec 70.312% (70.312%)\n",
      " * Prec 63.220% \n",
      "best acc: 88.020000\n",
      "Epoch: [251][0/391]\tTime 0.165 (0.165)\tData 0.129 (0.129)\tLoss 1.3826 (1.3826)\tPrec 61.719% (61.719%)\n",
      "Epoch: [251][100/391]\tTime 0.037 (0.035)\tData 0.002 (0.003)\tLoss 1.2381 (1.2609)\tPrec 69.531% (65.602%)\n",
      "Epoch: [251][200/391]\tTime 0.029 (0.034)\tData 0.002 (0.003)\tLoss 1.3641 (1.2636)\tPrec 64.844% (65.648%)\n",
      "Epoch: [251][300/391]\tTime 0.039 (0.034)\tData 0.002 (0.003)\tLoss 1.2985 (1.2590)\tPrec 64.062% (65.833%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.101 (0.101)\tLoss 1.3312 (1.3312)\tPrec 66.406% (66.406%)\n",
      " * Prec 63.690% \n",
      "best acc: 88.020000\n",
      "Epoch: [252][0/391]\tTime 0.186 (0.186)\tData 0.144 (0.144)\tLoss 1.1877 (1.1877)\tPrec 66.406% (66.406%)\n",
      "Epoch: [252][100/391]\tTime 0.034 (0.036)\tData 0.002 (0.004)\tLoss 1.1782 (1.2574)\tPrec 70.312% (66.050%)\n",
      "Epoch: [252][200/391]\tTime 0.038 (0.036)\tData 0.002 (0.003)\tLoss 1.2679 (1.2612)\tPrec 64.844% (65.656%)\n",
      "Epoch: [252][300/391]\tTime 0.035 (0.036)\tData 0.002 (0.003)\tLoss 1.2174 (1.2594)\tPrec 64.844% (65.643%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.122 (0.122)\tLoss 1.3069 (1.3069)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.890% \n",
      "best acc: 88.020000\n",
      "Epoch: [253][0/391]\tTime 0.171 (0.171)\tData 0.134 (0.134)\tLoss 1.2352 (1.2352)\tPrec 65.625% (65.625%)\n",
      "Epoch: [253][100/391]\tTime 0.038 (0.035)\tData 0.002 (0.003)\tLoss 1.2296 (1.2579)\tPrec 66.406% (65.826%)\n",
      "Epoch: [253][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.3675 (1.2557)\tPrec 57.812% (65.940%)\n",
      "Epoch: [253][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.3286 (1.2595)\tPrec 61.719% (65.755%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 1.3316 (1.3316)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.620% \n",
      "best acc: 88.020000\n",
      "Epoch: [254][0/391]\tTime 0.162 (0.162)\tData 0.124 (0.124)\tLoss 1.0590 (1.0590)\tPrec 75.781% (75.781%)\n",
      "Epoch: [254][100/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.3052 (1.2622)\tPrec 64.062% (65.927%)\n",
      "Epoch: [254][200/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.2565 (1.2556)\tPrec 64.844% (65.889%)\n",
      "Epoch: [254][300/391]\tTime 0.038 (0.035)\tData 0.002 (0.003)\tLoss 1.1614 (1.2575)\tPrec 69.531% (65.789%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.104 (0.104)\tLoss 1.3261 (1.3261)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.380% \n",
      "best acc: 88.020000\n",
      "Epoch: [255][0/391]\tTime 0.163 (0.163)\tData 0.132 (0.132)\tLoss 1.2904 (1.2904)\tPrec 66.406% (66.406%)\n",
      "Epoch: [255][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.004)\tLoss 1.3406 (1.2592)\tPrec 62.500% (65.896%)\n",
      "Epoch: [255][200/391]\tTime 0.039 (0.034)\tData 0.002 (0.003)\tLoss 1.3413 (1.2626)\tPrec 63.281% (65.812%)\n",
      "Epoch: [255][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.2360 (1.2591)\tPrec 64.062% (65.846%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.099 (0.099)\tLoss 1.3280 (1.3280)\tPrec 64.844% (64.844%)\n",
      " * Prec 64.000% \n",
      "best acc: 88.020000\n",
      "Epoch: [256][0/391]\tTime 0.174 (0.174)\tData 0.131 (0.131)\tLoss 1.3357 (1.3357)\tPrec 64.844% (64.844%)\n",
      "Epoch: [256][100/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.1467 (1.2642)\tPrec 75.000% (65.370%)\n",
      "Epoch: [256][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.1881 (1.2524)\tPrec 72.656% (66.037%)\n",
      "Epoch: [256][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.1892 (1.2576)\tPrec 66.406% (65.695%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.104 (0.104)\tLoss 1.3587 (1.3587)\tPrec 62.500% (62.500%)\n",
      " * Prec 63.890% \n",
      "best acc: 88.020000\n",
      "Epoch: [257][0/391]\tTime 0.166 (0.166)\tData 0.133 (0.133)\tLoss 1.1507 (1.1507)\tPrec 70.312% (70.312%)\n",
      "Epoch: [257][100/391]\tTime 0.032 (0.034)\tData 0.003 (0.003)\tLoss 1.1695 (1.2535)\tPrec 71.875% (66.159%)\n",
      "Epoch: [257][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.3419 (1.2580)\tPrec 59.375% (65.769%)\n",
      "Epoch: [257][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.2248 (1.2591)\tPrec 71.875% (65.729%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 1.2827 (1.2827)\tPrec 67.969% (67.969%)\n",
      " * Prec 63.530% \n",
      "best acc: 88.020000\n",
      "Epoch: [258][0/391]\tTime 0.167 (0.167)\tData 0.133 (0.133)\tLoss 1.3581 (1.3581)\tPrec 60.938% (60.938%)\n",
      "Epoch: [258][100/391]\tTime 0.032 (0.035)\tData 0.003 (0.004)\tLoss 1.2060 (1.2581)\tPrec 69.531% (65.695%)\n",
      "Epoch: [258][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.3723 (1.2594)\tPrec 60.938% (65.707%)\n",
      "Epoch: [258][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.3342 (1.2577)\tPrec 61.719% (65.885%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.116 (0.116)\tLoss 1.3251 (1.3251)\tPrec 65.625% (65.625%)\n",
      " * Prec 64.260% \n",
      "best acc: 88.020000\n",
      "Epoch: [259][0/391]\tTime 0.180 (0.180)\tData 0.138 (0.138)\tLoss 1.2161 (1.2161)\tPrec 69.531% (69.531%)\n",
      "Epoch: [259][100/391]\tTime 0.037 (0.035)\tData 0.002 (0.003)\tLoss 1.2940 (1.2573)\tPrec 66.406% (65.640%)\n",
      "Epoch: [259][200/391]\tTime 0.028 (0.034)\tData 0.002 (0.003)\tLoss 1.3641 (1.2561)\tPrec 63.281% (65.792%)\n",
      "Epoch: [259][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.1372 (1.2539)\tPrec 71.875% (65.960%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 1.2875 (1.2875)\tPrec 70.312% (70.312%)\n",
      " * Prec 63.360% \n",
      "best acc: 88.020000\n",
      "Epoch: [260][0/391]\tTime 0.169 (0.169)\tData 0.137 (0.137)\tLoss 1.2985 (1.2985)\tPrec 60.938% (60.938%)\n",
      "Epoch: [260][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.3014 (1.2602)\tPrec 64.062% (66.221%)\n",
      "Epoch: [260][200/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.2419 (1.2545)\tPrec 64.062% (66.262%)\n",
      "Epoch: [260][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.3655 (1.2573)\tPrec 57.031% (66.121%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 1.2991 (1.2991)\tPrec 67.969% (67.969%)\n",
      " * Prec 64.140% \n",
      "best acc: 88.020000\n",
      "Epoch: [261][0/391]\tTime 0.183 (0.183)\tData 0.144 (0.144)\tLoss 1.3829 (1.3829)\tPrec 59.375% (59.375%)\n",
      "Epoch: [261][100/391]\tTime 0.032 (0.034)\tData 0.002 (0.004)\tLoss 1.3918 (1.2726)\tPrec 58.594% (65.254%)\n",
      "Epoch: [261][200/391]\tTime 0.038 (0.034)\tData 0.003 (0.003)\tLoss 1.3297 (1.2650)\tPrec 60.938% (65.633%)\n",
      "Epoch: [261][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.1793 (1.2622)\tPrec 63.281% (65.773%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 1.3363 (1.3363)\tPrec 62.500% (62.500%)\n",
      " * Prec 63.180% \n",
      "best acc: 88.020000\n",
      "Epoch: [262][0/391]\tTime 0.165 (0.165)\tData 0.133 (0.133)\tLoss 1.3897 (1.3897)\tPrec 60.156% (60.156%)\n",
      "Epoch: [262][100/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.2657 (1.2540)\tPrec 58.594% (66.136%)\n",
      "Epoch: [262][200/391]\tTime 0.034 (0.034)\tData 0.003 (0.003)\tLoss 1.3119 (1.2495)\tPrec 64.844% (66.453%)\n",
      "Epoch: [262][300/391]\tTime 0.034 (0.034)\tData 0.003 (0.003)\tLoss 1.2366 (1.2578)\tPrec 67.969% (66.035%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.095 (0.095)\tLoss 1.3358 (1.3358)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.710% \n",
      "best acc: 88.020000\n",
      "Epoch: [263][0/391]\tTime 0.151 (0.151)\tData 0.119 (0.119)\tLoss 1.1382 (1.1382)\tPrec 70.312% (70.312%)\n",
      "Epoch: [263][100/391]\tTime 0.030 (0.034)\tData 0.002 (0.003)\tLoss 1.2172 (1.2672)\tPrec 65.625% (65.161%)\n",
      "Epoch: [263][200/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.2354 (1.2610)\tPrec 63.281% (65.823%)\n",
      "Epoch: [263][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.1624 (1.2585)\tPrec 67.188% (65.965%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.119 (0.119)\tLoss 1.3259 (1.3259)\tPrec 68.750% (68.750%)\n",
      " * Prec 63.910% \n",
      "best acc: 88.020000\n",
      "Epoch: [264][0/391]\tTime 0.168 (0.168)\tData 0.128 (0.128)\tLoss 1.0999 (1.0999)\tPrec 75.781% (75.781%)\n",
      "Epoch: [264][100/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.2522 (1.2406)\tPrec 69.531% (66.894%)\n",
      "Epoch: [264][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.2691 (1.2544)\tPrec 67.188% (66.329%)\n",
      "Epoch: [264][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.1308 (1.2556)\tPrec 71.094% (66.100%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.105 (0.105)\tLoss 1.3069 (1.3069)\tPrec 67.188% (67.188%)\n",
      " * Prec 63.750% \n",
      "best acc: 88.020000\n",
      "Epoch: [265][0/391]\tTime 0.167 (0.167)\tData 0.134 (0.134)\tLoss 1.2516 (1.2516)\tPrec 69.531% (69.531%)\n",
      "Epoch: [265][100/391]\tTime 0.037 (0.035)\tData 0.002 (0.004)\tLoss 1.1951 (1.2508)\tPrec 69.531% (65.733%)\n",
      "Epoch: [265][200/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.2087 (1.2563)\tPrec 69.531% (65.804%)\n",
      "Epoch: [265][300/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.3412 (1.2550)\tPrec 61.719% (65.877%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.115 (0.115)\tLoss 1.2852 (1.2852)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.520% \n",
      "best acc: 88.020000\n",
      "Epoch: [266][0/391]\tTime 0.171 (0.171)\tData 0.130 (0.130)\tLoss 1.2020 (1.2020)\tPrec 70.312% (70.312%)\n",
      "Epoch: [266][100/391]\tTime 0.038 (0.035)\tData 0.002 (0.003)\tLoss 1.1843 (1.2417)\tPrec 67.188% (66.785%)\n",
      "Epoch: [266][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.3094 (1.2520)\tPrec 60.938% (66.130%)\n",
      "Epoch: [266][300/391]\tTime 0.033 (0.034)\tData 0.001 (0.003)\tLoss 1.2395 (1.2558)\tPrec 64.844% (65.949%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 1.3365 (1.3365)\tPrec 64.844% (64.844%)\n",
      " * Prec 64.450% \n",
      "best acc: 88.020000\n",
      "Epoch: [267][0/391]\tTime 0.156 (0.156)\tData 0.121 (0.121)\tLoss 1.2179 (1.2179)\tPrec 70.312% (70.312%)\n",
      "Epoch: [267][100/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.2934 (1.2588)\tPrec 64.844% (66.027%)\n",
      "Epoch: [267][200/391]\tTime 0.030 (0.034)\tData 0.002 (0.003)\tLoss 1.2660 (1.2579)\tPrec 72.656% (66.049%)\n",
      "Epoch: [267][300/391]\tTime 0.028 (0.033)\tData 0.002 (0.003)\tLoss 1.1866 (1.2527)\tPrec 70.312% (66.134%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.104 (0.104)\tLoss 1.3162 (1.3162)\tPrec 67.969% (67.969%)\n",
      " * Prec 63.750% \n",
      "best acc: 88.020000\n",
      "Epoch: [268][0/391]\tTime 0.183 (0.183)\tData 0.141 (0.141)\tLoss 1.3200 (1.3200)\tPrec 64.062% (64.062%)\n",
      "Epoch: [268][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.1352 (1.2512)\tPrec 74.219% (66.445%)\n",
      "Epoch: [268][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.3612 (1.2560)\tPrec 67.188% (66.119%)\n",
      "Epoch: [268][300/391]\tTime 0.028 (0.034)\tData 0.002 (0.003)\tLoss 1.2541 (1.2600)\tPrec 62.500% (65.757%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 1.3702 (1.3702)\tPrec 69.531% (69.531%)\n",
      " * Prec 63.520% \n",
      "best acc: 88.020000\n",
      "Epoch: [269][0/391]\tTime 0.176 (0.176)\tData 0.141 (0.141)\tLoss 1.1872 (1.1872)\tPrec 65.625% (65.625%)\n",
      "Epoch: [269][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.004)\tLoss 1.1255 (1.2552)\tPrec 75.000% (65.849%)\n",
      "Epoch: [269][200/391]\tTime 0.035 (0.034)\tData 0.003 (0.003)\tLoss 1.2088 (1.2489)\tPrec 67.188% (66.309%)\n",
      "Epoch: [269][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.1623 (1.2494)\tPrec 71.094% (66.349%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.116 (0.116)\tLoss 1.2958 (1.2958)\tPrec 67.969% (67.969%)\n",
      " * Prec 63.760% \n",
      "best acc: 88.020000\n",
      "Epoch: [270][0/391]\tTime 0.165 (0.165)\tData 0.126 (0.126)\tLoss 1.2573 (1.2573)\tPrec 67.969% (67.969%)\n",
      "Epoch: [270][100/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.0946 (1.2611)\tPrec 71.875% (66.050%)\n",
      "Epoch: [270][200/391]\tTime 0.032 (0.033)\tData 0.001 (0.003)\tLoss 1.3373 (1.2630)\tPrec 62.500% (65.812%)\n",
      "Epoch: [270][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.002)\tLoss 1.2544 (1.2597)\tPrec 72.656% (65.936%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.111 (0.111)\tLoss 1.3305 (1.3305)\tPrec 62.500% (62.500%)\n",
      " * Prec 63.830% \n",
      "best acc: 88.020000\n",
      "Epoch: [271][0/391]\tTime 0.173 (0.173)\tData 0.134 (0.134)\tLoss 1.3151 (1.3151)\tPrec 61.719% (61.719%)\n",
      "Epoch: [271][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.2720 (1.2534)\tPrec 63.281% (66.166%)\n",
      "Epoch: [271][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.3155 (1.2619)\tPrec 62.500% (65.563%)\n",
      "Epoch: [271][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.3837 (1.2597)\tPrec 60.938% (65.713%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.099 (0.099)\tLoss 1.3479 (1.3479)\tPrec 68.750% (68.750%)\n",
      " * Prec 64.390% \n",
      "best acc: 88.020000\n",
      "Epoch: [272][0/391]\tTime 0.180 (0.180)\tData 0.140 (0.140)\tLoss 1.1176 (1.1176)\tPrec 78.125% (78.125%)\n",
      "Epoch: [272][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.004)\tLoss 1.2847 (1.2570)\tPrec 64.062% (65.625%)\n",
      "Epoch: [272][200/391]\tTime 0.036 (0.034)\tData 0.003 (0.003)\tLoss 1.2179 (1.2539)\tPrec 65.625% (66.018%)\n",
      "Epoch: [272][300/391]\tTime 0.031 (0.034)\tData 0.001 (0.003)\tLoss 1.2408 (1.2568)\tPrec 66.406% (65.796%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.111 (0.111)\tLoss 1.3429 (1.3429)\tPrec 64.062% (64.062%)\n",
      " * Prec 63.590% \n",
      "best acc: 88.020000\n",
      "Epoch: [273][0/391]\tTime 0.168 (0.168)\tData 0.137 (0.137)\tLoss 1.3152 (1.3152)\tPrec 65.625% (65.625%)\n",
      "Epoch: [273][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.004)\tLoss 1.3551 (1.2500)\tPrec 60.938% (66.306%)\n",
      "Epoch: [273][200/391]\tTime 0.032 (0.034)\tData 0.003 (0.003)\tLoss 1.1580 (1.2526)\tPrec 70.312% (66.161%)\n",
      "Epoch: [273][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.3355 (1.2559)\tPrec 59.375% (66.014%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.137 (0.137)\tLoss 1.3197 (1.3197)\tPrec 66.406% (66.406%)\n",
      " * Prec 64.200% \n",
      "best acc: 88.020000\n",
      "Epoch: [274][0/391]\tTime 0.179 (0.179)\tData 0.134 (0.134)\tLoss 1.2221 (1.2221)\tPrec 67.969% (67.969%)\n",
      "Epoch: [274][100/391]\tTime 0.030 (0.035)\tData 0.003 (0.003)\tLoss 1.4222 (1.2631)\tPrec 56.250% (65.617%)\n",
      "Epoch: [274][200/391]\tTime 0.033 (0.034)\tData 0.003 (0.003)\tLoss 1.2801 (1.2570)\tPrec 62.500% (65.858%)\n",
      "Epoch: [274][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.1911 (1.2583)\tPrec 69.531% (65.804%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.106 (0.106)\tLoss 1.3589 (1.3589)\tPrec 67.188% (67.188%)\n",
      " * Prec 63.100% \n",
      "best acc: 88.020000\n",
      "Epoch: [275][0/391]\tTime 0.174 (0.174)\tData 0.135 (0.135)\tLoss 1.2368 (1.2368)\tPrec 62.500% (62.500%)\n",
      "Epoch: [275][100/391]\tTime 0.034 (0.035)\tData 0.002 (0.003)\tLoss 1.2708 (1.2589)\tPrec 66.406% (65.362%)\n",
      "Epoch: [275][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.2270 (1.2521)\tPrec 66.406% (65.909%)\n",
      "Epoch: [275][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.2992 (1.2526)\tPrec 64.062% (65.890%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.118 (0.118)\tLoss 1.3665 (1.3665)\tPrec 62.500% (62.500%)\n",
      " * Prec 63.660% \n",
      "best acc: 88.020000\n",
      "Epoch: [276][0/391]\tTime 0.174 (0.174)\tData 0.131 (0.131)\tLoss 1.2761 (1.2761)\tPrec 64.062% (64.062%)\n",
      "Epoch: [276][100/391]\tTime 0.034 (0.035)\tData 0.002 (0.003)\tLoss 1.3106 (1.2607)\tPrec 66.406% (66.074%)\n",
      "Epoch: [276][200/391]\tTime 0.032 (0.034)\tData 0.001 (0.003)\tLoss 1.2828 (1.2589)\tPrec 58.594% (65.815%)\n",
      "Epoch: [276][300/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.2873 (1.2582)\tPrec 60.938% (65.809%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 1.2946 (1.2946)\tPrec 64.062% (64.062%)\n",
      " * Prec 64.200% \n",
      "best acc: 88.020000\n",
      "Epoch: [277][0/391]\tTime 0.160 (0.160)\tData 0.132 (0.132)\tLoss 1.2773 (1.2773)\tPrec 62.500% (62.500%)\n",
      "Epoch: [277][100/391]\tTime 0.039 (0.035)\tData 0.002 (0.003)\tLoss 1.3257 (1.2493)\tPrec 61.719% (65.787%)\n",
      "Epoch: [277][200/391]\tTime 0.029 (0.034)\tData 0.001 (0.003)\tLoss 1.1881 (1.2538)\tPrec 76.562% (65.714%)\n",
      "Epoch: [277][300/391]\tTime 0.033 (0.033)\tData 0.002 (0.002)\tLoss 1.3144 (1.2568)\tPrec 64.844% (65.589%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 1.2765 (1.2765)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.880% \n",
      "best acc: 88.020000\n",
      "Epoch: [278][0/391]\tTime 0.181 (0.181)\tData 0.142 (0.142)\tLoss 1.3014 (1.3014)\tPrec 63.281% (63.281%)\n",
      "Epoch: [278][100/391]\tTime 0.035 (0.035)\tData 0.002 (0.004)\tLoss 1.3379 (1.2546)\tPrec 62.500% (66.213%)\n",
      "Epoch: [278][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.3499 (1.2607)\tPrec 64.844% (65.742%)\n",
      "Epoch: [278][300/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.2199 (1.2618)\tPrec 67.188% (65.615%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.098 (0.098)\tLoss 1.3581 (1.3581)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.840% \n",
      "best acc: 88.020000\n",
      "Epoch: [279][0/391]\tTime 0.178 (0.178)\tData 0.138 (0.138)\tLoss 1.2280 (1.2280)\tPrec 67.969% (67.969%)\n",
      "Epoch: [279][100/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.2230 (1.2609)\tPrec 67.969% (65.787%)\n",
      "Epoch: [279][200/391]\tTime 0.034 (0.033)\tData 0.002 (0.003)\tLoss 1.3713 (1.2593)\tPrec 58.594% (65.819%)\n",
      "Epoch: [279][300/391]\tTime 0.033 (0.033)\tData 0.002 (0.002)\tLoss 1.3031 (1.2549)\tPrec 65.625% (66.009%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.089 (0.089)\tLoss 1.3138 (1.3138)\tPrec 61.719% (61.719%)\n",
      " * Prec 63.600% \n",
      "best acc: 88.020000\n",
      "Epoch: [280][0/391]\tTime 0.177 (0.177)\tData 0.135 (0.135)\tLoss 1.2460 (1.2460)\tPrec 66.406% (66.406%)\n",
      "Epoch: [280][100/391]\tTime 0.035 (0.036)\tData 0.002 (0.004)\tLoss 1.1776 (1.2478)\tPrec 73.438% (66.491%)\n",
      "Epoch: [280][200/391]\tTime 0.035 (0.034)\tData 0.002 (0.003)\tLoss 1.2675 (1.2493)\tPrec 60.938% (66.383%)\n",
      "Epoch: [280][300/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.2446 (1.2521)\tPrec 67.188% (66.282%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.088 (0.088)\tLoss 1.3154 (1.3154)\tPrec 67.188% (67.188%)\n",
      " * Prec 63.500% \n",
      "best acc: 88.020000\n",
      "Epoch: [281][0/391]\tTime 0.167 (0.167)\tData 0.127 (0.127)\tLoss 1.4575 (1.4575)\tPrec 57.031% (57.031%)\n",
      "Epoch: [281][100/391]\tTime 0.030 (0.035)\tData 0.002 (0.003)\tLoss 1.2772 (1.2545)\tPrec 64.062% (65.865%)\n",
      "Epoch: [281][200/391]\tTime 0.039 (0.034)\tData 0.002 (0.003)\tLoss 1.2832 (1.2561)\tPrec 60.938% (66.006%)\n",
      "Epoch: [281][300/391]\tTime 0.031 (0.033)\tData 0.001 (0.002)\tLoss 1.2124 (1.2560)\tPrec 64.844% (66.045%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 1.2937 (1.2937)\tPrec 67.969% (67.969%)\n",
      " * Prec 64.270% \n",
      "best acc: 88.020000\n",
      "Epoch: [282][0/391]\tTime 0.164 (0.164)\tData 0.132 (0.132)\tLoss 1.1843 (1.1843)\tPrec 71.875% (71.875%)\n",
      "Epoch: [282][100/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.2601 (1.2517)\tPrec 64.844% (66.205%)\n",
      "Epoch: [282][200/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.4102 (1.2534)\tPrec 57.812% (66.177%)\n",
      "Epoch: [282][300/391]\tTime 0.036 (0.034)\tData 0.003 (0.003)\tLoss 1.2843 (1.2560)\tPrec 63.281% (66.001%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.109 (0.109)\tLoss 1.3294 (1.3294)\tPrec 62.500% (62.500%)\n",
      " * Prec 64.120% \n",
      "best acc: 88.020000\n",
      "Epoch: [283][0/391]\tTime 0.174 (0.174)\tData 0.134 (0.134)\tLoss 1.2390 (1.2390)\tPrec 68.750% (68.750%)\n",
      "Epoch: [283][100/391]\tTime 0.025 (0.035)\tData 0.001 (0.003)\tLoss 1.2936 (1.2629)\tPrec 59.375% (65.470%)\n",
      "Epoch: [283][200/391]\tTime 0.038 (0.034)\tData 0.002 (0.003)\tLoss 1.3026 (1.2567)\tPrec 61.719% (66.045%)\n",
      "Epoch: [283][300/391]\tTime 0.032 (0.034)\tData 0.003 (0.003)\tLoss 1.2055 (1.2541)\tPrec 70.312% (66.183%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.115 (0.115)\tLoss 1.3172 (1.3172)\tPrec 70.312% (70.312%)\n",
      " * Prec 64.110% \n",
      "best acc: 88.020000\n",
      "Epoch: [284][0/391]\tTime 0.175 (0.175)\tData 0.140 (0.140)\tLoss 1.3146 (1.3146)\tPrec 60.938% (60.938%)\n",
      "Epoch: [284][100/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.1182 (1.2534)\tPrec 75.781% (66.282%)\n",
      "Epoch: [284][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.2848 (1.2520)\tPrec 65.625% (66.142%)\n",
      "Epoch: [284][300/391]\tTime 0.037 (0.034)\tData 0.003 (0.003)\tLoss 1.3340 (1.2544)\tPrec 65.625% (66.025%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.124 (0.124)\tLoss 1.3803 (1.3803)\tPrec 61.719% (61.719%)\n",
      " * Prec 63.800% \n",
      "best acc: 88.020000\n",
      "Epoch: [285][0/391]\tTime 0.168 (0.168)\tData 0.131 (0.131)\tLoss 1.2181 (1.2181)\tPrec 64.844% (64.844%)\n",
      "Epoch: [285][100/391]\tTime 0.030 (0.034)\tData 0.003 (0.003)\tLoss 1.3377 (1.2531)\tPrec 63.281% (65.973%)\n",
      "Epoch: [285][200/391]\tTime 0.028 (0.034)\tData 0.001 (0.003)\tLoss 1.2930 (1.2555)\tPrec 63.281% (65.823%)\n",
      "Epoch: [285][300/391]\tTime 0.035 (0.034)\tData 0.002 (0.002)\tLoss 1.3703 (1.2550)\tPrec 60.938% (65.804%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.109 (0.109)\tLoss 1.2917 (1.2917)\tPrec 69.531% (69.531%)\n",
      " * Prec 63.550% \n",
      "best acc: 88.020000\n",
      "Epoch: [286][0/391]\tTime 0.167 (0.167)\tData 0.131 (0.131)\tLoss 1.2496 (1.2496)\tPrec 70.312% (70.312%)\n",
      "Epoch: [286][100/391]\tTime 0.031 (0.034)\tData 0.001 (0.003)\tLoss 1.3298 (1.2585)\tPrec 60.156% (66.159%)\n",
      "Epoch: [286][200/391]\tTime 0.034 (0.033)\tData 0.003 (0.003)\tLoss 1.2553 (1.2502)\tPrec 66.406% (66.367%)\n",
      "Epoch: [286][300/391]\tTime 0.037 (0.033)\tData 0.002 (0.002)\tLoss 1.2462 (1.2542)\tPrec 63.281% (66.123%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.107 (0.107)\tLoss 1.2677 (1.2677)\tPrec 67.188% (67.188%)\n",
      " * Prec 63.750% \n",
      "best acc: 88.020000\n",
      "Epoch: [287][0/391]\tTime 0.176 (0.176)\tData 0.134 (0.134)\tLoss 1.4166 (1.4166)\tPrec 55.469% (55.469%)\n",
      "Epoch: [287][100/391]\tTime 0.032 (0.035)\tData 0.002 (0.003)\tLoss 1.1073 (1.2514)\tPrec 71.094% (66.143%)\n",
      "Epoch: [287][200/391]\tTime 0.034 (0.034)\tData 0.002 (0.003)\tLoss 1.2930 (1.2549)\tPrec 64.844% (65.769%)\n",
      "Epoch: [287][300/391]\tTime 0.033 (0.034)\tData 0.003 (0.003)\tLoss 1.3443 (1.2517)\tPrec 60.156% (65.934%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 1.2545 (1.2545)\tPrec 69.531% (69.531%)\n",
      " * Prec 63.390% \n",
      "best acc: 88.020000\n",
      "Epoch: [288][0/391]\tTime 0.177 (0.177)\tData 0.141 (0.141)\tLoss 1.3116 (1.3116)\tPrec 62.500% (62.500%)\n",
      "Epoch: [288][100/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.2150 (1.2576)\tPrec 67.188% (66.182%)\n",
      "Epoch: [288][200/391]\tTime 0.031 (0.033)\tData 0.003 (0.003)\tLoss 1.2578 (1.2541)\tPrec 64.062% (66.138%)\n",
      "Epoch: [288][300/391]\tTime 0.033 (0.033)\tData 0.002 (0.002)\tLoss 1.2621 (1.2499)\tPrec 67.969% (66.258%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.096 (0.096)\tLoss 1.3124 (1.3124)\tPrec 64.844% (64.844%)\n",
      " * Prec 63.780% \n",
      "best acc: 88.020000\n",
      "Epoch: [289][0/391]\tTime 0.160 (0.160)\tData 0.131 (0.131)\tLoss 1.1700 (1.1700)\tPrec 71.875% (71.875%)\n",
      "Epoch: [289][100/391]\tTime 0.032 (0.034)\tData 0.002 (0.003)\tLoss 1.4354 (1.2563)\tPrec 60.938% (66.012%)\n",
      "Epoch: [289][200/391]\tTime 0.032 (0.033)\tData 0.002 (0.003)\tLoss 1.4075 (1.2563)\tPrec 56.250% (65.963%)\n",
      "Epoch: [289][300/391]\tTime 0.031 (0.033)\tData 0.002 (0.002)\tLoss 1.2417 (1.2539)\tPrec 64.062% (65.996%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.118 (0.118)\tLoss 1.3103 (1.3103)\tPrec 67.969% (67.969%)\n",
      " * Prec 63.370% \n",
      "best acc: 88.020000\n",
      "Epoch: [290][0/391]\tTime 0.153 (0.153)\tData 0.122 (0.122)\tLoss 1.2321 (1.2321)\tPrec 66.406% (66.406%)\n",
      "Epoch: [290][100/391]\tTime 0.035 (0.035)\tData 0.003 (0.003)\tLoss 1.1728 (1.2559)\tPrec 71.094% (65.888%)\n",
      "Epoch: [290][200/391]\tTime 0.032 (0.034)\tData 0.001 (0.003)\tLoss 1.2749 (1.2545)\tPrec 63.281% (66.029%)\n",
      "Epoch: [290][300/391]\tTime 0.031 (0.034)\tData 0.003 (0.003)\tLoss 1.1635 (1.2563)\tPrec 70.312% (65.983%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.102 (0.102)\tLoss 1.3392 (1.3392)\tPrec 64.062% (64.062%)\n",
      " * Prec 64.040% \n",
      "best acc: 88.020000\n",
      "Epoch: [291][0/391]\tTime 0.183 (0.183)\tData 0.141 (0.141)\tLoss 1.2340 (1.2340)\tPrec 70.312% (70.312%)\n",
      "Epoch: [291][100/391]\tTime 0.032 (0.035)\tData 0.002 (0.004)\tLoss 1.1340 (1.2463)\tPrec 70.312% (66.429%)\n",
      "Epoch: [291][200/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.4260 (1.2535)\tPrec 60.156% (66.107%)\n",
      "Epoch: [291][300/391]\tTime 0.036 (0.034)\tData 0.002 (0.003)\tLoss 1.1702 (1.2539)\tPrec 69.531% (66.170%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.097 (0.097)\tLoss 1.2945 (1.2945)\tPrec 68.750% (68.750%)\n",
      " * Prec 63.590% \n",
      "best acc: 88.020000\n",
      "Epoch: [292][0/391]\tTime 0.168 (0.168)\tData 0.134 (0.134)\tLoss 1.3107 (1.3107)\tPrec 66.406% (66.406%)\n",
      "Epoch: [292][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.003)\tLoss 1.3209 (1.2459)\tPrec 61.719% (66.321%)\n",
      "Epoch: [292][200/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.0677 (1.2473)\tPrec 72.656% (66.192%)\n",
      "Epoch: [292][300/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.2636 (1.2514)\tPrec 65.625% (66.038%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.142 (0.142)\tLoss 1.3021 (1.3021)\tPrec 65.625% (65.625%)\n",
      " * Prec 63.230% \n",
      "best acc: 88.020000\n",
      "Epoch: [293][0/391]\tTime 0.170 (0.170)\tData 0.130 (0.130)\tLoss 1.3069 (1.3069)\tPrec 64.062% (64.062%)\n",
      "Epoch: [293][100/391]\tTime 0.036 (0.035)\tData 0.003 (0.003)\tLoss 1.2614 (1.2486)\tPrec 67.188% (66.654%)\n",
      "Epoch: [293][200/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.2884 (1.2535)\tPrec 61.719% (66.212%)\n",
      "Epoch: [293][300/391]\tTime 0.033 (0.034)\tData 0.002 (0.003)\tLoss 1.3246 (1.2569)\tPrec 64.062% (65.949%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.114 (0.114)\tLoss 1.2790 (1.2790)\tPrec 67.969% (67.969%)\n",
      " * Prec 63.630% \n",
      "best acc: 88.020000\n",
      "Epoch: [294][0/391]\tTime 0.178 (0.178)\tData 0.144 (0.144)\tLoss 1.1449 (1.1449)\tPrec 69.531% (69.531%)\n",
      "Epoch: [294][100/391]\tTime 0.031 (0.035)\tData 0.002 (0.004)\tLoss 1.2553 (1.2491)\tPrec 64.062% (66.244%)\n",
      "Epoch: [294][200/391]\tTime 0.031 (0.034)\tData 0.002 (0.003)\tLoss 1.2494 (1.2494)\tPrec 70.312% (66.072%)\n",
      "Epoch: [294][300/391]\tTime 0.037 (0.034)\tData 0.002 (0.003)\tLoss 1.3610 (1.2512)\tPrec 64.062% (66.014%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.113 (0.113)\tLoss 1.3624 (1.3624)\tPrec 61.719% (61.719%)\n",
      " * Prec 63.530% \n",
      "best acc: 88.020000\n",
      "Epoch: [295][0/391]\tTime 0.169 (0.169)\tData 0.127 (0.127)\tLoss 1.1763 (1.1763)\tPrec 67.969% (67.969%)\n",
      "Epoch: [295][100/391]\tTime 0.033 (0.035)\tData 0.002 (0.003)\tLoss 1.2555 (1.2457)\tPrec 64.062% (66.437%)\n",
      "Epoch: [295][200/391]\tTime 0.029 (0.034)\tData 0.001 (0.003)\tLoss 1.2939 (1.2498)\tPrec 65.625% (66.297%)\n",
      "Epoch: [295][300/391]\tTime 0.034 (0.034)\tData 0.002 (0.002)\tLoss 1.2205 (1.2511)\tPrec 67.969% (66.212%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.117 (0.117)\tLoss 1.2547 (1.2547)\tPrec 69.531% (69.531%)\n",
      " * Prec 64.110% \n",
      "best acc: 88.020000\n",
      "Epoch: [296][0/391]\tTime 0.174 (0.174)\tData 0.146 (0.146)\tLoss 1.2806 (1.2806)\tPrec 64.062% (64.062%)\n",
      "Epoch: [296][100/391]\tTime 0.034 (0.034)\tData 0.003 (0.003)\tLoss 1.3086 (1.2543)\tPrec 60.938% (65.548%)\n",
      "Epoch: [296][200/391]\tTime 0.036 (0.033)\tData 0.002 (0.003)\tLoss 1.3139 (1.2517)\tPrec 64.062% (65.858%)\n",
      "Epoch: [296][300/391]\tTime 0.034 (0.033)\tData 0.002 (0.002)\tLoss 1.1872 (1.2549)\tPrec 65.625% (65.781%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.106 (0.106)\tLoss 1.2163 (1.2163)\tPrec 67.969% (67.969%)\n",
      " * Prec 64.410% \n",
      "best acc: 88.020000\n",
      "Epoch: [297][0/391]\tTime 0.170 (0.170)\tData 0.128 (0.128)\tLoss 1.4215 (1.4215)\tPrec 58.594% (58.594%)\n",
      "Epoch: [297][100/391]\tTime 0.036 (0.035)\tData 0.002 (0.003)\tLoss 1.2020 (1.2495)\tPrec 65.625% (65.749%)\n",
      "Epoch: [297][200/391]\tTime 0.032 (0.034)\tData 0.003 (0.003)\tLoss 1.1483 (1.2550)\tPrec 75.000% (65.796%)\n",
      "Epoch: [297][300/391]\tTime 0.037 (0.034)\tData 0.003 (0.003)\tLoss 1.1929 (1.2551)\tPrec 70.312% (65.654%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.112 (0.112)\tLoss 1.3085 (1.3085)\tPrec 67.969% (67.969%)\n",
      " * Prec 63.750% \n",
      "best acc: 88.020000\n",
      "Epoch: [298][0/391]\tTime 0.157 (0.157)\tData 0.122 (0.122)\tLoss 1.2677 (1.2677)\tPrec 64.844% (64.844%)\n",
      "Epoch: [298][100/391]\tTime 0.030 (0.034)\tData 0.002 (0.003)\tLoss 1.2345 (1.2552)\tPrec 63.281% (65.733%)\n",
      "Epoch: [298][200/391]\tTime 0.026 (0.033)\tData 0.001 (0.003)\tLoss 1.1815 (1.2499)\tPrec 70.312% (66.123%)\n",
      "Epoch: [298][300/391]\tTime 0.031 (0.033)\tData 0.003 (0.002)\tLoss 1.3227 (1.2511)\tPrec 62.500% (66.108%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.109 (0.109)\tLoss 1.2799 (1.2799)\tPrec 67.969% (67.969%)\n",
      " * Prec 63.840% \n",
      "best acc: 88.020000\n",
      "Epoch: [299][0/391]\tTime 0.178 (0.178)\tData 0.136 (0.136)\tLoss 1.2699 (1.2699)\tPrec 65.625% (65.625%)\n",
      "Epoch: [299][100/391]\tTime 0.030 (0.035)\tData 0.002 (0.003)\tLoss 1.1615 (1.2494)\tPrec 70.312% (66.437%)\n",
      "Epoch: [299][200/391]\tTime 0.034 (0.034)\tData 0.003 (0.003)\tLoss 1.2944 (1.2531)\tPrec 59.375% (66.189%)\n",
      "Epoch: [299][300/391]\tTime 0.036 (0.034)\tData 0.002 (0.002)\tLoss 1.2089 (1.2555)\tPrec 70.312% (66.017%)\n",
      "Validation starts\n",
      "Test: [0/79]\tTime 0.106 (0.106)\tLoss 1.3189 (1.3189)\tPrec 64.062% (64.062%)\n",
      " * Prec 64.000% \n",
      "best acc: 88.020000\n"
     ]
    }
   ],
   "source": [
    "lr = 1e-2\n",
    "weight_decay = 1e-5\n",
    "epochs = 300\n",
    "best_prec = 0\n",
    "\n",
    "model.cuda()\n",
    "\n",
    "all_params = model.named_parameters()\n",
    "params_main = []\n",
    "params_quant = []\n",
    "\n",
    "for name, param in all_params:\n",
    "    if 'alpha' in name:\n",
    "        params_quant.append(param)\n",
    "    else:\n",
    "        params_main.append(param)\n",
    "\n",
    "criterion = nn.CrossEntropyLoss(label_smoothing=0.1).cuda()\n",
    "optimizer = torch.optim.SGD([\n",
    "    {'params': params_main, 'weight_decay': weight_decay, 'lr': lr},\n",
    "    {'params': params_quant, 'weight_decay': 0.0, 'lr': lr * 0.1}\n",
    "], momentum=0.9)\n",
    "scheduler = torch.optim.lr_scheduler.CosineAnnealingLR(optimizer, T_max=epochs)\n",
    "\n",
    "if not os.path.exists('result'):\n",
    "    os.makedirs('result')\n",
    "fdir = 'result/'+str(model_name)\n",
    "if not os.path.exists(fdir):\n",
    "    os.makedirs(fdir)\n",
    "\n",
    "for epoch in range(0, epochs):\n",
    "    # adjust_learning_rate(optimizer, epoch)\n",
    "    train(trainloader, model, criterion, optimizer, epoch)\n",
    "    scheduler.step()\n",
    "\n",
    "    # evaluate on test set\n",
    "    print(\"Validation starts\")\n",
    "    prec = validate(testloader, model, criterion)\n",
    "\n",
    "    # remember best precision and save checkpoint\n",
    "    is_best = prec > best_prec\n",
    "    best_prec = max(prec,best_prec)\n",
    "    print('best acc: {:1f}'.format(best_prec))\n",
    "    save_checkpoint({\n",
    "        'epoch': epoch + 1,\n",
    "        'state_dict': model.state_dict(),\n",
    "        'best_prec': best_prec,\n",
    "        'optimizer': optimizer.state_dict(),\n",
    "    }, is_best, fdir)\n",
    "    # if best_prec > 87.0:\n",
    "    #     print(\"Achieved accuracy greater than 87%, early stopping.\")\n",
    "    #     break"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7b02195c",
   "metadata": {},
   "source": [
    "### Testing Loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "033648cb",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1037538/3160766666.py:2: FutureWarning: You are using `torch.load` with `weights_only=False` (the current default value), which uses the default pickle module implicitly. It is possible to construct malicious pickle data which will execute arbitrary code during unpickling (See https://github.com/pytorch/pytorch/blob/main/SECURITY.md#untrusted-models for more details). In a future release, the default value for `weights_only` will be flipped to `True`. This limits the functions that could be executed during unpickling. Arbitrary objects will no longer be allowed to be loaded via this mode unless they are explicitly allowlisted by the user via `torch.serialization.add_safe_globals`. We recommend you start setting `weights_only=True` for any use case where you don't have full control of the loaded file. Please open an issue on GitHub for any issues related to this experimental feature.\n",
      "  checkpoint = torch.load(PATH)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Test set: Accuracy: 8802/10000 (88%)\n",
      "\n"
     ]
    }
   ],
   "source": [
    "PATH = \"result/VGG16_2a4w_quant_noskipblock/model_best.pth.tar\"\n",
    "checkpoint = torch.load(PATH)\n",
    "model.load_state_dict(checkpoint['state_dict'])\n",
    "device = torch.device(\"cuda\") \n",
    "\n",
    "model.cuda()\n",
    "model.eval()\n",
    "\n",
    "test_loss = 0\n",
    "correct = 0\n",
    "\n",
    "with torch.no_grad():\n",
    "    for data, target in testloader:\n",
    "        data, target = data.to(device), target.to(device) # loading to GPU\n",
    "        output = model(data)\n",
    "        pred = output.argmax(dim=1, keepdim=True)  \n",
    "        correct += pred.eq(target.view_as(pred)).sum().item()\n",
    "\n",
    "test_loss /= len(testloader.dataset)\n",
    "\n",
    "print('\\nTest set: Accuracy: {}/{} ({:.0f}%)\\n'.format(\n",
    "        correct, len(testloader.dataset),\n",
    "        100. * correct / len(testloader.dataset)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e4966337",
   "metadata": {},
   "source": [
    "### Weight and Activation recovery verification"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7f5df54",
   "metadata": {},
   "source": [
    "#### Getting the right target layer and attaching hooks for fwd pass"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "13736843",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Captured Transient Input for 16x16 layer: [[[[1.23831189e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 6.71324193e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 1.32691607e-01 1.76276970e+00 7.28025019e-01]\n",
      "   [5.15404284e-01 1.03986478e+00 1.73442006e+00 1.47927773e+00]]\n",
      "\n",
      "  [[1.89826801e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 1.77257344e-01 4.03556108e-01 1.32132292e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 4.41273540e-01 0.00000000e+00]]\n",
      "\n",
      "  [[1.32021332e+00 1.73326778e+00 2.71155310e+00 3.33113289e+00]\n",
      "   [0.00000000e+00 1.26586592e+00 2.74416304e+00 3.22243619e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [6.13675117e-01 0.00000000e+00 1.01585865e+00 1.68978882e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00000000e+00 7.08765149e-01 1.70264459e+00 9.02694762e-01]\n",
      "   [2.22382259e+00 4.81758881e+00 6.25991678e+00 4.12672472e+00]\n",
      "   [3.03589177e+00 3.92067838e+00 6.18719578e+00 4.76910830e+00]\n",
      "   [4.17880744e-01 1.49659550e+00 2.19957924e+00 9.39056873e-01]]\n",
      "\n",
      "  [[9.05456662e-01 1.02590010e-01 3.28392297e-01 8.05088580e-01]\n",
      "   [7.92542458e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 6.49496689e-02 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 2.19504178e-01 0.00000000e+00 7.39737689e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 6.14625454e-01 0.00000000e+00]\n",
      "   [1.45093071e+00 2.42897654e+00 2.41480136e+00 3.02786738e-01]\n",
      "   [2.06043863e+00 4.14410114e+00 3.39284849e+00 1.18517034e-01]\n",
      "   [2.10296106e+00 3.67634010e+00 2.85421348e+00 1.53597653e+00]]\n",
      "\n",
      "  [[0.00000000e+00 1.64682180e-01 1.32131982e+00 9.56728280e-01]\n",
      "   [1.13274086e+00 7.17859447e-01 1.24589002e+00 4.03555989e-01]\n",
      "   [4.03556913e-01 1.12016833e+00 6.92715287e-01 2.63913665e-02]\n",
      "   [0.00000000e+00 0.00000000e+00 1.64685622e-01 0.00000000e+00]]\n",
      "\n",
      "  [[7.01814219e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [9.19203609e-02 0.00000000e+00 0.00000000e+00 4.72366720e-01]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[6.48173094e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 5.54193497e-01 1.84629440e+00]\n",
      "   [3.66022855e-01 1.90395907e-01 0.00000000e+00 9.93255615e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 6.49503991e-02]]\n",
      "\n",
      "  [[1.15458474e-01 0.00000000e+00 6.35691345e-01 4.27598864e-01]\n",
      "   [2.84535110e-01 2.71528572e-01 1.78020370e+00 2.19504967e-01]\n",
      "   [1.06488323e+00 1.46806419e+00 1.01285994e+00 0.00000000e+00]\n",
      "   [4.53611225e-01 7.64414668e-02 5.44651031e-01 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [1.19578815e+00 1.73442161e+00 1.33753288e+00 9.01684538e-02]\n",
      "   [6.71330690e-01 2.98178697e+00 2.68412042e+00 4.30359542e-01]\n",
      "   [1.61043033e-01 1.79112053e+00 2.10296106e+00 6.00454152e-01]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 6.67570174e-01 1.03216290e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 5.66993594e-01 4.53844309e-01 0.00000000e+00]\n",
      "   [3.15549225e-01 1.77256867e-01 7.55575895e-01 0.00000000e+00]]\n",
      "\n",
      "  [[4.39761341e-01 1.68010935e-01 0.00000000e+00 3.20189029e-01]\n",
      "   [4.07148868e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [7.33244419e-01 0.00000000e+00 0.00000000e+00 1.13663159e-01]\n",
      "   [1.49413228e+00 7.76721895e-01 7.22373724e-01 1.60283017e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.32690787e+00 6.36045456e-01 1.51230514e-01 0.00000000e+00]\n",
      "   [1.02747895e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [1.54507768e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [1.38751221e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 6.54549420e-01 9.05441821e-01 1.67066777e+00]\n",
      "   [0.00000000e+00 9.00402963e-02 6.79639339e-01 1.43231976e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 3.28388244e-01 1.28178322e+00]\n",
      "   [0.00000000e+00 1.52763113e-01 8.05085778e-01 5.16558528e-01]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 2.06499934e-01 4.53612357e-01]\n",
      "   [2.71528423e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [6.61701918e-01 8.69795978e-01 5.70662320e-01 9.21819806e-01]\n",
      "   [3.10544968e-01 3.75575244e-01 4.27598655e-01 2.32511312e-01]]]\n",
      "\n",
      "\n",
      " ...\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 1.67772377e+00 1.94704056e+00 0.00000000e+00]\n",
      "   [8.83944094e-01 3.16605496e+00 1.69189739e+00 0.00000000e+00]]\n",
      "\n",
      "  [[1.25191011e-03 1.34647107e+00 1.29618037e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 5.29278040e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 3.53268862e-01 4.78989512e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 2.63920557e-02 4.66417193e-01]]\n",
      "\n",
      "  [[9.07161832e-01 6.46286607e-01 4.18020159e-01 1.46152580e+00]\n",
      "   [2.33234078e-01 0.00000000e+00 0.00000000e+00 9.18031096e-01]\n",
      "   [7.01832250e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[1.99712932e-01 1.39112100e-01 0.00000000e+00 7.81492949e-01]\n",
      "   [1.52084017e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [2.32078433e+00 1.08450365e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [2.62379336e+00 8.42094302e-01 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 4.28744674e-01 0.00000000e+00 2.22716294e-03]\n",
      "   [2.28028879e-01 1.05597830e+00 5.91826439e-01 7.17272162e-01]\n",
      "   [0.00000000e+00 1.40218571e-01 3.91111642e-01 5.54192185e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 8.30780447e-01 2.84532547e-01 3.49562436e-01]\n",
      "   [6.61697805e-01 4.01587576e-01 2.44162790e-02 8.43784451e-01]\n",
      "   [4.27597940e-01 3.75576317e-01 1.15592360e+00 1.37702298e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 5.04283868e-02 7.65749097e-01]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [1.92963518e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [8.83946359e-01 3.45312059e-01 1.23831141e+00 7.59945884e-02]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[1.89755365e-01 0.00000000e+00 5.37589014e-01 1.46275043e-01]\n",
      "   [8.52815092e-01 0.00000000e+00 6.78895831e-01 2.76711136e-01]\n",
      "   [1.29847598e+00 0.00000000e+00 3.41930002e-01 5.70196629e-01]\n",
      "   [2.26589155e+00 1.08107805e+00 1.34195471e+00 2.09197307e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 5.26961207e-01]\n",
      "   [4.78483260e-01 8.05732906e-01 0.00000000e+00 0.00000000e+00]\n",
      "   [1.35115242e+00 9.39057052e-01 1.48447633e+00 6.60287857e-01]\n",
      "   [8.54215682e-01 1.71476412e+00 1.67840278e+00 5.26963353e-01]]\n",
      "\n",
      "  [[7.92535186e-01 4.66378361e-01 7.54905105e-01 1.90901375e+00]\n",
      "   [6.49482831e-02 0.00000000e+00 0.00000000e+00 4.41289961e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 1.02583490e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 2.73153167e-02 3.28387946e-01]]\n",
      "\n",
      "  [[0.00000000e+00 1.65014994e+00 1.88425171e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 2.58656573e+00 3.71807218e+00 5.31645358e-01]\n",
      "   [0.00000000e+00 6.61703646e-01 2.18338490e+00 7.64411315e-02]\n",
      "   [1.14134494e-02 0.00000000e+00 0.00000000e+00 0.00000000e+00]]]\n",
      "\n",
      "\n",
      " [[[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 7.59946853e-02 5.12140710e-03]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[4.28698242e-01 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [1.89831987e-01 1.14531171e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 1.38198705e-02 8.68725300e-01 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 5.41850030e-01 2.52690613e-01]]\n",
      "\n",
      "  [[1.37456715e+00 2.05936170e+00 3.67896891e+00 3.36374259e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 2.18980217e+00 2.92895031e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 3.20190042e-01 1.75500786e+00]\n",
      "   [1.14629877e+00 0.00000000e+00 4.07148868e-01 2.07023382e+00]]\n",
      "\n",
      "  ...\n",
      "\n",
      "  [[9.75420475e-01 2.21169877e+00 2.00565147e+00 3.93637896e-01]\n",
      "   [3.16921520e+00 3.54494500e+00 3.15709186e+00 2.00565171e+00]\n",
      "   [2.59955430e+00 1.48447573e+00 3.52070451e+00 3.62978792e+00]\n",
      "   [4.66360748e-01 1.07238173e+00 1.18146503e+00 1.64204049e+00]]\n",
      "\n",
      "  [[0.00000000e+00 1.00580156e+00 1.00580025e+00 9.80711460e-01]\n",
      "   [5.41647255e-01 1.84629321e+00 1.40722978e+00 5.29102623e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]]\n",
      "\n",
      "  [[0.00000000e+00 0.00000000e+00 0.00000000e+00 0.00000000e+00]\n",
      "   [8.95809293e-01 2.04032016e+00 1.48107040e+00 0.00000000e+00]\n",
      "   [1.52008724e+00 2.82067037e+00 2.63858843e+00 4.01586920e-01]\n",
      "   [0.00000000e+00 0.00000000e+00 1.16893089e+00 4.40604299e-01]]]]\n"
     ]
    }
   ],
   "source": [
    "if use_skip_block:\n",
    "    target_layer = model.features[20].conv27\n",
    "    next_layer = model.features[20].bn28\n",
    "else:\n",
    "    target_layer = model.features[27]\n",
    "    next_layer = model.features[28]\n",
    "\n",
    "# some sanity checking to ensure we're extracting the right layer\n",
    "assert isinstance(target_layer, QuantConv2d)\n",
    "\n",
    "input_records = {}\n",
    "def get_input_hook(name):\n",
    "    def hook(model, input, output):\n",
    "        input_records[name] = input[0].detach().clone()\n",
    "    return hook\n",
    "\n",
    "target_layer.register_forward_hook(get_input_hook('conv16x16_input'))\n",
    "next_layer.register_forward_hook(get_input_hook('next_layer_input'))\n",
    "\n",
    "# Running a sample forward pass to extract inputs\n",
    "data, _ = next(iter(testloader))\n",
    "data = data.cuda()\n",
    "model = model.cuda()\n",
    "model.eval()\n",
    "with torch.no_grad():\n",
    "    output = model(data)\n",
    "conv16x16_input = input_records['conv16x16_input'].cpu().numpy()\n",
    "print(f\"Captured Transient Input for 16x16 layer: {conv16x16_input}\")\n",
    "\n",
    "target_layer = target_layer.cpu()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "da37d13f",
   "metadata": {},
   "source": [
    "#### Extracting weights for 16x16 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "d062bece",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Weights (check if they're all integers for sanity): tensor([[-0., 3., 2.],\n",
      "        [1., 2., 2.],\n",
      "        [3., 3., 2.]], grad_fn=<SliceBackward0>)\n",
      "Sample Weights after rounding: tensor([[-0., 3., 2.],\n",
      "        [1., 2., 2.],\n",
      "        [3., 3., 2.]], grad_fn=<SliceBackward0>)\n"
     ]
    }
   ],
   "source": [
    "w_bit = 4\n",
    "weight_float_q = target_layer.weight_q\n",
    "w_alpha = target_layer.weight_quant.wgt_alpha\n",
    "w_delta = w_alpha / (2**(w_bit - 1)-1)\n",
    "\n",
    "weight_int = (weight_float_q / w_delta)\n",
    "print(f\"Sample Weights (check if they're all integers for sanity): {weight_int[0][0][:][:]}\")\n",
    "\n",
    "weight_int = weight_int.round()\n",
    "print(f\"Sample Weights after rounding: {weight_int[0][0][:][:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "88a7af54",
   "metadata": {},
   "source": [
    "#### Extracting Inputs for 16x16 layer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d873ee67",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Sample Inputs after quantization: tensor([[1., 0., 0., 0.],\n",
      "        [0., 0., 0., 0.],\n",
      "        [0., 0., 1., 0.],\n",
      "        [0., 1., 1., 1.]])\n"
     ]
    }
   ],
   "source": [
    "x_bit = 2\n",
    "x = conv16x16_input\n",
    "x_alpha = target_layer.act_alpha.detach()\n",
    "x_delta = x_alpha / (2**x_bit - 1)\n",
    "\n",
    "x_div = x / x_alpha\n",
    "x_clamped = torch.clamp(x_div, 0, 1)\n",
    "x_int = (x_clamped * (2**x_bit - 1)).round()\n",
    "\n",
    "print(f\"Sample Inputs after quantization: {x_int[0][0][:][:]}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0495f661",
   "metadata": {},
   "source": [
    "#### Verifying Psum Integrity with reference psum"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "eab353ec",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 1.5899438494670903e-06\n",
      "Success... Psum integrity verified!\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/tmp/ipykernel_1037538/3644988574.py:3: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  psum_int = conv_int(torch.tensor(x_int))\n",
      "/tmp/ipykernel_1037538/3644988574.py:7: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  x_model_q = act_fn(torch.tensor(x), torch.tensor(x_alpha))\n",
      "/tmp/ipykernel_1037538/3644988574.py:8: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  output_ref = F.conv2d(torch.tensor(x_model_q), torch.tensor(target_layer.weight_q), bias=None, stride=1, padding=1)\n"
     ]
    }
   ],
   "source": [
    "conv_int = nn.Conv2d(16, 16, kernel_size=3, padding=1, bias=False)\n",
    "conv_int.weight = nn.Parameter(weight_int.float())\n",
    "psum_int = conv_int(torch.tensor(x_int))\n",
    "output_recovered = psum_int * x_delta * w_delta\n",
    "\n",
    "act_fn = act_quantization(b=2)\n",
    "x_model_q = act_fn(torch.tensor(x), torch.tensor(x_alpha))\n",
    "output_ref = F.conv2d(torch.tensor(x_model_q), torch.tensor(target_layer.weight_q), bias=None, stride=1, padding=1)\n",
    "\n",
    "difference = torch.abs(output_recovered - output_ref)\n",
    "print(f\"Mean Absolute Error: {difference.mean().item()}\")\n",
    "if difference.mean().item() < 1e-3:\n",
    "    print(\"Success... Psum integrity verified!\")\n",
    "else:\n",
    "    print(\"Error too high... Psum integrity failed.\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0b1f74f7",
   "metadata": {},
   "source": [
    "#### Verifying Psum Integrity with next layer input"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1dc51b24",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error with next layer input: 1.6895540966288536e-06\n",
      "Success... Psum integrity verified!\n"
     ]
    }
   ],
   "source": [
    "difference2 = torch.abs(input_records['next_layer_input'].cpu() - output_recovered)\n",
    "print(f\"Mean Absolute Error with next layer input: {difference2.mean().item()}\")\n",
    "if difference2.mean().item() < 1e-3:\n",
    "    print(\"Success... Psum integrity verified!\")\n",
    "else:\n",
    "    print(\"Error too high... Psum integrity failed.\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "school-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.19"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
